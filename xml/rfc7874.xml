<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [
<!ENTITY rfc2119 PUBLIC '' 'reference.RFC.2119.xml'>
<!ENTITY rfc3551 PUBLIC '' 'reference.RFC.3551.xml'>
<!ENTITY rfc3389 PUBLIC '' 'reference.RFC.3389.xml'>
<!ENTITY rfc4733 PUBLIC '' 'reference.RFC.4733.xml'>
<!ENTITY rfc6716 PUBLIC '' 'reference.RFC.6716.xml'>
<!ENTITY rfc6562 PUBLIC '' 'reference.RFC.6562.xml'>
<!ENTITY rfc7587 PUBLIC '' 'reference.RFC.7587.xml'>
<!ENTITY nbsp "&#160;">
  ]>

<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="3"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="no"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc number="7874" category="std" ipr="trust200902" submissionType="IETF"
     consensus="yes">
  <front>
    <title abbrev="WebRTC Audio">WebRTC Audio Codec and Processing
    Requirements</title>

    <author fullname="Jean-Marc Valin" initials="JM." surname="Valin">
      <organization>Mozilla</organization>

      <address>
        <postal>
          <street>331 E. Evelyn Avenue</street>

          <city>Mountain View</city>

          <region>CA</region>

          <code>94041</code>

          <country>United States</country>
        </postal>

        <email>jmvalin@jmvalin.ca</email>
      </address>
    </author>

    <author fullname="Cary Bran" initials="C." surname="Bran">
      <organization>Plantronics</organization>

      <address>
        <postal>
          <street>345 Encinial Street</street>

          <city>Santa Cruz</city>

          <region>CA</region>

          <code>95060</code>

          <country>United States</country>
        </postal>

        <phone>+1 206 661-2398</phone>

        <email>cary.bran@plantronics.com</email>
      </address>
    </author>

    <date month="May" year="2016"/>

    <abstract>
      <t>This document outlines the audio codec and processing requirements
      for WebRTC endpoints.</t>
    </abstract>
  </front>

  <middle>
    <section title="Introduction">

      <t>An integral part of the success and adoption of Web Real-Time
      Communications (WebRTC) will be the voice and video interoperability
      between WebRTC applications. This specification will outline the audio
      processing and codec requirements for WebRTC endpoints.</t>
    </section>

    <section title="Terminology">
      <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
      "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and "OPTIONAL" in this
      document are to be interpreted as described in <xref
      target="RFC2119">RFC 2119</xref>.</t>
    </section>

    <section title="Codec Requirements">
      <t>To ensure a baseline level of interoperability between WebRTC
      endpoints, a minimum set of required codecs are specified below.
      If other suitable audio codecs are available for the WebRTC endpoint to use,
      it is RECOMMENDED that they also be included in the offer in order
      to maximize the possibility of establishing the session without the need
      for audio transcoding.</t>

      <t>WebRTC endpoints are REQUIRED to implement the following audio
      codecs:</t>

      <t><list style="symbols">
          <t>Opus <xref target="RFC6716"/> with the payload format specified
          in <xref target="RFC7587"/>.</t>

          <t>PCMA and PCMU (as specified in ITU-T Recommendation G.711 <xref target="G.711"/>) with the payload format specified in Section
          4.5.14 of <xref target="RFC3551"/>.</t>

          <t><xref target="RFC3389"/> comfort noise (CN). WebRTC endpoints MUST
          support <xref target="RFC3389"/> CN for streams encoded with G.711 or any other supported
          codec that does not provide its own CN. Since Opus provides its own CN mechanism,
          the use of <xref target="RFC3389"/> CN with Opus is NOT RECOMMENDED.
          Use of Discontinuous Transmission (DTX) / CN by senders is OPTIONAL.</t>

          <t>the 'audio/telephone-event' media type as specified in <xref
          target="RFC4733"/>. The endpoints MAY send DTMF events at any time
          and SHOULD suppress in-band dual-tone multi-frequency (DTMF) tones, if any.
          DTMF events generated by a WebRTC endpoint MUST have a duration of
	  no more than 8000 ms and no less than 40 ms.  The recommended
	  default duration is 100 ms for each tone. The gap between events
	  MUST be no less than 30 ms; the recommended default gap duration is
	  70 ms. WebRTC endpoints are not required to do anything with tones
	  (as specified in RFC 4733) sent to them, except gracefully drop
	  them. There is currently no API to inform JavaScript about the
	  received DTMF or other tones (as specified in RFC 4733).
          WebRTC endpoints are REQUIRED to be able to
          generate and consume the following events:</t>
        </list></t>

      <t/>

      <figure>
        <artwork><![CDATA[
      +------------+--------------------------------+-----------+ 
      |Event Code  | Event Name                     | Reference |
      +------------+--------------------------------+-----------+ 
      | 0          | DTMF digit "0"                 | [RFC4733] |
      | 1          | DTMF digit "1"                 | [RFC4733] |    
      | 2          | DTMF digit "2"                 | [RFC4733] | 
      | 3          | DTMF digit "3"                 | [RFC4733] |
      | 4          | DTMF digit "4"                 | [RFC4733] |
      | 5          | DTMF digit "5"                 | [RFC4733] |
      | 6          | DTMF digit "6"                 | [RFC4733] |
      | 7          | DTMF digit "7"                 | [RFC4733] |
      | 8          | DTMF digit "8"                 | [RFC4733] |
      | 9          | DTMF digit "9"                 | [RFC4733] |
      | 10         | DTMF digit "*"                 | [RFC4733] |
      | 11         | DTMF digit "#"                 | [RFC4733] |
      | 12         | DTMF digit "A"                 | [RFC4733] |
      | 13         | DTMF digit "B"                 | [RFC4733] |
      | 14         | DTMF digit "C"                 | [RFC4733] |
      | 15         | DTMF digit "D"                 | [RFC4733] |
      +------------+--------------------------------+-----------+ 
        ]]></artwork>
      </figure>

      <t/>

      <t>For all cases where the endpoint is able to process audio at a sampling
      rate higher than 8 kHz, it is RECOMMENDED that Opus be offered before
      PCMA/PCMU. For Opus, all modes MUST be supported on the decoder side.
      The choice of encoder-side modes is left to the implementer. Endpoints MAY
      use the offer/answer mechanism to signal a preference for a particular
      mode or ptime.</t>
    
      <t>For additional information on implementing codecs other than the
      mandatory-to-implement codecs listed above, refer to <xref target="RFC7875"/>.</t>
      
    </section>

    <section anchor="level" title="Audio Level">
      <t>It is desirable to standardize the "on the wire" audio level for
      speech transmission to avoid users having to manually adjust the
      playback and to facilitate mixing in conferencing applications. It is
      also desirable to be consistent with ITU-T Recommendations G.169 and
      G.115, which recommend an active audio level of -19 dBm0. However,
      unlike G.169 and G.115, the audio for WebRTC is not constrained to have
      a passband specified by G.712 and can in fact be sampled at any sampling
      rate from 8 to 48 kHz and higher. For this reason, the level SHOULD be
      normalized by only considering frequencies above 300 Hz, regardless of
      the sampling rate used. The level SHOULD also be adapted to avoid
      clipping, either by lowering the gain to a level below -19 dBm0 or
      through the use of a compressor.</t>

      <t>Assuming linear 16-bit PCM with a value of +/-32767, -19 dBm0 corresponds to
      a root mean square (RMS) level of 2600. Only active speech should be
      considered in the RMS calculation.

 If the endpoint has control over the
      entire audio-capture path, as is typically the case for a regular phone,
then it is RECOMMENDED that the gain be adjusted in such a way that an average
speaker would have a level of 2600 (-19 dBm0) for active speech.

      If
      the endpoint does not have control over the entire audio capture, as is
      typically the case for a software endpoint, then the endpoint SHOULD use
      automatic gain control (AGC) to dynamically adjust the level to 2600
      (-19 dBm0) +/- 6 dB. For music- or desktop-sharing applications, the
      level SHOULD NOT be automatically adjusted, and the endpoint SHOULD allow
      the user to set the gain manually.</t>

      <t>The RECOMMENDED filter for normalizing the signal energy is a
      second-order Butterworth filter with a 300 Hz cutoff frequency.</t>

      <t>It is common for the audio output on some devices to be "calibrated"
      for playing back pre-recorded "commercial" music, which is typically
      around 12 dB louder than the level recommended in this section. Because
      of this, endpoints MAY increase the gain before playback.</t>
    </section>

    <section anchor="aec" title="Acoustic Echo Cancellation (AEC)">
      <t>It is plausible that the dominant near-to-medium-term WebRTC usage model
      will be people using the interactive audio and video capabilities to
      communicate with each other via web browsers running on a notebook
      computer that has a built-in microphone and speakers. The notebook-as-communication-device paradigm presents challenging echo cancellation
      problems, the specific remedy of which will not be mandated here.
      However, while no specific algorithm or standard will be required by
      WebRTC-compatible endpoints, echo cancellation will improve the user
      experience and should be implemented by the endpoint device.</t>

      <t>WebRTC endpoints SHOULD include an AEC or some other form of echo
      control. On general-purpose platforms (e.g., a PC), it is common for the
 analog-to-digital converter (ADC) for audio capture and the 
 digital-to-analog converter (DAC) for audio playback to use different clocks.
      In these cases, such as when a webcam is used for capture and a separate
      soundcard is used for playback, the sampling rates are likely to differ
      slightly. Endpoint AECs SHOULD be robust to such conditions, unless they
      are shipped along with hardware that guarantees capture and playback to
      be sampled from the same clock.</t>


      <t>Endpoints SHOULD allow the entire AEC and/or the nonlinear processing
      (NLP) to be turned off for applications, such as music, that do not
      behave well with the spectral attenuation methods typically used in
      NLP. Similarly, endpoints SHOULD have the ability to detect the presence
      of a headset and disable echo cancellation.</t>

      <t>For some applications where the remote endpoint may not have an echo
      canceller, the local endpoint MAY include a far-end echo canceller, but
      when included, it SHOULD be disabled by default.</t>
    </section>

    <section title="Legacy VoIP Interoperability">
      <t>The codec requirements above will ensure, at a minimum, voice
      interoperability capabilities between WebRTC endpoints and
      legacy phone systems that support G.711.</t>
    </section>

    <section anchor="Security" title="Security Considerations">
      <t>For security considerations regarding the codecs themselves, please
      refer to their specifications, including <xref target="RFC6716"/>,
      <xref target="RFC7587"/>, <xref target="RFC3551"/>,
      <xref target="RFC3389"/>, and <xref target="RFC4733"/>.  Likewise, consult the RTP base specification
      for RTP-based security considerations. WebRTC security is further
      discussed in <xref target="WebRTC-SEC"/>,
      <xref target="WebRTC-SEC-ARCH"/>, and <xref target="WebRTC-RTP-USAGE"/>.</t>

      <t>Using the guidelines in <xref target="RFC6562"/>, implementers should consider whether the use of variable bitrate is appropriate
      for their application. Encryption and
      authentication issues are beyond the scope of this document.</t>
    </section>


  </middle>

  <back>
    <references title="Normative References">

      &rfc2119;
      &rfc3551;
      &rfc3389;
      &rfc4733;
      &rfc6716;
      &rfc6562;
      &rfc7587;

<reference anchor="G.711" target="http://www.itu.int/rec/T-REC-G.711-198811-I/en">
	<front>
		<title>Pulse code modulation (PCM) of voice frequencies
		</title>

		<author>
			<organization>ITU-T</organization>
		</author>
		<date month="November" year="1988"></date>
	</front>
<seriesInfo name="ITU-T Recommendation" value="G.711"/>
</reference>	

    </references>
    
    <references title="Informative References">

<!-- draft-ietf-rtcweb-security-08: Expired -->

<reference anchor='WebRTC-SEC'>
<front>
<title>Security Considerations for WebRTC</title>

<author initials='E' surname='Rescorla' fullname='Eric Rescorla'>
    <organization />
</author>

<date month='February' day='26' year='2015' />

<abstract><t>The Real-Time Communications on the Web (RTCWEB) working group is tasked with standardizing protocols for real-time communications between Web browsers, generally called "WebRTC".  The major use cases for WebRTC technology are real-time audio and/or video calls, Web conferencing, and direct data transfer.  Unlike most conventional real-time systems (e.g., SIP-based soft phones) WebRTC communications are directly controlled by a Web server, which poses new security challenges.  For instance, a Web browser might expose a JavaScript API which allows a server to place a video call.  Unrestricted access to such an API would allow any site which a user visited to "bug" a user's computer, capturing any activity which passed in front of their camera.  This document defines the WebRTC threat model and analyzes the security threats of WebRTC in that model.</t></abstract>

</front>
<seriesInfo name='Work in Progress,' value='draft-ietf-rtcweb-security-08' />

</reference>

<!-- draft-ietf-rtcweb-security-arch-11: Expired -->

<reference anchor='WebRTC-SEC-ARCH'>
<front>
<title>WebRTC Security Architecture</title>

<author initials='E' surname='Rescorla' fullname='Eric Rescorla'>
    <organization />
</author>

<date month='March' day='7' year='2015' />

<abstract><t>The Real-Time Communications on the Web (RTCWEB) working group is tasked with standardizing protocols for enabling real-time communications within user-agents using web technologies (commonly called "WebRTC").  This document defines the security architecture for WebRTC.</t></abstract>

</front>
<seriesInfo name='Work in Progress,' value='draft-ietf-rtcweb-security-arch-11' />

</reference>

<!-- draft-ietf-rtcweb-rtp-usage-26: in queue in MISSREF -->
<reference anchor='WebRTC-RTP-USAGE'>
<front>
<title>Web Real-Time Communication (WebRTC): Media Transport and Use of RTP</title>

<author initials='C' surname='Perkins' fullname='Colin Perkins'>
    <organization />
</author>

<author initials='M' surname='Westerlund' fullname='Magnus Westerlund'>
    <organization />
</author>

<author initials='J' surname='Ott' fullname='Joerg Ott'>
    <organization />
</author>

<date month='March' day='17' year='2016' />

<abstract><t>The Web Real-Time Communication (WebRTC) framework provides support for direct interactive rich communication using audio, video, text, collaboration, games, etc. between two peers' web-browsers.  This memo describes the media transport aspects of the WebRTC framework. It specifies how the Real-time Transport Protocol (RTP) is used in the WebRTC context, and gives requirements for which RTP features, profiles, and extensions need to be supported.</t></abstract>

</front>
<seriesInfo name='Work in Progress,' value='draft-ietf-rtcweb-rtp-usage-26' />

</reference>

<!-- draft-ietf-rtcweb-audio-codecs-for-interop-06: companion doc -->
<reference anchor="RFC7875" target="http://www.rfc-editor.org/info/rfc7875">
<front>
<title>Additional WebRTC Audio Codecs for Interoperability</title>
<author initials='S' surname='Proust' fullname='Stephane Proust' role='editor'>
  <organization/>
</author>
<date month='May' year='2016'/>
</front>
<seriesInfo name="RFC" value="7875"/>
<seriesInfo name="DOI" value="10.17487/RFC7875"/>
</reference>

    </references>

    <section anchor="Acknowledgements" title="Acknowledgements" numbered="no">
      <t>This document incorporates ideas and text from various other documents. In
      particular, we would like to acknowledge, and say thanks for, work we
      incorporated from Harald Alvestrand and Cullen Jennings.</t>
    </section>
  </back>
</rfc>
