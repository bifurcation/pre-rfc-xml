<?xml version="1.0" encoding="US-ASCII"?>

<?rfc rfcedstyle="yes" ?>
<?rfc toc="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes" ?>
<?rfc compact="yes" ?>
<?rfc subcompact="no" ?>

<rfc number="6412" category="info" submissionType="IETF" consensus="yes"
     ipr="pre5378Trust200902">
  <front>
    <title abbrev="IGP Convergence Benchmark Terminology">Terminology for
    Benchmarking Link-State IGP Data-Plane Route Convergence</title>

    <author fullname="Scott Poretsky" initials="S" surname="Poretsky">
      <organization>Allot Communications</organization>

      <address>
        <postal>
          <street>300 TradeCenter</street>

          <city>Woburn</city>

          <region>MA</region>

          <code>01801</code>

          <country>USA</country>
        </postal>

        <phone>+ 1 508 309 2179</phone>

        <email>sporetsky@allot.com</email>
      </address>
    </author>

    <author fullname="Brent Imhoff" initials="B" surname="Imhoff">
      <organization>F5 Networks</organization>

      <address>
        <postal>
          <street>401 Elliott Avenue West</street>

          <city>Seattle</city>

          <region>WA</region>

          <code>98119</code>

          <country>USA</country>
        </postal>

        <phone>+ 1 314 378 2571</phone>

        <email>bimhoff@planetspork.com</email>
      </address>
    </author>

    <author fullname="Kris Michielsen" initials="K" surname="Michielsen">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street>6A De Kleetlaan</street>

          <city>Diegem</city>

          <region>BRABANT</region>

          <code>1831</code>

          <country>Belgium</country>
        </postal>

        <email>kmichiel@cisco.com</email>
      </address>
    </author>

    <date month="November" year="2011" />

    <area>Benchmarking Working Group</area>

    <abstract>
      <t>This document describes the terminology for benchmarking link-state
      Interior Gateway Protocol (IGP) route convergence. The terminology is to
      be used for benchmarking IGP convergence time through externally
      observable (black-box) data-plane measurements. The terminology can be
      applied to any link-state IGP, such as IS-IS and OSPF.</t>
    </abstract>

  </front>

  <middle>
    <section title="Introduction and Scope">
      <t>This document is a companion to <xref target="Po11m"></xref>,
      which contains
      the methodology to be used for benchmarking link-state Interior Gateway
      Protocol (IGP) convergence by observing the data plane. The purpose of
      this document is to introduce new terms required to complete execution
      of the Link-State IGP Data-Plane Route Convergence methodology <xref
      target="Po11m"></xref>.</t>

      <t>IGP convergence time is measured by observing the data plane through
      the Device Under Test (DUT) at the Tester. The methodology and
      terminology to be used for benchmarking IGP convergence can be applied
      to IPv4 and IPv6 traffic and link-state IGPs such as Intermediate System
      to Intermediate System (IS-IS) <xref target="Ca90"></xref><xref
      target="Ho08"></xref>, Open Shortest Path First (OSPF) <xref
      target="Mo98"></xref> <xref target="Co08"></xref>, and others.</t>
    </section>

    <section title="Existing Definitions">
      <t>This document uses existing terminology defined in other IETF
      documents. Examples include, but are not limited to:</t>

      <texttable style="none" suppress-title="true">
        <ttcol></ttcol>

        <ttcol></ttcol>

        <c>Throughput</c>

        <c><xref target="Br91"></xref>, Section 3.17</c>

        <c>Offered Load</c>

        <c><xref target="Ma98"></xref>, Section 3.5.2</c>

        <c>Forwarding Rate</c>

        <c><xref target="Ma98"></xref>, Section 3.6.1</c>

        <c>Device Under Test (DUT)</c>

        <c><xref target="Ma98"></xref>, Section 3.1.1</c>

        <c>System Under Test (SUT)</c>

        <c><xref target="Ma98"></xref>, Section 3.1.2</c>

        <c>Out-of-Order Packet</c>

        <c><xref target="Po06"></xref>, Section 3.3.4</c>

        <c>Duplicate Packet</c>

        <c><xref target="Po06"></xref>, Section 3.3.5</c>

        <c>Stream</c>

        <c><xref target="Po06"></xref>, Section 3.3.2</c>

        <c>Forwarding Delay</c>

        <c><xref target="Po06"></xref>, Section 3.2.4</c>

        <c>IP Packet Delay Variation (IPDV)</c>

        <c><xref target="De02"></xref>, Section 1.2</c>

        <c>Loss Period</c>

        <c><xref target="Ko02"></xref>, Section 4</c>
      </texttable>

      <t>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
      "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
      document are to be interpreted as described in BCP 14, RFC 2119 <xref
      target="Br97"></xref>. RFC 2119 defines the use of these keywords to
      help make the intent of Standards Track documents as clear as possible.
      While this document uses these keywords, this document is not a
      Standards Track document.</t>
    </section>

    <section title="Term Definitions">
      <section title="Convergence Types">
        <section anchor="route_convergence" title="Route Convergence">
          <t>Definition:

          <list><t>The process of updating all components of the router, including
          the Routing Information Base (RIB) and Forwarding Information Base
          (FIB), along with software and hardware tables, with the most recent
          route change(s) such that forwarding for a route entry is successful
          on the Next-Best Egress Interface (<xref
          target="next-best_egress_interface"></xref>).</t></list></t>

          <t>Discussion:

          <list><t>In general, IGP convergence does not necessarily result in a
          change in forwarding. But the test cases in <xref
          target="Po11m"></xref> are specified such that the IGP convergence
          results in a change of egress interface for the measurement
          data-plane traffic. Due to this property of the test case
          specifications, Route Convergence can be observed externally by the
          rerouting of the measurement data-plane traffic to the Next-Best
          Egress Interface (<xref
          target="next-best_egress_interface"></xref>).</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:

          <list><t>Next-Best Egress Interface, Full Convergence</t></list></t>
        </section>

        <section anchor="full_convergence" title="Full Convergence">
          <t>Definition:

          <list><t>Route Convergence for all routes in the Forwarding Information
          Base (FIB).</t></list></t>

          <t>Discussion:

          <list><t>In general, IGP convergence does not necessarily result in a
          change in forwarding. But the test cases in <xref
          target="Po11m"></xref> are specified such that the IGP convergence
          results in a change of egress interface for the measurement
          data-plane traffic. Due to this property of the test cases
          specifications, Full Convergence can be observed externally by the
          rerouting of the measurement data-plane traffic to the Next-Best
          Egress Interface (<xref
          target="next-best_egress_interface"></xref>).</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:

          <list><t>Next-Best Egress Interface, Route Convergence</t></list></t>
        </section>
      </section>

      <section title="Instants">
        <section anchor="traffic_start_instant" title="Traffic Start Instant">
          <t>Definition:

          <list><t>The time instant the Tester sends out the first data packet to
          the DUT.</t></list></t>


          <t>Discussion:

          <list><t>If using the Loss-Derived Method (<xref
          target="loss-derived_method"></xref>) or the Route-Specific
          Loss-Derived Method (<xref
          target="route-specific_loss-derived_method"></xref>) to benchmark
          IGP convergence time, and the applied Convergence Event (<xref
          target="convergence_event"></xref>) does not cause instantaneous
          traffic loss for all routes at the Convergence Event Instant (<xref
          target="convergence_event_instant"></xref>), then the Tester SHOULD
          collect a timestamp on the Traffic Start Instant in order to measure
          the period of time between the Traffic Start Instant and Convergence
          Event Instant.</t></list></t>

          <t>Measurement Units:

          <list><t>seconds (and fractions), reported with resolution sufficient to
          distinguish between different instants</t></list></t>

          <t>See Also:

          <list><t>Loss-Derived Method, Route-Specific Loss-Derived Method,
          Convergence Event, Convergence Event Instant</t></list></t>
        </section>

        <section anchor="convergence_event_instant"
                 title="Convergence Event Instant">
          <t>Definition:

          <list><t>The time instant that a Convergence Event (<xref
          target="convergence_event"></xref>) occurs.</t></list></t>

          <t>Discussion:

          <list><t>If the Convergence Event (<xref
          target="convergence_event"></xref>) causes instantaneous traffic
          loss on the Preferred Egress Interface (<xref
          target="preferred_egress_interface"></xref>), the Convergence Event
          Instant is observable from the data plane as the instant that no
          more packets are received on the Preferred Egress Interface.</t>

          <t>The Tester SHOULD collect a timestamp on the Convergence Event
          Instant if the Convergence Event does not cause instantaneous
          traffic loss on the Preferred Egress Interface (<xref
          target="preferred_egress_interface"></xref>).</t></list></t>

          <t>Measurement Units:

          <list><t>seconds (and fractions), reported with resolution sufficient to
          distinguish between different instants</t></list></t>

          <t>See Also:

          <list><t>Convergence Event, Preferred Egress Interface</t></list></t>
        </section>

        <section anchor="convergence_recovery_instant"
                 title="Convergence Recovery Instant">
          <t>Definition:

          <list><t>The time instant that Full Convergence (<xref
          target="full_convergence"></xref>) has completed.</t></list></t>

          <t>Discussion:

          <list><t>The Full Convergence completed state MUST be maintained for an
          interval of duration equal to the Sustained Convergence Validation
          Time (<xref target="sustained_convergence_validation_time"></xref>)
          in order to validate the Convergence Recovery Instant.</t>

          <t>The Convergence Recovery Instant is observable from the data
          plane as the instant the DUT forwards traffic to
          all destinations over the Next-Best Egress Interface (<xref
          target="next-best_egress_interface"></xref>) without
          impairments.</t></list></t>

          <t>Measurement Units:

          <list><t>seconds (and fractions), reported with resolution sufficient to
          distinguish between different instants</t></list></t>

          <t>See Also:

          <list><t>Sustained Convergence Validation Time, Full Convergence,
          Next-Best Egress Interface</t></list></t>
        </section>

        <section anchor="first_route_convergence_instant"
                 title="First Route Convergence Instant">
          <t>Definition:

          <list><t>The time instant the first route entry completes Route
          Convergence (<xref target="route_convergence"></xref>)</t></list></t>

          <t>Discussion:

          <list><t>Any route may be the first to complete Route Convergence. The
          First Route Convergence Instant is observable from the data plane as
          the instant that the first packet that is not an Impaired Packet
          (<xref target="impaired_packet"></xref>) is received from the
          Next-Best Egress Interface (<xref
          target="next-best_egress_interface"></xref>) or, for the test cases
          with Equal Cost Multi-Path (ECMP) or Parallel Links, the instant
          that the Forwarding Rate on the Next-Best Egress Interface (<xref
          target="next-best_egress_interface"></xref>) starts to increase.</t></list></t>

          <t>Measurement Units:

          <list><t>seconds (and fractions), reported with resolution sufficient to
          distinguish between different instants</t></list></t>

          <t>See Also:

          <list><t>Route Convergence, Impaired Packet, Next-Best Egress
          Interface</t></list></t>
        </section>
      </section>

      <section title="Transitions">
        <section anchor="convergence_event_transition"
                 title="Convergence Event Transition">
          <t>Definition:

          <list><t>A time interval following a Convergence Event (<xref
          target="convergence_event"></xref>) in which the Forwarding Rate on the
          Preferred Egress Interface (<xref
          target="preferred_egress_interface"></xref>) gradually reduces to
          zero.</t></list></t>

          <t>Discussion:

          <list><t>The Forwarding Rate during a Convergence Event Transition may or
          may not decrease linearly.</t>

          <t>The Forwarding Rate observed on the DUT
          egress interface(s) may or may not decrease to zero.</t>

          <t>The Offered Load, the number of routes, and the Packet Sampling
          Interval (<xref target="packet_sampling_interval"></xref>) influence
          the observations of the Convergence Event Transition using the
          Rate-Derived Method (<xref
          target="rate-derived_method"></xref>).</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Convergence Event, Preferred Egress Interface, Packet Sampling
          Interval, Rate-Derived Method</t></list></t>
        </section>

        <section anchor="convergence_recovery_transition"
                 title="Convergence Recovery Transition">
          <t>Definition:

          <list><t>A time interval following the First Route Convergence Instant
          (<xref target="next-best_egress_interface"></xref>) in which
          the Forwarding Rate on the DUT egress interface(s)
          gradually increases to equal to the Offered Load.</t></list></t>

          <t>Discussion:

          <list><t>The Forwarding Rate observed during a Convergence Recovery
          Transition may or may not increase linearly.</t>

          <t>The Offered Load, the number of routes, and the Packet Sampling
          Interval (<xref target="packet_sampling_interval"></xref>) influence
          the observations of the Convergence Recovery Transition using the
          Rate-Derived Method (<xref
          target="rate-derived_method"></xref>).</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>First Route Convergence Instant, Packet Sampling Interval,
          Rate-Derived Method</t></list></t>
        </section>
      </section>

      <section title="Interfaces ">
        <section anchor="local_interface" title="Local Interface">
          <t>Definition:

          <list><t>An interface on the DUT.</t></list></t>

          <t>Discussion:

          <list><t>A failure of a Local Interface indicates that the failure
          occurred directly on the DUT.</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:
<list><t>Remote Interface</t></list></t>
        </section>

        <section anchor="remote_interface" title="Remote Interface">
          <t>Definition:

          <list><t>An interface on a neighboring router that is not directly
          connected to any interface on the DUT.</t></list></t>

          <t>Discussion:

          <list><t>A failure of a Remote Interface indicates that the failure
          occurred on a neighbor router's interface that is not directly
          connected to the DUT.</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:
<list><t>Local Interface</t></list></t>
        </section>

        <section anchor="preferred_egress_interface"
                 title="Preferred Egress Interface">
          <t>Definition:

          <list><t>The outbound interface from the DUT for
          traffic routed to the preferred next-hop.</t></list></t>

          <t>Discussion:

          <list><t>The Preferred Egress Interface is the egress interface prior to a
          Convergence Event (<xref target="convergence_event"></xref>).</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:
<list><t>Convergence Event, Next-Best Egress Interface</t></list></t>
        </section>

        <section anchor="next-best_egress_interface"
                 title="Next-Best Egress Interface">
          <t>Definition:

          <list><t>The outbound interface or set of outbound interfaces in an Equal
          Cost Multipath (ECMP) set or parallel link set of the Device Under
          Test (DUT) for traffic routed to the second-best next-hop.</t></list></t>

          <t>Discussion:

          <list><t>The Next-Best Egress Interface becomes the egress interface after
          a Convergence Event (<xref
          target="next-best_egress_interface"></xref>).</t>

          <t>For the test cases in <xref target="Po11m"></xref> using test
          topologies with an ECMP set or parallel link set, the term Preferred
          Egress Interface refers to all members of the link set.</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:
<list><t>Convergence Event, Preferred Egress Interface</t></list></t>
        </section>
      </section>

      <section title="Benchmarking Methods">
        <section anchor="rate-derived_method" title="Rate-Derived Method">
          <t>Definition:

          <list><t>The method to calculate convergence time benchmarks from
          observing the Forwarding Rate each Packet Sampling Interval (<xref
          target="packet_sampling_interval"></xref>).</t></list></t>

          <t>Discussion:

          <list><t><xref target="fig1"></xref> shows an example of the Forwarding
          Rate change in time during convergence as observed when using the
          Rate-Derived Method.

          <figure align="center" anchor="fig1"
                  title="Rate-Derived Convergence Graph">
            <artwork><![CDATA[
     ^         Traffic                      Convergence
Fwd  |         Start                        Recovery
Rate |         Instant                      Instant
     | Offered  ^                             ^
     | Load --> ----------\                   /-----------
     |                     \                 /<--- Convergence
     |                      \     Packet    /      Recovery
     |       Convergence --->\     Loss    /       Transition
     |       Event            \           /
     |       Transition        \---------/ <-- Max Packet Loss
     |
     +--------------------------------------------------------->
                     ^                   ^                 time
                Convergence         First Route
                Event Instant       Convergence Instant
]]></artwork>
          </figure>
</t>

          <t>To enable collecting statistics of Out-of-Order Packets per flow
          (see <xref target="Th00"></xref>, Section 3), the Offered Load SHOULD
          consist of multiple Streams <xref target="Po06"></xref>, and each
          Stream SHOULD consist of a single flow . If sending multiple
          Streams, the measured traffic statistics for all Streams MUST be
          added together.</t>

          <t>The destination addresses for the Offered Load MUST be
          distributed such that all routes or a statistically representative
          subset of all routes are matched and each of these routes is offered
          an equal share of the Offered Load. It is RECOMMENDED to send
          traffic to all routes, but a statistically representative subset of
          all routes can be used if required.</t>

          <t>At least one packet per route for all routes matched in the
          Offered Load MUST be offered to the DUT within each Packet Sampling
          Interval. For maximum accuracy, the value of the Packet Sampling
          Interval SHOULD be as small as possible, but the presence of IP
          Packet Delay Variation (IPDV) <xref target="De02"></xref> may
          require that a larger Packet Sampling Interval be used.</t>

          <t>The Offered Load, IPDV, the number of routes, and the Packet
          Sampling Interval influence the observations for the Rate-Derived
          Method. It may be difficult to identify the different convergence
          time instants in the Rate-Derived Convergence Graph. For example, it
          is possible that a Convergence Event causes the Forwarding Rate to
          drop to zero, while this may not be observed in the Forwarding Rate
          measurements if the Packet Sampling Interval is too large.</t>

          <t>IPDV causes fluctuations in the number of received packets during
          each Packet Sampling Interval. To account for the presence of IPDV
          in determining if a convergence instant has been reached, Forwarding
          Delay SHOULD be observed during each Packet Sampling Interval. The
          minimum and maximum number of packets expected in a Packet Sampling
          Interval in presence of IPDV can be calculated with Equation 1.

          <figure align="center">
            <artwork><![CDATA[
number of packets expected in a Packet Sampling Interval
  in presence of IP Packet Delay Variation
    = expected number of packets without IP Packet Delay Variation
      +/-( (maxDelay - minDelay) * Offered Load)
where minDelay and maxDelay indicate (respectively) the minimum and
maximum Forwarding Delay of packets received during the Packet 
Sampling Interval
]]></artwork>

            <postamble>Equation 1</postamble>
          </figure>
</t>

          <t>To determine if a convergence instant has been reached, the number
          of packets received in a Packet Sampling Interval is compared with
          the range of expected number of packets calculated in Equation
          1.</t>

          <t>If packets are going over multiple ECMP members and one or more
          of the members has failed, then the number of received packets during
          each Packet Sampling Interval may vary, even excluding presence of
          IPDV. To prevent fluctuation of the number of received packets
          during each Packet Sampling Interval for this reason, the Packet
          Sampling Interval duration SHOULD be a whole multiple of the time
          between two consecutive packets sent to the same destination.</t>

          <t>Metrics measured at the Packet Sampling Interval MUST include
          Forwarding Rate and Impaired Packet count.</t>

          <t>To measure convergence time benchmarks for Convergence Events
          (<xref target="convergence_event"></xref>) that do not cause
          instantaneous traffic loss for all routes at the Convergence Event
          Instant, the Tester SHOULD collect a timestamp of the Convergence
          Event Instant (<xref target="convergence_event_instant"></xref>), and
          the Tester SHOULD observe Forwarding Rate separately on the
          Next-Best Egress Interface.</t>

          <t>Since the Rate-Derived Method does not distinguish between
          individual traffic destinations, it SHOULD NOT be used for any route
          specific measurements. Therefore, the Rate-Derived Method SHOULD NOT be
          used to benchmark Route Loss of Connectivity Period (<xref
          target="route_LoC_period"></xref>).</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:

          <list><t>Packet Sampling Interval, Convergence Event, Convergence Event
          Instant, Next-Best Egress Interface, Route Loss of Connectivity
          Period</t></list></t>
        </section>

        <section anchor="loss-derived_method" title="Loss-Derived Method">
          <t>Definition:

          <list><t>The method to calculate the Loss-Derived Convergence Time (<xref
          target="loss_derived_convergence_time"></xref>) and Loss-Derived
          Loss of Connectivity Period (<xref
          target="loss_derived_LoC_period"></xref>) benchmarks from the amount
          of Impaired Packets (<xref target="impaired_packet"></xref>).</t></list></t>

          <t>Discussion:

          <list><t>To enable collecting statistics of Out-of-Order Packets per flow
          (see <xref target="Th00"></xref>, Section 3), the Offered Load SHOULD
          consist of multiple Streams <xref target="Po06"></xref>, and each
          Stream SHOULD consist of a single flow . If sending multiple
          Streams, the measured traffic statistics for all Streams MUST be
          added together.</t>

          <t>The destination addresses for the Offered Load MUST be
          distributed such that all routes or a statistically representative
          subset of all routes are matched and each of these routes is offered
          an equal share of the Offered Load. It is RECOMMENDED to send
          traffic to all routes, but a statistically representative subset of
          all routes can be used if required.</t>

          <t>Loss-Derived Method SHOULD always be combined with the Rate-Derived
          Method in order to observe Full Convergence completion. The total
          amount of Convergence Packet Loss is collected after Full
          Convergence completion.</t>

          <t>To measure convergence time and loss of connectivity benchmarks
          for Convergence Events that cause instantaneous traffic loss for all
          routes at the Convergence Event Instant, the Tester SHOULD observe
          the Impaired Packet count on all DUT egress interfaces (see Connectivity
          Packet Loss (<xref target="connectivity_packet_loss"></xref>)).</t>

          <t>To measure convergence time benchmarks for Convergence Events
          that do not cause instantaneous traffic loss for all routes at the
          Convergence Event Instant, the Tester SHOULD collect timestamps of
          the Start Traffic Instant and of the Convergence Event Instant, and
          the Tester SHOULD observe Impaired Packet count separately on the
          Next-Best Egress Interface (see Convergence Packet Loss (<xref
          target="convergence_packet_loss"></xref>)).</t>

          <t>Since Loss-Derived Method does not distinguish between traffic
          destinations and the Impaired Packet statistics are only collected
          after Full Convergence completion, this method can only be used to
          measure average values over all routes. For these reasons,
          Loss-Derived Method can only be used to benchmark Loss-Derived
          Convergence Time (<xref
          target="loss_derived_convergence_time"></xref>) and Loss-Derived
          Loss of Connectivity Period (<xref
          target="loss_derived_LoC_period"></xref>).</t>

          <t>Note that the Loss-Derived Method measures an average over all
          routes, including the routes that may not be impacted by the
          Convergence Event, such as routes via non-impacted members of ECMP
          or parallel links.</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:

          <list><t>Loss-Derived Convergence Time, Loss-Derived Loss of Connectivity
          Period, Connectivity Packet Loss, Convergence Packet Loss</t></list></t>
        </section>

        <section anchor="route-specific_loss-derived_method"
                 title="Route-Specific Loss-Derived Method">
          <t>Definition:

          <list><t>The method to calculate the Route-Specific Convergence Time
          (<xref target="route_specific_convergence_time"></xref>) benchmark
          from the amount of Impaired Packets (<xref
          target="impaired_packet"></xref>) during convergence for a specific
          route entry.</t></list></t>

          <t>Discussion:

          <list><t>To benchmark Route-Specific Convergence Time, the Tester provides
          an Offered Load that consists of multiple Streams <xref
          target="Po06"></xref>. Each Stream has a single destination address
          matching a different route entry, for all routes or a statistically
          representative subset of all routes. Each Stream SHOULD consist of a
          single flow (see <xref target="Th00"></xref>, Section 3).
          Convergence Packet Loss is measured for each Stream separately.</t>

          <t>Route-Specific Loss-Derived Method SHOULD always be combined with
          the Rate-Derived Method in order to observe Full Convergence completion.
          The total amount of Convergence Packet Loss (<xref
          target="convergence_packet_loss"></xref>) for each Stream is
          collected after Full Convergence completion.</t>

          <t>Route-Specific Loss-Derived Method is the RECOMMENDED method to
          measure convergence time benchmarks.</t>

          <t>To measure convergence time and loss of connectivity benchmarks
          for Convergence Events that cause instantaneous traffic loss for all
          routes at the Convergence Event Instant, the Tester SHOULD observe
          Impaired Packet count on all DUT egress interfaces (see Connectivity
          Packet Loss (<xref target="connectivity_packet_loss"></xref>)).</t>

          <t>To measure convergence time benchmarks for Convergence Events
          that do not cause instantaneous traffic loss for all routes at the
          Convergence Event Instant, the Tester SHOULD collect timestamps of
          the Start Traffic Instant and of the Convergence Event Instant, and
          the Tester SHOULD observe packet loss separately on the Next-Best
          Egress Interface (see Convergence Packet Loss (<xref
          target="convergence_packet_loss"></xref>)).</t>

          <t>Since Route-Specific Loss-Derived Method uses traffic streams to
          individual routes, it observes Impaired Packet count as it would be
          experienced by a network user. For this reason, Route-Specific
          Loss-Derived Method is RECOMMENDED to measure Route-Specific
          Convergence Time benchmarks and Route Loss of Connectivity Period
          benchmarks.</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:

          <list><t>Route-Specific Convergence Time, Route Loss of Connectivity
          Period, Connectivity Packet Loss, Convergence Packet Loss</t></list></t>
        </section>
      </section>

      <section title="Benchmarks">
        <section anchor="full_convergence_time" title="Full Convergence Time">
          <t>Definition:

          <list><t>The time duration of the period between the Convergence Event
          Instant and the Convergence Recovery Instant as observed using the
          Rate-Derived Method.</t></list></t>

          <t>Discussion:

          <list><t>Using the Rate-Derived Method, Full Convergence Time can be
          calculated as the time difference between the Convergence Event
          Instant and the Convergence Recovery Instant, as shown in Equation
          2.

          <figure align="center">
            <artwork><![CDATA[
Full Convergence Time =
    Convergence Recovery Instant - Convergence Event Instant
]]></artwork>

            <postamble>Equation 2</postamble>
          </figure></t>

          <t>The Convergence Event Instant can be derived from the Forwarding
          Rate observation or from a timestamp collected by the Tester.</t>

          <t>For the test cases described in <xref target="Po11m"></xref>, it
          is expected that Full Convergence Time equals the maximum
          Route-Specific Convergence Time when benchmarking all routes
          in the FIB
          using the Route-Specific Loss-Derived Method.</t>

          <t>It is not possible to measure Full Convergence Time using the
          Loss-Derived Method.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Full Convergence, Rate-Derived Method, Route-Specific
          Loss-Derived Method, Convergence Event Instant, Convergence Recovery
          Instant</t></list></t>
        </section>

        <section anchor="first_route_convergence_time"
                 title="First Route Convergence Time">
          <t>Definition:

          <list><t>The duration of the period between the Convergence Event Instant
          and the First Route Convergence Instant as observed using the
          Rate-Derived Method.</t></list></t>

          <t>Discussion:

          <list><t>Using the Rate-Derived Method, First Route Convergence Time can
          be calculated as the time difference between the Convergence Event
          Instant and the First Route Convergence Instant, as shown with
          Equation 3.

          <figure align="center">
            <artwork><![CDATA[
First Route Convergence Time =
    First Route Convergence Instant - Convergence Event Instant
]]></artwork>

            <postamble>Equation 3</postamble>
          </figure></t>

          <t>The Convergence Event Instant can be derived from the Forwarding
          Rate observation or from a timestamp collected by the Tester.</t>

          <t>For the test cases described in <xref target="Po11m"></xref>, it
          is expected that First Route Convergence Time equals the minimum
          Route-Specific Convergence Time when benchmarking all routes
          in the FIB
          using the Route-Specific Loss-Derived Method.</t>

          <t>It is not possible to measure First Route Convergence Time using
          the Loss-Derived Method.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Rate-Derived Method, Route-Specific Loss-Derived Method,
          Convergence Event Instant, First Route Convergence Instant</t></list></t>
        </section>

        <section anchor="route_specific_convergence_time"
                 title="Route-Specific Convergence Time">
          <t>Definition:

          <list><t>The amount of time it takes for Route Convergence to be completed
          for a specific route, as calculated from the amount of Impaired
          Packets (<xref target="impaired_packet"></xref>) during convergence
          for a single route entry.</t></list></t>

          <t>Discussion:

          <list><t>Route-Specific Convergence Time can only be measured using the
          Route-Specific Loss-Derived Method.</t>

          <t>If the applied Convergence Event causes instantaneous traffic
          loss for all routes at the Convergence Event Instant, Connectivity
          Packet Loss should be observed. Connectivity Packet Loss is the
          combined Impaired Packet count observed on Preferred Egress
          Interface and Next-Best Egress Interface. When benchmarking
          Route-Specific Convergence Time, Connectivity Packet Loss is
          measured, and Equation 4 is applied for each measured route. The
          calculation is equal to Equation 8 in <xref
          target="route_LoC_period"></xref>.

          <figure align="center">
            <artwork><![CDATA[
Route-Specific Convergence Time =
 Connectivity Packet Loss for specific route / Offered Load per route
]]></artwork>

            <postamble>Equation 4</postamble>
          </figure></t>

          <t>If the applied Convergence Event does not cause instantaneous
          traffic loss for all routes at the Convergence Event Instant, then
          the Tester SHOULD collect timestamps of the Traffic Start Instant
          and of the Convergence Event Instant, and the Tester SHOULD observe
          Convergence Packet Loss separately on the Next-Best Egress
          Interface. When benchmarking Route-Specific Convergence Time,
          Convergence Packet Loss is measured, and Equation 5 is applied for
          each measured route.

          <figure align="center">
            <artwork><![CDATA[
Route-Specific Convergence Time =
  Convergence Packet Loss for specific route / Offered Load per route
  - (Convergence Event Instant - Traffic Start Instant)
]]></artwork>

            <postamble>Equation 5</postamble>
          </figure></t>

          <t>The Route-Specific Convergence Time benchmarks enable minimum,
          maximum, average, and median convergence time measurements to be
          reported by comparing the results for the different route entries.
          It also enables benchmarking of convergence time when configuring a
          priority value for the route entry or entries. Since multiple Route-Specific
          Convergence Times can be measured, it is possible to have an array of
          results. The format for reporting Route-Specific Convergence Time is
          provided in <xref target="Po11m"></xref>.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Route-Specific Loss-Derived Method, Convergence Event,
          Convergence Event Instant, Convergence Packet Loss, Connectivity
          Packet Loss, Route Convergence</t></list></t>
        </section>

        <section anchor="loss_derived_convergence_time"
                 title="Loss-Derived Convergence Time">
          <t>Definition:

          <list><t>The average Route Convergence time for all routes in the
          Forwarding Information Base (FIB), as calculated from the amount of
          Impaired Packets (<xref target="impaired_packet"></xref>) during
          convergence.</t></list></t>

          <t>Discussion:

          <list><t>Loss-Derived Convergence Time is measured using the Loss-Derived
          Method.</t>

          <t>If the applied Convergence Event causes instantaneous traffic
          loss for all routes at the Convergence Event Instant, Connectivity
          Packet Loss (<xref target="connectivity_packet_loss"></xref>) should
          be observed. Connectivity Packet Loss is the combined Impaired
          Packet count observed on Preferred Egress Interface and Next-Best
          Egress Interface. When benchmarking Loss-Derived Convergence Time,
          Connectivity Packet Loss is measured, and Equation 6 is applied.

          <figure align="center">
            <artwork><![CDATA[
Loss-Derived Convergence Time =
    Connectivity Packet Loss / Offered Load
]]></artwork>

            <postamble>Equation 6</postamble>
          </figure></t>

          <t>If the applied Convergence Event does not cause instantaneous
          traffic loss for all routes at the Convergence Event Instant, then
          the Tester SHOULD collect timestamps of the Start Traffic Instant
          and of the Convergence Event Instant, and the Tester SHOULD observe
          Convergence Packet Loss (<xref
          target="convergence_packet_loss"></xref>) separately on the
          Next-Best Egress Interface. When benchmarking Loss-Derived
          Convergence Time, Convergence Packet Loss is measured and Equation 7
          is applied.</t></list></t>

          <figure align="center">
            <artwork><![CDATA[
Loss-Derived Convergence Time =
    Convergence Packet Loss / Offered Load
    - (Convergence Event Instant - Traffic Start Instant)
]]></artwork>

            <postamble>Equation 7</postamble>
          </figure>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Convergence Packet Loss, Connectivity Packet Loss, Route
          Convergence, Loss-Derived Method</t></list></t>
        </section>

        <section anchor="route_LoC_period"
                 title="Route Loss of Connectivity Period">
          <t>Definition:

          <list><t>The time duration of packet impairments for a specific route
          entry following a Convergence Event until Full Convergence
          completion, as observed using the Route-Specific Loss-Derived
          Method.</t></list></t>

          <t>Discussion:

          <list><t>In general, the Route Loss of Connectivity Period is not equal to
          the Route-Specific Convergence Time. If the DUT continues to forward
          traffic to the Preferred Egress Interface after the Convergence
          Event is applied, then the Route Loss of Connectivity Period will be
          smaller than the Route-Specific Convergence Time. This is also
          specifically the case after reversing a failure event.</t>

          <t>The Route Loss of Connectivity Period may be equal to the
          Route-Specific Convergence Time if, as a characteristic of the
          Convergence Event, traffic for all routes starts dropping
          instantaneously on the Convergence Event Instant. See discussion in
          <xref target="Po11m"></xref>.</t>

          <t>For the test cases described in <xref target="Po11m"></xref>, the
          Route Loss of Connectivity Period is expected to be a single Loss
          Period <xref target="Ko02"></xref>.</t>

          <t>When benchmarking the Route Loss of Connectivity Period, Connectivity
          Packet Loss is measured for each route, and Equation 8 is applied for
          each measured route entry. The calculation is equal to Equation 4 in
          <xref target="route_specific_convergence_time"></xref>.

          <figure align="center">
            <artwork><![CDATA[
Route Loss of Connectivity Period =
 Connectivity Packet Loss for specific route / Offered Load per route
]]></artwork>

            <postamble>Equation 8</postamble>
          </figure></t>

          <t>Route Loss of Connectivity Period SHOULD be measured using
          Route-Specific Loss-Derived Method.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Route-Specific Convergence Time, Route-Specific Loss-Derived
          Method, Connectivity Packet Loss</t></list></t>
        </section>

        <section anchor="loss_derived_LoC_period"
                 title="Loss-Derived Loss of Connectivity Period">
          <t>Definition:

          <list><t>The average time duration of packet impairments for all routes
          following a Convergence Event until Full Convergence completion, as
          observed using the Loss-Derived Method.</t></list></t>

          <t>Discussion:

          <list><t>In general, the Loss-Derived Loss of Connectivity Period is not
          equal to the Loss-Derived Convergence Time. If the DUT continues to
          forward traffic to the Preferred Egress Interface after the
          Convergence Event is applied, then the Loss-Derived Loss of
          Connectivity Period will be smaller than the Loss-Derived
          Convergence Time. This is also specifically the case after reversing
          a failure event.</t>

          <t>The Loss-Derived Loss of Connectivity Period may be equal to the
          Loss-Derived Convergence Time if, as a characteristic of the
          Convergence Event, traffic for all routes starts dropping
          instantaneously on the Convergence Event Instant. See discussion in
          <xref target="Po11m"></xref>.</t>

          <t>For the test cases described in <xref target="Po11m"></xref>, each
          route's Route Loss of Connectivity Period is expected to be a single
          Loss Period <xref target="Ko02"></xref>.</t>

          <t>When benchmarking the Loss-Derived Loss of Connectivity Period,
          Connectivity Packet Loss is measured for all routes, and Equation 9
          is applied. The calculation is equal to Equation 6 in <xref
          target="loss_derived_convergence_time"></xref>.

          <figure align="center">
            <artwork><![CDATA[
Loss-Derived Loss of Connectivity Period =
   Connectivity Packet Loss for all routes / Offered Load
]]></artwork>
            <postamble>Equation 9</postamble>
          </figure></t>

          <t>The Loss-Derived Loss of Connectivity Period SHOULD be measured using
          the Loss-Derived Method.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Loss-Derived Convergence Time, Loss-Derived Method, Connectivity
          Packet Loss</t></list></t>
        </section>
      </section>

      <section title="Measurement Terms">
        <section anchor="convergence_event" title="Convergence Event">
          <t>Definition:

          <list><t>The occurrence of an event in the network that will result in a
          change in the egress interface of the DUT for
          routed packets.</t></list></t>

          <t>Discussion:

          <list><t>All test cases in <xref target="Po11m"></xref> are defined such
          that a Convergence Event results in a change of egress interface of
          the DUT. Local or remote triggers that cause a route calculation
          that does not result in a change in forwarding are not
          considered.</t></list></t>

          <t>Measurement Units:

	    <list><t>N/A</t></list></t>

          <t>See Also:

	    <list><t>Convergence Event Instant</t></list></t>

	</section>

	<section anchor="convergence_packet_loss" title="Convergence Packet Loss">

	  <t>Definition:

          <list><t>The number of Impaired Packets (<xref
          target="impaired_packet"></xref>) as observed on the Next-Best
          Egress Interface of the DUT during convergence.</t></list></t>
`
          <t>Discussion:

          <list><t>An Impaired Packet is considered as a lost packet.</t></list></t>

          <t>Measurement Units:
<list><t>number of packets</t></list></t>

          <t>See Also:

          <list><t>Connectivity Packet Loss</t></list></t>
        </section>

        <section anchor="connectivity_packet_loss"
                 title="Connectivity Packet Loss">
          <t>Definition:

          <list><t>The number of Impaired Packets observed on all DUT egress
          interfaces during convergence.</t></list></t>

          <t>Discussion:

          <list><t>An Impaired Packet is considered as a lost packet. Connectivity
          Packet Loss is equal to Convergence Packet Loss if the Convergence
          Event causes instantaneous traffic loss for all egress interfaces of
          the DUT except for the Next-Best Egress Interface.</t></list></t>

          <t>Measurement Units:
<list><t>number of packets</t></list></t>

          <t>See Also:

          <list><t>Convergence Packet Loss</t></list></t>
        </section>

        <section anchor="packet_sampling_interval"
                 title="Packet Sampling Interval">
          <t>Definition:

          <list><t>The interval at which the Tester (test equipment) polls to make
          measurements for arriving packets.</t></list></t>

          <t>Discussion:

          <list><t>At least one packet per route for all routes matched in the
          Offered Load MUST be offered to the DUT within the Packet Sampling
          Interval. Metrics measured at the Packet Sampling Interval MUST
          include Forwarding Rate and received packets.</t>

          <t>Packet Sampling Interval can influence the convergence graph as
          observed with the Rate-Derived Method. This is particularly true
          when implementations complete Full Convergence in less time than the
          Packet Sampling Interval. The Convergence Event Instant and First
          Route Convergence Instant may not be easily identifiable, and the
          Rate-Derived Method may produce a larger than actual convergence
          time.</t>

          <t>Using a small Packet Sampling Interval in the presence of IPDV
          <xref target="De02"></xref> may cause fluctuations of the Forwarding
          Rate observation and can prevent correct observation of the
          different convergence time instants.</t>

          <t>The value of the Packet Sampling Interval only contributes to the
          measurement accuracy of the Rate-Derived Method. For maximum
          accuracy, the value for the Packet Sampling Interval SHOULD be as
          small as possible, but the presence of IPDV may enforce using a
          larger Packet Sampling Interval.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:
<list><t>Rate-Derived Method</t></list></t>
        </section>

        <section anchor="sustained_convergence_validation_time"
                 title="Sustained Convergence Validation Time">
          <t>Definition:

          <list><t>The amount of time for which the completion of Full Convergence
          is maintained without additional Impaired Packets being
          observed.</t></list></t>

          <t>Discussion:

          <list><t>The purpose of the Sustained Convergence Validation Time is to
          produce convergence benchmarks protected against fluctuation in
          Forwarding Rate after the completion of Full Convergence is
          observed. The RECOMMENDED Sustained Convergence Validation Time to
          be used is the time to send 5 consecutive packets to each
          destination with a minimum of 5 seconds. The Benchmarking
          Methodology Working Group (BMWG) selected 5 seconds based upon <xref
          target="Br99"></xref>, which recommends waiting 2 seconds for
          residual frames to arrive (this is the Forwarding Delay Threshold
          for the last packet sent) and 5 seconds for DUT restabilization.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Full Convergence, Convergence Recovery Instant</t></list></t>
        </section>

        <section anchor="forwarding_delay_threshold"
                 title="Forwarding Delay Threshold">
          <t>Definition:

          <list><t>The maximum waiting time threshold used to distinguish between
          packets with very long delay and lost packets that will never
          arrive.</t></list></t>

          <t>Discussion:

          <list><t>Applying a Forwarding Delay Threshold allows packets
          with a too large Forwarding Delay to be considered lost, as is required for
          some applications (e.g. voice, video, etc.). The Forwarding Delay
          Threshold is a parameter of the methodology, and it MUST be
          reported. <xref target="Br99"></xref> recommends waiting 2 seconds
          for residual frames to arrive.</t></list></t>

          <t>Measurement Units:
<list><t>seconds (and fractions)</t></list></t>

          <t>See Also:

          <list><t>Convergence Packet Loss, Connectivity Packet Loss</t></list></t>
        </section>
      </section>

      <section title="Miscellaneous Terms">
        <section anchor="impaired_packet" title="Impaired Packet">
          <t>Definition:

          <list><t>A packet that experienced at least one of the following
          impairments: loss, excessive Forwarding Delay, corruption,
          duplication, reordering.</t></list></t>

          <t>Discussion:

          <list><t>A lost packet, a packet with a Forwarding Delay exceeding the
          Forwarding Delay Threshold, a corrupted packet, a Duplicate Packet
          <xref target="Po06"></xref>, and an Out-of-Order Packet <xref
          target="Po06"></xref> are Impaired Packets.</t>

          <t>Packet ordering is observed for each individual flow (see <xref
          target="Th00"></xref>, Section 3) of the Offered Load.</t></list></t>

          <t>Measurement Units:
<list><t>N/A</t></list></t>

          <t>See Also:
<list><t>Forwarding Delay Threshold</t></list></t>
        </section>
      </section>
    </section>

    <section title="Security Considerations">
      <t>Benchmarking activities as described in this memo are limited to
      technology characterization using controlled stimuli in a laboratory
      environment, with dedicated address space and the constraints specified
      in the sections above.</t>

      <t>The benchmarking network topology will be an independent test setup
      and MUST NOT be connected to devices that may forward the test traffic
      into a production network or misroute traffic to the test management
      network.</t>

      <t>Further, benchmarking is performed on a "black-box" basis, relying
      solely on measurements observable external to the DUT/SUT.</t>

      <t>Special capabilities SHOULD NOT exist in the DUT/SUT specifically for
      benchmarking purposes. Any implications for network security arising
      from the DUT/SUT SHOULD be identical in the lab and in production
      networks.</t>
    </section>

    <section title="Acknowledgements">
      <t>Thanks to Sue Hares, Al Morton, Kevin Dubray, Ron Bonica, David Ward,
      Peter De Vriendt, Anuj Dewagan, Adrian Farrel, Stewart Bryant, Francis
      Dupont, and the Benchmarking Methodology Working Group for their
      contributions to this work.</t>
    </section>
  </middle>

  <back>
    <references title="Normative References">

      <reference anchor="Br91">
        <front>
          <title abbrev="Benchmarking Terminology">Benchmarking terminology
          for network interconnection devices</title>

          <author fullname="Scott Bradner" initials="S." surname="Bradner">
            <organization>Harvard University</organization>

            <address>
              <postal>
                <street>33 Kirkland Street</street>

                <street>William James Hall 1232</street>

                <city>Cambridge</city>

                <region>MA</region>

                <code>02138</code>

                <country>US</country>
              </postal>

              <phone>+1 617 495 3864</phone>

              <email>SOB@HARVARD.HARVARD.EDU</email>
            </address>
          </author>

          <date day="1" month="July" year="1991" />

          <abstract>
            <t>This memo discusses and defines a number of terms that are used
            in describing performance benchmarking tests and the results of
            such tests. The terms defined in this memo will be used in
            additional memos to define specific benchmarking tests and the
            suggested format to be used in reporting the results of each of
            the tests. This memo is a product of the Benchmarking Methodology
            Working Group (BMWG) of the Internet Engineering Task Force
            (IETF).</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="1242" />

        <format octets="22817" target="http://www.rfc-editor.org/rfc/rfc1242.txt"
                type="TXT" />
      </reference>

      <reference anchor="Br97">
        <front>
          <title abbrev="RFC Key Words">Key words for use in RFCs to Indicate
          Requirement Levels</title>

          <author fullname="Scott Bradner" initials="S." surname="Bradner">
            <organization>Harvard University</organization>

            <address>
              <postal>
                <street>1350 Mass. Ave.</street>

                <street>Cambridge</street>

                <street>MA 02138</street>
              </postal>

              <phone>- +1 617 495 3864</phone>

              <email>sob@harvard.edu</email>
            </address>
          </author>

          <date month="March" year="1997" />

          <area>General</area>

          <keyword>keyword</keyword>

          <abstract>
            <t>In many standards track documents several words are used to
            signify the requirements in the specification. These words are
            often capitalized. This document defines these words as they
            should be interpreted in IETF documents. Authors who follow these
            guidelines should incorporate this phrase near the beginning of
            their document: <list>
                <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL",
                "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
                "OPTIONAL" in this document are to be interpreted as described
                in RFC 2119.</t>
              </list></t>

            <t>Note that the force of these words is modified by the
            requirement level of the document in which they are used.</t>
          </abstract>
        </front>

        <seriesInfo name="BCP" value="14" />

        <seriesInfo name="RFC" value="2119" />

        <format octets="4723" target="http://www.rfc-editor.org/rfc/rfc2119.txt"
                type="TXT" />

        <format octets="17491"
                target="http://xml.resource.org/public/rfc/html/rfc2119.html"
                type="HTML" />

        <format octets="5777"
                target="http://xml.resource.org/public/rfc/xml/rfc2119.xml"
                type="XML" />
      </reference>



      <reference anchor="Br99">
        <front>
          <title abbrev="Benchmarking Methodology">Benchmarking Methodology
          for Network Interconnect Devices</title>

          <author fullname="Scott Bradner" initials="S." surname="Bradner">
            <organization>Harvard University</organization>

            <address>
              <postal>
                <street>1350 Mass. Ave</street>

                <street>Room 813</street>

                <city>Cambridge</city>

                <region>MA</region>

                <code>02138</code>

                <country>US</country>
              </postal>

              <phone>+1 617 495 3864</phone>

              <facsimile>+1 617 496 8500</facsimile>

              <email>sob@harvard.edu</email>
            </address>
          </author>

          <author fullname="Jim McQuaid" initials="J." surname="McQuaid">
            <organization>NetScout Systems</organization>

            <address>
              <postal>
                <street>4 Westford Tech Park Drive</street>

                <city>Westford</city>

                <region>MA</region>

                <code>01886</code>

                <country>US</country>
              </postal>

              <phone>+1 978 614 4116</phone>

              <facsimile>+1 978 614 4004</facsimile>

              <email>mcquaidj@netscout.com</email>
            </address>
          </author>

          <date month="March" year="1999" />

          <abstract>
            <t>This document discusses and defines a number of tests that may
            be used to describe the performance characteristics of a network
            interconnecting device. In addition to defining the tests this
            document also describes specific formats for reporting the results
            of the tests. Appendix A lists the tests and conditions that we
            believe should be included for specific cases and gives additional
            information about testing practices. Appendix B is a reference
            listing of maximum frame rates to be used with specific frame
            sizes on various media and Appendix C gives some examples of frame
            formats to be used in testing.</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="2544" />

        <format octets="66688" target="http://www.rfc-editor.org/rfc/rfc2544.txt"
                type="TXT" />
      </reference>



      <reference anchor="Ca90">
        <front>
          <title abbrev="OSI ISIS for IP and Dual Environments">Use of OSI
          IS-IS for routing in TCP/IP and dual environments</title>

          <author fullname="Ross Callon" initials="R." surname="Callon">
            <organization>Digital Equipment Corporation (DEC)</organization>

            <address>
              <postal>
                <street>550 King Street</street>

                <street>LKG 1-2/A19</street>

                <city>Littleton</city>

                <region>MA</region>

                <code>01460-1289</code>

                <country>US</country>
              </postal>

              <phone>+1 508 486 5009</phone>
            </address>
          </author>

          <date day="1" month="December" year="1990" />

          <abstract>
            <t>This RFC specifies an integrated routing protocol, based on the
            OSI Intra-Domain IS-IS Routing Protocol, which may be used as an
            interior gateway protocol (IGP) to support TCP/IP as well as OSI.
            This allows a single routing protocol to be used to support pure
            IP environments, pure OSI environments, and dual environments.
            This specification was developed by the IS-IS working group of the
            Internet Engineering Task Force.</t>

            <t>The OSI IS-IS protocol has reached a mature state, and is ready
            for implementation and operational use. The most recent version of
            the OSI IS-IS protocol is contained in ISO DP 10589. The proposed
            standard for using IS-IS for support of TCP/IP will therefore make
            use of this version (with a minor bug correction, as discussed in
            Annex B). We expect that future versions of this proposed standard
            will upgrade to the final International Standard version of IS-IS
            when available.</t>

            <t>Comments should be sent to "isis@merit.edu".</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="1195" />

        <format octets="187866"
                target="http://www.rfc-editor.org/rfc/rfc1195.txt" type="TXT" />

      </reference>



      <reference anchor="Ma98">
        <front>
          <title abbrev="Benchmarking Terminology">Benchmarking Terminology
          for LAN Switching Devices</title>

          <author fullname="Robert Mandeville" initials="R."
                  surname="Mandeville">
            <organization>European Network Laboratories (ENL)</organization>

            <address>
              <postal>
                <street>2</street>

                <street>rue Helene Boucher</street>

                <street>78286 Guyancourt Cedex</street>

                <country>France</country>
              </postal>

              <phone>+ 33 1 39 44 12 05</phone>

              <facsimile>+ 33 1 39 44 12 06</facsimile>

              <email>bob.mandeville@eunet.fr</email>
            </address>
          </author>

          <date month="February" year="1998" />

          <area>Operations</area>

          <keyword>local area network</keyword>

          <keyword>Benchmarking</keyword>
        </front>

        <seriesInfo name="RFC" value="2285" />

        <format octets="43130" target="http://www.rfc-editor.org/rfc/rfc2285.txt"
                type="TXT" />

        <format octets="58104"
                target="http://xml.resource.org/public/rfc/html/rfc2285.html"
                type="HTML" />

        <format octets="42866"
                target="http://xml.resource.org/public/rfc/xml/rfc2285.xml"
                type="XML" />
      </reference>



      <reference anchor="Mo98">
        <front>
          <title>OSPF Version 2</title>

          <author fullname="John Moy" initials="J." surname="Moy">
            <organization>Ascend Communications, Inc.</organization>

            <address>
              <postal>
                <street>1 Robbins Road</street>

                <city>Westford</city>

                <region>MA</region>

                <code>01886</code>
              </postal>

              <phone>978-952-1367</phone>

              <facsimile>978-392-2075</facsimile>

              <email>jmoy@casc.com</email>
            </address>
          </author>

          <date month="April" year="1998" />

          <area>Routing</area>

          <keyword>open shortest-path first protocol</keyword>

          <keyword>routing</keyword>

          <keyword>OSPF</keyword>

          <abstract>
            <t>This memo documents version 2 of the OSPF protocol. OSPF is a
            link-state routing protocol. It is designed to be run internal to
            a single Autonomous System. Each OSPF router maintains an
            identical database describing the Autonomous System's topology.
            From this database, a routing table is calculated by constructing
            a shortest- path tree.</t>

            <t>OSPF recalculates routes quickly in the face of topological
            changes, utilizing a minimum of routing protocol traffic. OSPF
            provides support for equal-cost multipath. An area routing
            capability is provided, enabling an additional level of routing
            protection and a reduction in routing protocol traffic. In
            addition, all OSPF routing protocol exchanges are
            authenticated.</t>

            <t>The differences between this memo and RFC 2178 are explained in
            Appendix G. All differences are backward-compatible in nature.
            Implementations of this memo and of RFCs 2178, 1583, and 1247 will
            interoperate.</t>

            <t>Please send comments to ospf@gated.cornell.edu.</t>
          </abstract>
        </front>

        <seriesInfo name="STD" value="54" />

        <seriesInfo name="RFC" value="2328" />

        <format octets="447367"
                target="http://www.rfc-editor.org/rfc/rfc2328.txt" type="TXT" />

        <format octets="466915"
                target="http://xml.resource.org/public/rfc/html/rfc2328.html"
                type="HTML" />

        <format octets="446761"
                target="http://xml.resource.org/public/rfc/xml/rfc2328.xml"
                type="XML" />
      </reference>



      <reference anchor="Th00">
        <front>
          <title>Multipath Issues in Unicast and Multicast Next-Hop
          Selection</title>

          <author fullname="D. Thaler" initials="D." surname="Thaler">
            <organization></organization>
          </author>

          <author fullname="C. Hopps" initials="C." surname="Hopps">
            <organization></organization>
          </author>

          <date month="November" year="2000" />

          <abstract>
            <t>The effect of multipath routing on a forwarder is that the
            forwarder potentially has several next-hops for any given
            destination and must use some method to choose which next-hop
            should be used for a given data packet. This memo summarizes
            current practices, problems, and solutions. This memo provides
            information for the Internet community.</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="2991" />

        <format octets="17796"
                target="http://www.rfc-editor.org/rfc/rfc2991.txt" type="TXT" />
      </reference>

      <reference anchor="Po06">
        <front>
          <title>Terminology for Benchmarking Network-layer Traffic Control
          Mechanisms</title>

          <author fullname="S. Poretsky" initials="S." surname="Poretsky">
            <organization></organization>
          </author>

          <author fullname="J. Perser" initials="J." surname="Perser">
            <organization></organization>
          </author>

          <author fullname="S. Erramilli" initials="S." surname="Erramilli">
            <organization></organization>
          </author>

          <author fullname="S. Khurana" initials="S." surname="Khurana">
            <organization></organization>
          </author>

          <date month="October" year="2006" />

          <abstract>
            <t>This document describes terminology for the benchmarking of
            devices that implement traffic control using packet classification
            based on defined criteria. The terminology is to be applied to
            measurements made on the data plane to evaluate IP traffic control
            mechanisms. Rules for packet classification can be based on any
            field in the IP header, such as the Differentiated Services Code
            Point (DSCP), or any field in the packet payload, such as port
            number. This memo provides information for the Internet
            community.</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="4689" />

        <format octets="62369" target="http://www.rfc-editor.org/rfc/rfc4689.txt"
                type="TXT" />
      </reference>

<!-- draft-ietf-bmwg-igp-dataplane-conv-meth-23 = RFC 6413 -->
      <reference anchor="Po11m">
        <front>
          <title>Benchmarking Methodology for Link-State IGP Data-Plane Route
          Convergence</title>

          <author fullname="Scott Poretsky" initials="S" surname="Poretsky">
            <organization></organization>
          </author>

          <author fullname="Brent Imhoff" initials="B" surname="Imhoff">
            <organization></organization>
          </author>

          <author fullname="Kris Michielsen" initials="K" surname="Michielsen">
            <organization></organization>
          </author>

          <date month="November" year="2011" />

        </front>

        <seriesInfo name="RFC"
                    value="6413"/>

      </reference>


      <reference anchor="Co08">
        <front>
          <title>OSPF for IPv6</title>

          <author fullname="R. Coltun" initials="R." surname="Coltun">
            <organization></organization>
          </author>

          <author fullname="D. Ferguson" initials="D." surname="Ferguson">
            <organization></organization>
          </author>

          <author fullname="J. Moy" initials="J." surname="Moy">
            <organization></organization>
          </author>

          <author fullname="A. Lindem" initials="A." surname="Lindem">
            <organization></organization>
          </author>

          <date month="July" year="2008" />

          <abstract>
            <t>This document describes the modifications to OSPF to support
            version 6 of the Internet Protocol (IPv6). The fundamental
            mechanisms of OSPF (flooding, Designated Router (DR) election,
            area support, Short Path First (SPF) calculations, etc.) remain
            unchanged. However, some changes have been necessary, either due
            to changes in protocol semantics between IPv4 and IPv6, or simply
            to handle the increased address size of IPv6. These modifications
            will necessitate incrementing the protocol version from version 2
            to version 3. OSPF for IPv6 is also referred to as OSPF version 3
            (OSPFv3).&lt;/t&gt;&lt;t&gt; Changes between OSPF for IPv4, OSPF
            Version 2, and OSPF for IPv6 as described herein include the
            following. Addressing semantics have been removed from OSPF
            packets and the basic Link State Advertisements (LSAs). New LSAs
            have been created to carry IPv6 addresses and prefixes. OSPF now
            runs on a per-link basis rather than on a per-IP-subnet basis.
            Flooding scope for LSAs has been generalized. Authentication has
            been removed from the OSPF protocol and instead relies on IPv6's
            Authentication Header and Encapsulating Security Payload
            (ESP).&lt;/t&gt;&lt;t&gt; Even with larger IPv6 addresses, most
            packets in OSPF for IPv6 are almost as compact as those in OSPF
            for IPv4. Most fields and packet- size limitations present in OSPF
            for IPv4 have been relaxed. In addition, option handling has been
            made more flexible.&lt;/t&gt;&lt;t&gt; All of OSPF for IPv4's
            optional capabilities, including demand circuit support and
            Not-So-Stubby Areas (NSSAs), are also supported in OSPF for IPv6.
            [STANDARDS TRACK]</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="5340" />

        <format octets="225664"
                target="http://www.rfc-editor.org/rfc/rfc5340.txt" type="TXT" />
      </reference>

      <reference anchor="Ho08">
        <front>
          <title>Routing IPv6 with IS-IS</title>

          <author fullname="C. Hopps" initials="C." surname="Hopps">
            <organization></organization>
          </author>

          <date month="October" year="2008" />

          <abstract>
            <t>This document specifies a method for exchanging IPv6 routing
            information using the IS-IS routing protocol. The described method
            utilizes two new TLVs: a reachability TLV and an interface address
            TLV to distribute the necessary IPv6 information throughout a
            routing domain. Using this method, one can route IPv6 along with
            IPv4 and OSI using a single intra-domain routing protocol.
            [STANDARDS TRACK]</t>
          </abstract>
        </front>

        <seriesInfo name="RFC" value="5308" />

        <format octets="13324" target="http://www.rfc-editor.org/rfc/rfc5308.txt"
                type="TXT" />
      </reference>

      <reference anchor="Ko02">
        <front>
          <title>One-way Loss Pattern Sample Metrics</title>

          <author fullname="R. Koodli" initials="R." surname="Koodli">
            <organization></organization>
          </author>

          <author fullname="R. Ravikanth" initials="R." surname="Ravikanth">
            <organization></organization>
          </author>

          <date month="August" year="2002" />
        </front>

        <seriesInfo name="RFC" value="3357" />

        <format octets="30570" target="http://www.rfc-editor.org/rfc/rfc3357.txt"
                type="TXT" />
      </reference>

      <reference anchor="De02">
        <front>
          <title>IP Packet Delay Variation Metric for IP Performance Metrics
          (IPPM)</title>

          <author fullname="C. Demichelis" initials="C." surname="Demichelis">
            <organization></organization>
          </author>

          <author fullname="P. Chimento" initials="P." surname="Chimento">
            <organization></organization>
          </author>

          <date month="November" year="2002" />
        </front>

        <seriesInfo name="RFC" value="3393" />

        <format octets="47731"
                target="http://www.rfc-editor.org/rfc/rfc3393.txt" type="TXT" />
      </reference>
    </references>
  </back>
</rfc>
