<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="3"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc comments="yes"?>
<?rfc inline="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<?rfc rfcedstyle="yes"?>
<rfc submissionType="IETF" category="info" consensus="yes" number="6815"  ipr="trust200902"
     updates="2544">

  <front>
    <title abbrev="RFC 2544 Applicability">Applicability&nbsp;Statement&nbsp;for&nbsp;RFC 2544: Use&nbsp;on&nbsp;Production&nbsp;Networks&nbsp;Considered&nbsp;Harmful</title>

    <author fullname="Scott Bradner" initials="S." surname="Bradner">
      <organization>Harvard University</organization>

      <address>
        <postal>
          <street>1350 Mass. Ave., Room 760</street>

          <city>Cambridge</city>

          <region>MA</region>

          <code>02138</code>

          <country>USA</country>
        </postal>

        <phone>+1 617 495 3864</phone>

 
        <email>sob@harvard.edu</email>

        <uri>http://www.sobco.com</uri>
      </address>
    </author>

    <author fullname="Kevin Dubray" initials="K." surname="Dubray">
      <organization>Juniper Networks</organization>


        <email>kdubray@juniper.net</email>

    </author>

    <author fullname="Jim McQuaid" initials="J." surname="McQuaid">
      <organization>Turnip Video</organization>

      <address>
        <postal>
          <street>6 Cobbleridge Court</street>

          <city>Durham</city>

          <region>North Carolina</region>

          <code>27713</code>

          <country>USA</country>
        </postal>

        <phone>+1 919-619-3220</phone>



        <email>jim@turnipvideo.com</email>

        <uri>www.turnipvideo.com</uri>
      </address>
    </author>

    <author fullname="Al Morton" initials="A." surname="Morton">
      <organization>AT&amp;T Labs</organization>

      <address>
        <postal>
          <street>200 Laurel Avenue South</street>

          <city>Middletown,</city>

          <region>NJ</region>

          <code>07748</code>

          <country>USA</country>
        </postal>

        <phone>+1 732 420 1571</phone>

        <facsimile>+1 732 368 1192</facsimile>

        <email>acmorton@att.com</email>

        <uri>http://home.comcast.net/~acmacm/</uri>
      </address>
    </author>

    <date month="November" year="2012"/>

    <abstract>
      <t>The Benchmarking Methodology Working Group (BMWG) has been developing key
      performance metrics and laboratory test methods since 1990, and
      continues this work at present. The methods described in RFC 2544 are
      intended to generate traffic that overloads network device resources in
      order to assess their capacity. Overload of shared resources would
      likely be harmful to user traffic performance on a production network,
      and there are further negative consequences identified with production
      application of the methods. This memo clarifies the scope of RFC 2544
      and other IETF BMWG benchmarking work for isolated test environments
      only, and it encourages new standards activity for measurement methods
      applicable outside that scope.</t>
    </abstract>
  </front>

  <middle>
    <section title="Introduction">
      <t>This memo clarifies the scope and use of IETF Benchmarking
      Methodology Working Group (BMWG) tests including <xref
      target="RFC2544"/>, which discusses and defines several tests that may
      be used to characterize the performance of a network interconnecting
      device. All readers of this memo must read and fully understand <xref
      target="RFC2544"/>.</t>

      <t>Benchmarking methodologies (beginning with <xref target="RFC2544"/>)
      have always relied on test conditions that can only be produced and
      replicated reliably in the laboratory. These methodologies are not
      appropriate for inclusion in wider specifications such as:</t>

      <t><list style="numbers">
          <t>Validation of telecommunication service configuration, such as
          the Committed Information Rate (CIR).</t>

          <t>Validation of performance metrics in a telecommunication Service
          Level Agreement (SLA), such as frame loss and latency.</t>

          <t>Telecommunication service activation testing, where traffic that
          shares network resources with the test might be adversely
          affected.</t>
        </list>Above, we distinguish "telecommunication service" (where a
      network service provider contracts with a customer to transfer
      information between specified interfaces at different geographic
      locations) from the generic term "service". Below, we use the adjective
      "production" to refer to networks carrying live user traffic. <xref
      target="RFC2544"/> used the term "real-world" to refer to production
      networks and to differentiate them from test networks.</t>

      <t>Although <xref target="RFC2544" /> has been held up as the standard reference for the
      testing listed above, we believe that the actual methods used vary from <xref
      target="RFC2544"/> in significant ways. Since the only citation is to
      <xref target="RFC2544"/>, the modifications are opaque to the standards
      community and to users in general.</t>

      <t>Since applying the test traffic and methods described in <xref
      target="RFC2544"/> on a production network risks causing overload in
      shared resources, there is direct risk of harming user traffic if the
      methods are misused in this way. Therefore, the IETF BMWG developed this
      Applicability Statement for <xref target="RFC2544"/> to directly address
      the situation.</t>

      <section title="Requirements Language">
        <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
        "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
        document are to be interpreted as described in <xref
        target="RFC2119">RFC 2119</xref>.</t>
      </section>
    </section>

    <section title="Scope and Goals">
      <t>This memo clarifies the scope of <xref target="RFC2544"/> with the
      goal of providing guidance to the industry on its applicability, which is
      limited to laboratory testing.</t>
    </section>

    <section title="The Concept of an Isolated Test Environment">
      <t>An Isolated Test Environment (ITE) used with the methods of <xref target="RFC2544"/>
      (as illustrated in Figures 1 through 3 of <xref
      target="RFC2544"/>) has the ability to:<list style="symbols">
          <t>contain the test streams to paths within the desired setup</t>

          <t>prevent non-test traffic from traversing the test setup</t>
        </list></t>

      <t>These features allow unfettered experimentation, while at the same
      time protecting lab equipment management/control LANs and other
      production networks from the unwanted effects of the test traffic.</t>
    </section>

    <section title="Why the Methods of RFC 2544 Are Intended Only for ITE">
      <t>The following sections discuss some of the reasons why <xref
      target="RFC2544"/> methods are applicable only for isolated laboratory
      use, and the consequences of applying these methods outside the lab
      environment.</t>

      <section title="Experimental Control and Accuracy">
        <t>All of the tests described in RFC 2544 require that the tester and
        device under test are the only devices on the networks that are
        transmitting data. The presence of other traffic (unwanted on the ITE
        network) would mean that the specified test conditions have not been
        achieved and flawed results are a likely consequence.</t>

        <t>If any other traffic appears and the amount varies over time, the
        repeatability of any test result will likely depend to some degree on
        the amount and variation of the other traffic.</t>

        <t>The presence of other traffic makes accurate, repeatable, and
        consistent measurements of the performance of the device under test
        very unlikely, since the complete details of test conditions will not
        be reported.</t>

        <t>For example, the RFC 2544 Throughput Test attempts to characterize
        a maximum reliable load; thus, there will be testing above the maximum
        that causes packet/frame loss. Any other sources of traffic on the
        network will cause packet loss to occur at a tester data rate lower
        than the rate that would be achieved without the extra traffic.</t>
      </section>

      <section title="Containing Damage">
        <t><xref target="RFC2544"/> methods, specifically to determine
        Throughput as defined in <xref target="RFC1242"/> and other
        benchmarks, may overload the resources of the device under test, and
        they may cause failure modes in the device under test. Since failures can
        become the root cause of more widespread failure, it is clearly
        desirable to contain all test traffic within the ITE.</t>

        <t>In addition, such testing can have a negative effect on any traffic
        that shares resources with the test stream(s) since, in most cases,
        the traffic load will be close to the capacity of the network
        links.</t>

        <t>Appendix C.2.2 of <xref target="RFC2544"/> (as adjusted by errata)
        gives the private IPv4 address range for testing:</t>

        <t>"...The network addresses 198.18.0.0 through 198.19.255.255 have
        been assigned to the BMWG by the IANA for this purpose. This
        assignment was made to minimize the chance of conflict in case a
        testing device were to be accidentally connected to part of the
        Internet. The specific use of the addresses is detailed below."</t>

        <t>In other words, devices operating on the Internet may be configured
        to discard any traffic they observe in this address range, as it is
        intended for laboratory ITE use only. Thus, if testers using the
        assigned testing address ranges are connected to the Internet and test
        packets are forwarded across the Internet, it is likely that the
        packets will be discarded and the test will not work.</t>

        <t>We note that a range of IPv6 addresses has been assigned to BMWG
        for laboratory test purposes, in <xref target="RFC5180"/> (as amended
        by errata).</t>

        <t>See the Security Considerations section below for further
        considerations on containing damage.</t>
      </section>
    </section>

    <section title="Advisory on RFC 2544 Methods in Production Networks">
      <t>The tests in <xref target="RFC2544"/> were designed to measure the
      performance of network devices, not of networks, and certainly not
      production networks carrying user traffic on shared resources. There
      will be undesirable consequences when applying these methods outside the
      isolated test environment.</t>

      <t>One negative consequence stems from reliance on frame loss as an
      indicator of resource exhaustion in <xref target="RFC2544"/> methods. In
      practice, link-layer and physical-layer errors prevent production
      networks from operating loss-free. The <xref target="RFC2544"/> methods
      will not correctly assess Throughput when loss from uncontrolled sources
      is present. Frame loss occurring at the SLA levels of some networks
      could affect every iteration of Throughput testing (when each step
      includes sufficient packets to experience facility-related loss). Flawed
      results waste the time and resources of the testing service user and of
      the service provider when called to dispute the measurement. These are
      additional examples of harm that compliance with this advisory should
      help to avoid. See <xref target="appendix" /> for an example.</t>

      <t>The methods described in <xref target="RFC2544"/> are intended to
      generate traffic that overloads network device resources in order to
      assess their capacity. Overload of shared resources would likely be
      harmful to user traffic performance on a production network. These tests
      MUST NOT be used on production networks and as discussed above. The
      tests will not produce a reliable or accurate benchmarking result on a
      production network.</t>

      <t><xref target="RFC2544"/> methods have never been validated on a
      network path, even when that path is not part of a production network
      and carrying no other traffic. It is unknown whether the tests can be
      used to measure valid and reliable performance of a multi-device,
      multi-network path. It is possible that some of the tests may prove
      valid in some path scenarios, but that work has not been done or has not
      been shared with the IETF community. Thus, such testing is
      contraindicated by the BMWG.</t>
    </section>

    <section title="Considering Performance Testing in Production Networks">
      <t>The IETF has addressed the problem of production network performance
      measurement by chartering a different working group: IP Performance
      Metrics (IPPM). This working group has developed a set of standard
      metrics to assess the quality, performance, and reliability of Internet
      packet transfer services. These metrics can be measured by network
      operators, end users, or independent testing groups. We note that some
      IPPM metrics differ from RFC 2544 metrics with similar names, and there
      is likely to be confusion if the details are ignored.</t>

      <t>IPPM has not yet standardized methods for raw capacity measurement of
      Internet paths. Such testing needs to adequately consider the strong
      possibility for degradation to any other traffic that may be present due
      to congestion. There are no specific methods proposed for activation of
      a packet transfer service in IPPM at this time. Thus, individuals who
      need to conduct capacity tests on production networks should actively
      participate in standards development to ensure their methods receive
      appropriate industry review and agreement, in the IETF or in alternate
      standards development organizations.</t>

      <t>Other standards may help to fill gaps in telecommunication service
      testing. For example, the IETF has many standards intended to assist
      with network Operations, Administration, and Maintenance (OAM).  ITU-T
      Study Group 12 has a Recommendation on service activation test
      methodology <xref target="Y.1564"/>.</t>

      <t>The world will not spin off axis while waiting for appropriate and
      standardized methods to emerge from the consensus process.</t>
    </section>

    <section title="Security Considerations">
      <t>This Applicability Statement intends to help preserve the security of
      the Internet by clarifying that the scope of <xref target="RFC2544"/>
      and other BMWG memos are all limited to testing in a laboratory ITE,
      thus avoiding accidental Denial-of-Service attacks or congestion due to
      high traffic volume test streams.</t>

      <t>All benchmarking activities are limited to technology
      characterization using controlled stimuli in a laboratory environment,
      with dedicated address space and the other constraints <xref
      target="RFC2544"/>.</t>

      <t>The benchmarking network topology will be an independent test setup
      and MUST NOT be connected to devices that may forward the test traffic
      into a production network or misroute traffic to the test management
      network.</t>

      <t>Further, benchmarking is performed on a "black-box" basis, relying
      solely on measurements observable external to the device under
      test/system under test (DUT/SUT).</t>

      <t>Special capabilities SHOULD NOT exist in the DUT/SUT specifically for
      benchmarking purposes. Any implications for network security arising
      from the DUT/SUT SHOULD be identical in the lab and in production
      networks.</t>
    </section>

    <section title="Acknowledgements">
      <t>Thanks to Matt Zekauskas, Bill Cerveny, Barry Constantine, Curtis
      Villamizar, David Newman, and Adrian Farrel for suggesting improvements
      to this memo.</t>

      <t>Specifically, Al Morton would like to thank his coauthors, who
      constitute the complete set of Chairmen-Emeritus of the BMWG, for
      returning from other pursuits to develop this statement and see it
      through to approval. This has been a rare privilege; one that likely
      will not be matched in the IETF again:<figure>
          <preamble/>

          <artwork><![CDATA[   Scott Bradner   served as Chairman from 1990 to 1993
   Jim McQuaid     served as Chairman from 1993 to 1995
   Kevin Dubray    served as Chairman from 1995 to 2006]]></artwork>

          <postamble/>
        </figure></t>

      <t>It's all about the band.</t>
    </section>


  </middle>

  <back>
    <references title="Normative References">

      <?rfc include='reference.RFC.2544'?>

      <?rfc include='reference.RFC.1242'?>

      <?rfc include="reference.RFC.2119"?>

      <?rfc include="reference.RFC.5180"?>

    </references>

    <references title="Informative References">

      <reference anchor="Y.1564">
        <front>
          <title>Ethernet Service Activation Test Methodology</title>

          <author fullname="" surname="ITU-T Recommendation Y.1564">
            <organization/>
          </author>

          <date month="March" year="2011"/>
        </front>
      </reference>





<!--draft-bb-2544like-production-tests-00; ID Exists -->
<reference anchor='Bryant'>
<front>
<title>RFC2544 Testing in Production Network</title>

<author initials='R' surname='Bonica' fullname='Ronald Bonica'>
    <organization />
</author>

<author initials='S' surname='Bryant' fullname='Stewart Bryant'>
    <organization />
</author>

<date month='October' day='22' year='2012' />

<abstract><t>This document considers the use of RFC2544 type tests in an production network.</t></abstract>

</front>

<seriesInfo name='Work in' value='Progress' />

</reference>

  
    </references>


    <section anchor="appendix" title="Example of RFC 2544 Method Failure in Production Network Measurement">
      <t>This Appendix provides an example illustrating how <xref
      target="RFC2544"/> methods applied on production networks can easily
      produce a form of harm from flawed and misleading results.</t>

      <t>The <xref target="RFC2544"/> Throughput benchmarking method usually
      includes the following steps:</t>
<list style="letters">
      <t>Set the offered traffic level, less than max of the ingress
      link(s).</t>

      <t>Send the test traffic through the device under test (DUT) and
      count all frames successfully transferred.</t>

      <t>If all frames are received, increment traffic level and repeat
      step b.</t>

      <t>If one or more frames are lost, the level is in the DUT-overload
      region (step b may be repeated at a reduced traffic level to more
      exactly determine the maximum rate at which none of the frames are
      dropped by the DUT, defined as the Throughput <xref
      target="RFC1242"/>).</t>

      <t>Report the Throughput values, the x-y of graph of frame size and
      Throughput, and other information in accordance with <xref
      target="RFC2544"/>.</t>
</list>

      <t>In this method, frame loss is the sole indicator of overload and
      therefore the determining factor in the measurement of Throughput using
      the <xref target="RFC2544"/> methodology (even though the results may
      not report frame loss per se).</t>

      <t>Frame loss is subject to many factors in addition to operating above
      the Throughput traffic level. These factors include optical interference
      (which may be due to dirty interfaces, crossover from other signals,
      fiber bend and temperature, etc.) and electrical interference (caused by
      local sources of radio signals, electrical spikes, solar particles,
      etc.). In the laboratory environment many of these issues can be
      carefully controlled through cleaning and isolation. Since <xref
      target="RFC2544"/> methodologies are primarily intended to test devices
      and not paths, the total length of path, the number of interfaces, and
      compound risk of random frame loss can be kept to a minimum.</t>

      <t>In a production network, however, there will be many interfaces and
      many kilometers of path under test. This considerably increases the risk
      of random frame loss.</t>

      <t>The risk of frame loss caused by outside effects is significantly
      higher in production networks, and significantly higher with long paths
      (both those with long physical path lengths, and those with large
      numbers of interfaces in the path). Thus, the risk of falsely low
      reported Throughput using an <xref target="RFC2544"/> methodology test
      is considerably increased in a production network.</t>

      <t>Therefore, to successfully conduct tests with similar objectives to
      those in <xref target="RFC2544"/> in a production network, it will be
      necessary to develop modifications to the methodologies defined in <xref
      target="RFC2544"/> and standards to describe them. See <xref
      target="Bryant"/> for an in-progress effort and <xref target="Y.1564"/>
      for an approved method adapted to production service activation.</t>
    </section>
  </back>
</rfc>
