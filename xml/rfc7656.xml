<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="3"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc category="info" consensus="yes" ipr="trust200902" number="7656"
     submissionType="IETF">
  <front>
    <title abbrev="RTP Taxonomy">A Taxonomy of Semantics and Mechanisms for
    Real&nbhy;Time&nbsp;Transport&nbsp;Protocol&nbsp;(RTP)&nbsp;Sources</title>

    <author fullname="Jonathan Lennox" initials="J." surname="Lennox">
      <organization abbrev="Vidyo">Vidyo, Inc.</organization>

      <address>
        <postal>
          <street>433 Hackensack Avenue</street>

          <street>Seventh Floor</street>

          <city>Hackensack</city>

          <region>NJ</region>

          <code>07601</code>

          <country>United States</country>
        </postal>

        <email>jonathan@vidyo.com</email>
      </address>
    </author>

    <author fullname="Kevin Gross" initials="K." surname="Gross">
      <organization abbrev="AVA">AVA Networks, LLC</organization>

      <address>
        <postal>
          <street/>

          <city>Boulder</city>

          <region>CO</region>

          <country>United States</country>
        </postal>

        <email>kevin.gross@avanw.com</email>
      </address>
    </author>

    <author fullname="Suhas Nandakumar" initials="S." surname="Nandakumar">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street>170 West Tasman Drive</street>

          <city>San Jose</city>

          <region>CA</region>

          <code>95134</code>

          <country>United States</country>
        </postal>

        <email>snandaku@cisco.com</email>
      </address>
    </author>

    <author fullname="Gonzalo Salgueiro" initials="G." surname="Salgueiro">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street>7200-12 Kit Creek Road</street>

          <city>Research Triangle Park</city>

          <region>NC</region>

          <code>27709</code>

          <country>United States</country>
        </postal>

        <email>gsalguei@cisco.com</email>
      </address>
    </author>

    <author fullname="Bo Burman" initials="B." role="editor" surname="Burman">
      <organization>Ericsson</organization>

      <address>
        <postal>
          <street>Kistavagen 25</street>

          <city>SE-16480 Stockholm</city>

          <region/>

          <code/>

          <country>Sweden</country>
        </postal>

        <phone/>

        <facsimile/>

        <email>bo.burman@ericsson.com</email>

        <uri/>
      </address>
    </author>

    <date month="October" year="2015"/>

    <area>Applications and Real-Time (ART)</area>

    <keyword>Taxonomy</keyword>

    <keyword>Terminology</keyword>

    <keyword>RTP</keyword>

    <keyword>Grouping</keyword>

    <abstract>
      <t>The terminology about, and associations among, Real-time Transport
      Protocol (RTP) sources can be complex and somewhat opaque. This document
      describes a number of existing and proposed properties and relationships
      among RTP sources and defines common terminology for discussing protocol
      entities and their relationships.</t>
    </abstract>
  </front>

  <middle>
    <section anchor="introduction" title="Introduction">
      <t>The existing taxonomy of sources in the <xref
      target="RFC3550">Real-time Transport Protocol (RTP)</xref> has
      previously been regarded as confusing and inconsistent. Consequently, a
      deep understanding of how the different terms relate to each other
      becomes a real challenge. Frequently cited examples of this confusion
      are (1) how different protocols that make use of RTP use the same terms
      to signify different things and (2) how the complexities addressed at
      one layer are often glossed over or ignored at another.</t>

      <t>This document improves clarity by reviewing the semantics of various
      aspects of sources in RTP. As an organizing mechanism, it approaches
      this by describing various ways that RTP sources are transformed on
      their way between sender and receiver, and how they can be grouped and
      associated together.</t>

      <t>All non-specific references to ControLling mUltiple streams for
      tElepresence (CLUE) in this document map to <xref target="CLUE-FRAME"/>,
      and all references to Web Real-time Communications (WebRTC) map to <xref
      target="WEBRTC-OVERVIEW"/>.</t>
    </section>

    <section title="Concepts">
      <t>This section defines concepts that serve to identify and name various
      transformations and streams in a given RTP usage. For each concept,
      alternate definitions and usages that coexist today are listed along
      with various characteristics that further describe the concept. These
      concepts are divided into two categories: one is related to the chain of
      streams and transformations that Media can be subject to, and the other
      is for entities involved in the communication.</t>

      <section title="Media Chain">
        <t>In the context of this document, media is a sequence of synthetic
        or <xref target="physical-stimulus">Physical Stimuli</xref> -- for
        example, sound waves, photons, key strokes -- represented in digital
        form. Synthesized media is typically generated directly in the digital
        domain.</t>

        <t>This section contains the concepts that can be involved in taking
        media at a sender side and transporting it to a receiver, which may
        recover a sequence of physical stimuli. This chain of concepts is of
        two main types: streams and transformations. Streams are time-based
        sequences of samples of the physical stimulus in various
        representations, while transformations change the representation of
        the streams in some way.</t>

        <t>The below examples are basic ones, and it is important to keep in
        mind that this conceptual model enables more complex usages. Some will
        be further discussed in later sections of this document. In general
        the following applies to this model:<list style="symbols">
            <t>A transformation may have zero or more inputs and one or more
            outputs.</t>

            <t>A stream is of some type, such as audio, video, real-time text,
            etc.</t>

            <t>A stream has one source transformation and one or more sink
            transformations (with the exception of <xref
            target="physical-stimulus">physical stimulus</xref> that may lack
            source or sink transformation).</t>

            <t>Streams can be forwarded from a transformation output to any
            number of inputs on other transformations that support that
            type.</t>

            <t>If the output of a transformation is sent to multiple
            transformations, those streams will be identical; it takes a
            transformation to make them different.</t>

            <t>There are no formal limitations on how streams are connected to
            transformations.</t>
          </list>It is also important to remember that this is a conceptual
        model. Thus, real-world implementations may look different and have a
        different structure.</t>

        <t>To provide a basic understanding of the relationships in the chain,
        we first introduce the concepts for the <xref
        target="fig-sender-chain">sender side</xref>. This covers physical
        stimuli until media packets are emitted onto the network.</t>

        <figure align="center" anchor="fig-sender-chain"
                title="Sender Side Concepts in the Media Chain">
          <artwork align="center"><![CDATA[    Physical Stimulus
           |
           V
+----------------------+
|     Media Capture    |
+----------------------+
           |
      Raw Stream
           V
+----------------------+
|     Media Source     |<- Synchronization Timing
+----------------------+
           |
     Source Stream
           V
+----------------------+
|    Media Encoder     |
+----------------------+
           |
     Encoded Stream      +------------+
           V             |            V
+----------------------+ | +----------------------+
|   Media Packetizer   | | | RTP-Based Redundancy |
+----------------------+ | +----------------------+
           |             |            |
           +-------------+  Redundancy RTP Stream
    Source RTP Stream                 |
           V                          V
+----------------------+   +----------------------+
|  RTP-Based Security  |   |  RTP-Based Security  |
+----------------------+   +----------------------+
           |                          |
   Secured RTP Stream   Secured Redundancy RTP Stream
           V                          V
+----------------------+   +----------------------+
|   Media Transport    |   |   Media Transport    |
+----------------------+   +----------------------+
]]></artwork>
        </figure>

        <t>In <xref target="fig-sender-chain"/>, we have included a branched
        chain to cover the concepts for using redundancy to improve the
        reliability of the transport. The Media Transport concept is an
        aggregate that is decomposed in <xref target="media-transport"/>.</t>

        <t>In <xref target="fig-receiver-chain"/>, we review a receiver media
        chain matching the sender side, to look at the inverse transformations
        and their attempts to recover identical streams as in the sender
        chain, subject to what may be lossy compression and imperfect media
        transport. Note that the streams out of a reverse transformation, like
        the Source Stream out of the Media Decoder, are in many cases not the
        same as the corresponding ones on the sender side; thus, they are
        prefixed with a "received" to denote a potentially modified version.
        The reason for not being the same lies in the transformations that can
        be of irreversible type. For example, lossy source coding in the Media
        Encoder prevents the source stream out of the media decoder from being
        the same as the one fed into the media encoder. Other reasons include
        packet loss in the media transport transformation that even RTP-based
        Repair, if used, fails to repair.</t>

        <figure align="center" anchor="fig-receiver-chain"
                title="Receiver Side Concepts of the Media Chain">
          <artwork align="center"><![CDATA[+----------------------+   +----------------------+
|   Media Transport    |   |   Media Transport    |
+----------------------+   +----------------------+
  Received |                 Received | Secured
  Secured RTP Stream       Redundancy RTP Stream
           V                          V
+----------------------+   +----------------------+
| RTP-Based Validation |   | RTP-Based Validation |
+----------------------+   +----------------------+
           |                          |
  Received RTP Stream   Received Redundancy RTP Stream
           |                          |
           |     +--------------------+
           V     V
+----------------------+
|   RTP-Based Repair   |
+----------------------+
           |
  Repaired RTP Stream
           V
+----------------------+
|  Media Depacketizer  |
+----------------------+
           |
 Received Encoded Stream
           V
+----------------------+
|    Media Decoder     |
+----------------------+
           |
 Received Source Stream
           V
+----------------------+
|      Media Sink      |--> Synchronization Information
+----------------------+
           |
  Received Raw Stream
           V
+----------------------+
|     Media Render     |
+----------------------+
           |
           V
   Physical Stimulus
]]></artwork>
        </figure>

        <section anchor="physical-stimulus" title="Physical Stimulus">
          <t>The physical stimulus is a physical event in the analog domain
          that can be sampled and converted to digital form by an appropriate
          sensor or transducer. This includes sound waves making up audio,
          photons in a light field, or other excitations or interactions with
          sensors, like keystrokes on a keyboard.</t>
        </section>

        <section anchor="media-capture" title="Media Capture">
          <t>Media Capture is the process of transforming the analog <xref
          target="physical-stimulus">physical stimulus</xref> into digital
          media using an appropriate sensor or transducer. The media capture
          performs a digital sampling of the physical stimulus, usually
          periodically, and outputs this in some representation as a <xref
          target="raw-stream">Raw Stream</xref>. This data is considered
          "media", because it includes data that is periodically sampled or
          made up of a set of timed asynchronous events. The media capture is
          normally instantiated in some type of device, i.e., media capture
          device. Examples of different types of media capturing devices are
          digital cameras, microphones connected to A/D converters, or
          keyboards.</t>

          <t>Characteristics:<list style="symbols">
              <t>A media capture is identified either by hardware/manufacturer
              ID or via a session-scoped device identifier as mandated by the
              application usage.</t>

              <t>A media capture can generate an <xref
              target="encoded-stream">Encoded Stream </xref> if the capture
              device supports such a configuration.</t>

              <t>The nature of the media capture may impose constraints on the
              clock handling in some of the subsequent steps. For example,
              many audio or video capture devices are not completely free in
              selecting the sample rate.</t>
            </list></t>
        </section>

        <section anchor="raw-stream" title="Raw Stream">
          <t>A raw stream is the time progressing stream of digitally sampled
          information, usually periodically sampled and provided by a <xref
          target="media-capture">media capture</xref>. A raw stream can also
          contain synthesized media that may not require any explicit media
          capture, since it is already in an appropriate digital form.</t>
        </section>

        <section anchor="media-source" title="Media Source">
          <t>A Media Source is the logical source of a time progressing
          digital media stream synchronized to a reference clock. This stream
          is called a <xref target="source-stream">source stream</xref>. This
          transformation takes one or more <xref target="raw-stream">raw
          streams</xref> and provides a source stream as output. The output is
          <xref target="sync-context">synchronized with a reference
          clock</xref>, which can be as simple as a system local wall clock or
          as complex as an NTP synchronized clock.</t>

          <t>The output can be of different types. One type is directly
          associated with a particular media capture's raw stream. Others are
          more conceptual sources, like an <xref
          target="fig-media-source-mixer">audio mix of multiple source
          streams</xref>. Mixing multiple streams typically requires that the
          input streams are possible to relate in time, meaning that they have
          to be <xref target="source-stream">source streams</xref> rather than
          raw streams. In <xref target="fig-media-source-mixer"/>, the
          generated source stream is a mix of the three input source
          streams.</t>

          <figure align="center" anchor="fig-media-source-mixer"
                  title="Conceptual Media Source in the form of an Audio Mixer">
            <artwork align="center"><![CDATA[  Source    Source    Source
  Stream    Stream    Stream
    |         |         |
    V         V         V
+--------------------------+
|        Media Source      |<-- Reference Clock
|           Mixer          |
+--------------------------+
              |
              V
        Source Stream
]]></artwork>
          </figure>

          <t>Another possible example of a conceptual media source is a video
          surveillance switch, where the input is multiple source streams from
          different cameras, and the output is one of those source streams
          based on some selection criteria, such as round robin or some video
          activity measure.</t>
        </section>

        <section anchor="source-stream" title="Source Stream">
          <t>A source stream is a stream of digital samples that has been
          synchronized with a reference clock and comes from a particular
          <xref target="media-source">media source</xref>.</t>
        </section>

        <section anchor="media-encoder" title="Media Encoder">
          <t>A media encoder is a transform that is responsible for encoding
          the media data from a <xref target="source-stream">source
          stream</xref> into another representation, usually more compact,
          that is output as an <xref target="encoded-stream">encoded
          stream</xref>.</t>

          <t>The media encoder step commonly includes pre-encoding
          transformations, such as scaling, resampling, etc. The media encoder
          can have a significant number of configuration options that affects
          the properties of the encoded stream. This includes properties such
          as codec, bitrate, start points for decoding, resolution, bandwidth,
          or other fidelity affecting properties.</t>

          <t>Scalable media encoders need special attention as they produce
          multiple outputs that are potentially of different types. As shown
          in <xref target="fig-scalable-media-encoder"/>, a scalable media
          encoder takes one input source stream and encodes it into multiple
          output streams of two different types: at least one encoded stream
          that is independently decodable and one or more <xref
          target="dependent-stream">Dependent Streams</xref>. Decoding
          requires at least one encoded stream and zero or more dependent
          streams. A dependent stream's dependency is one of the grouping
          relations this document discusses further in <xref
          target="layered-multi-stream"/>.</t>

          <figure align="center" anchor="fig-scalable-media-encoder"
                  title="Scalable Media Encoder Input and Outputs">
            <artwork align="center"><![CDATA[       Source Stream
             |
             V
+--------------------------+
|  Scalable Media Encoder  |
+--------------------------+
   |         |   ...    |
   V         V          V
Encoded  Dependent  Dependent
Stream    Stream     Stream
]]></artwork>
          </figure>

          <t>There are also other variants of encoders, like so-called
          Multiple Description Coding (MDC). Such media encoders produce
          multiple independent and thus individually decodable encoded
          streams. However, (logically) combining multiple of these encoded
          streams into a single Received Source Stream during decoding leads
          to an improvement in perceptual reproduced quality when compared to
          decoding a single encoded stream.</t>

          <t>Creating multiple encoded streams from the same source stream,
          where the encoded streams are neither in a scalable nor in an MDC
          relationship is commonly utilized in <xref
          target="SDP-SIMULCAST">simulcast</xref> environments.</t>
        </section>

        <section anchor="encoded-stream" title="Encoded Stream">
          <t>A stream of time synchronized encoded media that can be
          independently decoded.</t>

          <t>Due to temporal dependencies, an encoded stream may have
          limitations in where decoding can be started. These entry points,
          for example, Intra frames from a video encoder, may require
          identification and their generation may be event based or configured
          to occur periodically.</t>
        </section>

        <section anchor="dependent-stream" title="Dependent Stream">
          <t>A stream of time synchronized encoded media fragments that are
          dependent on one or more <xref target="encoded-stream">encoded
          streams</xref> and zero or more dependent streams to be possible to
          decode.</t>

          <t>Each dependent stream has a set of dependencies. These
          dependencies must be understood by the parties in a <xref
          target="multimedia-session">Multimedia Session</xref> that intend to
          use a dependent stream.</t>
        </section>

        <section anchor="media-packetizer" title="Media Packetizer">
          <t>The transformation of taking one or more <xref
          target="encoded-stream">encoded</xref> or <xref
          target="dependent-stream">dependent streams</xref> and putting their
          content into one or more sequences of packets, normally RTP Packets,
          and output <xref target="rtp-stream">Source RTP Streams</xref>. This
          step includes both generating RTP Payloads as well as RTP packets.
          The Media Packetizer then selects which synchronization source(s)
          (SSRC) <xref target="RFC3550"/> and <xref target="rtp-session">RTP
          Sessions</xref> to use.</t>

          <t>The media packetizer can combine multiple encoded or dependent
          streams into one or more RTP Streams:<list style="symbols">
              <t>The media packetizer can use multiple inputs when producing a
              single RTP stream. One such example is <xref
              target="layered-multi-stream">Single RTP stream on a Single
              media Transport (SRST) packetization when using Scalable Video
              Coding (SVC)</xref>.</t>

              <t>The media packetizer can also produce multiple RTP streams,
              for example, when encoded and/or dependent streams are
              distributed over multiple RTP streams. One example of this is
              <xref target="layered-multi-stream">Multiple RTP streams on
              Multiple media Transports (MRMT) packetization when using
              SVC</xref>.</t>
            </list></t>
        </section>

        <section anchor="rtp-stream" title="RTP Stream">
          <t>An RTP stream is a stream of RTP packets containing media data,
          source or redundant. The RTP stream is identified by an SSRC
          belonging to a particular RTP Session. The RTP session is identified
          as discussed in <xref target="rtp-session"/>.</t>

          <t>A source RTP stream is an RTP stream directly related to an <xref
          target="encoded-stream">encoded stream</xref>, targeted for
          transport over RTP without any additional <xref
          target="rtp-based-redundancy">RTP-based Redundancy</xref>
          applied.</t>

          <t>Characteristics:<list style="symbols">
              <t>Each RTP stream is identified by an SSRC <xref
              target="RFC3550"/> that is carried in every RTP and RTP Control
              Protocol (RTCP) packet header. The SSRC is unique in a specific
              RTP session context.</t>

              <t>At any given point in time, an RTP stream can have one and
              only one SSRC, but SSRCs for a given RTP stream can change over
              time. SSRC collision and <xref target="RFC7160">clock rate
              change</xref> are examples of valid reasons to change SSRC for
              an RTP stream. In those cases, the RTP stream itself is not
              changed in any significant way, only the identifying SSRC
              number.</t>

              <t>Each SSRC defines a unique RTP sequence numbering and timing
              space.</t>

              <t>Several RTP streams, each with their own SSRC, may represent
              a single media source.</t>

              <t>Several RTP streams, each with their own SSRC, can be carried
              in a single RTP session.</t>
            </list></t>
        </section>

        <section anchor="rtp-based-redundancy" title="RTP-Based Redundancy">
          <t>RTP-based redundancy is defined here as a transformation that
          generates redundant or repair packets sent out as a <xref
          target="redundancy-rtp-stream">Redundancy RTP Stream</xref> to
          mitigate <xref target="network-transport">Network Transport</xref>
          impairments, like packet loss and delay. Note that this excludes the
          type of redundancy that most suitable <xref
          target="media-encoder">media encoders</xref> may add to the media
          format of the <xref target="encoded-stream">encoded stream</xref>
          that makes it cope better with RTP packet losses.</t>

          <t>The RTP-based redundancy exists in many flavors: they may
          generate independent repair streams that are used in addition to the
          source stream (like <xref target="rtx">RTP Retransmission</xref> and
          some special types of <xref target="fec">Forward Error Correction
          (FEC)</xref>, like <xref target="stream-dup">RTP stream
          duplication</xref>); they may generate a new source stream by
          combining redundancy information with source information (using XOR
          FEC as a <xref target="red">redundancy payload</xref>); or they may
          completely replace the source information with only redundancy
          packets.</t>
        </section>

        <section anchor="redundancy-rtp-stream" title="Redundancy RTP Stream">
          <t>A redundancy RTP stream is an <xref target="rtp-stream">RTP
          stream</xref> that contains no original source data, only redundant
          data, which may either be used as standalone or be combined with one
          or more <xref target="received-rtp-stream">Received RTP
          Streams</xref> to produce <xref
          target="repaired-rtp-stream">Repaired RTP Streams</xref>.</t>
        </section>

        <section anchor="rtp-based-security" title="RTP-Based Security">
          <t>The optional RTP-based Security transformation applies security
          services such as authentication, integrity protection, and
          confidentiality to an input RTP stream, like what is specified in
          <xref target="RFC3711">"The Secure Real-time Transport Protocol
          (SRTP)"</xref>, producing a <xref
          target="secured-rtp-stream">Secured RTP Stream</xref>. Either an
          <xref target="rtp-stream">RTP stream</xref> or a <xref
          target="redundancy-rtp-stream">redundancy RTP stream</xref> can be
          used as input to this transformation.</t>

          <t>In SRTP and the related Secure RTCP (SRTCP), all of the
          above-mentioned security services are optional, except for integrity
          protection of SRTCP, which is mandatory. Also confidentiality
          (encryption) is effectively optional in SRTP, since it is possible
          to use a NULL encryption algorithm. As described in <xref
          target="RFC7201"/>, the strength of SRTP data origin authentication
          depends on the cryptographic transform and key management used. For
          example, in group communication, where it is sometimes possible to
          authenticate group membership but not the actual RTP stream
          sender.</t>

          <t>RTP-based security and RTP-based redundancy can be combined in a
          few different ways. One way is depicted in <xref
          target="fig-sender-chain"/>, where an RTP stream and its
          corresponding redundancy RTP stream are protected by separate
          RTP-based security transforms. In other cases, like when a Media
          Translator is adding FEC in Section 3.2.1.3 of <xref
          target="RTP-TOPOLOGIES"/>, a middlebox can apply RTP-based
          redundancy to an already secured RTP stream instead of a source RTP
          stream. One example of that is depicted in <xref
          target="fig-secure-redundancy"/> below.</t>

          <figure align="center" anchor="fig-secure-redundancy"
                  title="Adding Redundancy to a Secured RTP Stream">
            <artwork align="center"><![CDATA[    Source RTP Stream    +------------+
           V             |            V
+----------------------+ | +----------------------+
|  RTP-Based Security  | | | RTP-Based Redundancy |
+----------------------+ | +----------------------+
           |             |            |
           |             |  Redundancy RTP Stream
           +-------------+            |
           |                          V
           |               +----------------------+
   Secured RTP Stream      |  RTP-Based Security  |
           |               +----------------------+
           |                          |
           |            Secured Redundancy RTP Stream
           V                          V
+----------------------+   +----------------------+
|   Media Transport    |   |   Media Transport    |
+----------------------+   +----------------------+
]]></artwork>
          </figure>

          <t>In this case, the redundancy RTP stream may already have been
          secured for confidentiality (encrypted) by the first RTP-based
          security, and it may therefore not be necessary to apply additional
          confidentiality protection in the second RTP-based security. To
          avoid attacks and negative impact on <xref
          target="rtp-based-repair">RTP-based Repair</xref> and the resulting
          <xref target="repaired-rtp-stream">repaired RTP stream</xref>, it
          is, however, still necessary to have this second RTP-based security
          apply both authentication and integrity protection to the redundancy
          RTP stream.</t>
        </section>

        <section anchor="secured-rtp-stream" title="Secured RTP Stream">
          <t>A secured RTP stream is a source or redundancy RTP stream that is
          protected through <xref target="rtp-based-security">RTP-based
          security </xref> by one or more of the confidentiality, integrity,
          or authentication security services.</t>
        </section>

        <section anchor="media-transport" title="Media Transport">
          <t>A media transport defines the transformation that the <xref
          target="rtp-stream">RTP streams</xref> are subjected to by the
          end-to-end transport from one <xref target="rtp-sender">RTP
          Sender</xref> to one specific <xref target="rtp-receiver">RTP
          Receiver</xref> (an <xref target="rtp-session">RTP session</xref>
          may contain multiple RTP receivers per sender). Each media transport
          is defined by a transport association that is normally identified by
          a 5-tuple (source address, source port, destination address,
          destination port, transport protocol), but a proposal exists for
          sending <xref target="TRANSPORT-MULTIPLEX">multiple transport
          associations on a single 5-tuple</xref>.</t>

          <t>Characteristics:<list style="symbols">
              <t>Media transport transmits RTP streams of RTP packets from a
              source transport address to a destination transport address.</t>

              <t>Each media transport contains only a single RTP session.</t>

              <t>A single RTP session can span multiple media transports.</t>
            </list></t>

          <t>The media transport concept sometimes needs to be decomposed into
          more steps to enable discussion of what a sender emits that gets
          transformed by the network before it is received by the receiver.
          Thus, we provide also this <xref target="fig-media-transport">media
          transport decomposition</xref>.</t>

          <figure align="center" anchor="fig-media-transport"
                  title="Decomposition of Media Transport">
            <artwork align="center"><![CDATA[        RTP Stream
             |
             V
+--------------------------+
|  Media Transport Sender  |
+--------------------------+
             |
      Sent RTP Stream
             V
+--------------------------+
|    Network Transport     |
+--------------------------+
             |
  Transported RTP Stream
             V
+--------------------------+
| Media Transport Receiver |
+--------------------------+
             |
             V
    Received RTP Stream
]]></artwork>
          </figure>
        </section>

        <section anchor="media-transport-sender"
                 title="Media Transport Sender">
          <t>The first transformation within the <xref
          target="media-transport">media transport</xref> is the Media
          Transport Sender. The sending <xref
          target="endpoint">Endpoint</xref> takes an RTP stream and emits the
          packets onto the network using the transport association established
          for this media transport, thereby creating a <xref
          target="sent-rtp-stream">Sent RTP Stream</xref>. In the process, it
          transforms the RTP stream in several ways. First, it generates the
          necessary protocol headers for the transport association, for
          example, IP and UDP headers, thus forming IP/UDP/RTP packets. In
          addition, the media transport sender may queue, intentionally pace,
          or otherwise affect how the packets are emitted onto the network,
          thereby potentially introducing delay and <xref
          target="RFC5481">delay variations</xref> that characterize the sent
          RTP stream.</t>
        </section>

        <section anchor="sent-rtp-stream" title="Sent RTP Stream">
          <t>The sent RTP stream is the RTP stream as entering the first hop
          of the network path to its destination. The sent RTP stream is
          identified using network transport addresses, like the 5-tuple
          (source IP address, source port, destination IP address, destination
          port, and protocol (UDP)) for IP/UDP.</t>
        </section>

        <section anchor="network-transport" title="Network Transport">
          <t>Network transport is the transformation that subjects the <xref
          target="sent-rtp-stream">sent RTP stream</xref> to traveling from
          the source to the destination through the network. This
          transformation can result in loss of some packets, delay, and delay
          variation on a per-packet basis, packet duplication, and packet
          header or data corruption. This transformation produces a <xref
          target="transported-rtp-stream">Transported RTP Stream</xref> at the
          exit of the network path.</t>
        </section>

        <section anchor="transported-rtp-stream"
                 title="Transported RTP Stream">
          <t>The transported RTP stream is the RTP stream that is emitted out
          of the network path at the destination, subjected to the <xref
          target="network-transport">network transport's
          transformation</xref>.</t>
        </section>

        <section anchor="media-transport-receiver"
                 title="Media Transport Receiver">
          <t>The Media Transport Receiver is the receiver <xref
          target="endpoint">endpoint's</xref> transformation of the <xref
          target="transported-rtp-stream">transported RTP stream</xref> by its
          reception process, which results in the <xref
          target="received-rtp-stream">received RTP stream</xref>. This
          transformation includes transport checksums being verified. Sensible
          system designs typically either discard packets with mismatching
          checksums or pass them on while somehow marking them in the
          resulting received RTP stream so to alert subsequent transformations
          about the possible corrupt state. In this context, it is worth
          noting that there is typically some probability for corrupt packets
          to pass through undetected (with a seemingly correct checksum).
          Other transformations can compensate for delay variations in
          receiving a packet on the network interface and providing it to the
          application (de-jitter buffer).</t>
        </section>

        <section anchor="received-secured-rtp-stream"
                 title="Received Secured RTP Stream">
          <t>This is the <xref target="secured-rtp-stream">secured RTP
          stream</xref> resulting from the <xref
          target="media-transport">media transport</xref> aggregate
          transformation.</t>
        </section>

        <section anchor="rtp-based-validation" title="RTP-Based Validation">
          <t>RTP-based Validation is the reverse transformation of <xref
          target="rtp-based-security">RTP-based security</xref>. If this
          transformation fails, the result is either not usable and must be
          discarded or may be usable but cannot be trusted. If the
          transformation succeeds, the result can be a <xref
          target="received-rtp-stream">received RTP stream</xref> or a <xref
          target="received-redundancy-rs">Received Redundancy RTP
          Stream</xref>, depending on what was input to the corresponding
          RTP-based security transformation, but it can also be a <xref
          target="received-secured-rtp-stream">Received Secured RTP
          Stream</xref> in case several RTP-based security transformations
          were applied.</t>
        </section>

        <section anchor="received-rtp-stream" title="Received RTP Stream">
          <t>The received RTP stream is the <xref target="rtp-stream">RTP
          stream</xref> resulting from the <xref
          target="media-transport">media transport's aggregate
          transformation</xref>, i.e., subjected to packet loss, packet
          corruption, packet duplication, delay, and delay variation from
          sender to receiver.</t>
        </section>

        <section anchor="received-redundancy-rs"
                 title="Received Redundancy RTP Stream">
          <t>The received redundancy RTP stream is the <xref
          target="redundancy-rtp-stream">redundancy RTP stream</xref>
          resulting from the media transport's aggregate transformation, i.e.,
          subjected to packet loss, packet corruption, packet duplication,
          delay, and delay variation from sender to receiver.</t>
        </section>

        <section anchor="rtp-based-repair" title="RTP-Based Repair">
          <t>RTP-based repair is a transformation that takes as input zero or
          more <xref target="received-rtp-stream">received RTP streams</xref>
          and one or more <xref target="received-redundancy-rs">received
          redundancy RTP streams</xref> and produces one or more <xref
          target="repaired-rtp-stream">repaired RTP streams</xref> that are as
          close to the corresponding sent <xref target="rtp-stream">source RTP
          streams</xref> as possible, using different RTP-based repair
          methods, for example, the ones referred to in <xref
          target="rtp-based-redundancy">RTP-based redundancy</xref>.</t>
        </section>

        <section anchor="repaired-rtp-stream" title="Repaired RTP Stream">
          <t>A repaired RTP stream is a <xref
          target="received-rtp-stream">received RTP stream</xref> for which
          <xref target="received-redundancy-rs">received redundancy RTP
          stream</xref> information has been used to try to recover the <xref
          target="rtp-stream">source RTP stream</xref> as it was before <xref
          target="media-transport">media transport</xref>.</t>
        </section>

        <section anchor="media-depacketizer" title="Media Depacketizer">
          <t>A Media Depacketizer takes one or more <xref
          target="rtp-stream">RTP streams</xref>, depacketizes them, and
          attempts to reconstitute the <xref target="encoded-stream">encoded
          streams</xref> or <xref target="dependent-stream">dependent
          streams</xref> present in those RTP streams.</t>

          <t>In practical implementations, the media depacketizer and the
          media decoder may be tightly coupled and share information to
          improve or optimize the overall decoding and error concealment
          process. It is, however, not expected that there would be any
          benefit in defining a taxonomy for those detailed (and likely very
          implementation-dependent) steps.</t>
        </section>

        <section anchor="received-encoded-stream"
                 title="Received Encoded Stream">
          <t>The Received Encoded Stream is the received version of an <xref
          target="encoded-stream">encoded stream</xref>.</t>
        </section>

        <section anchor="media-decoder" title="Media Decoder">
          <t>A media decoder is a transformation that is responsible for
          decoding <xref target="encoded-stream">encoded streams</xref> and
          any <xref target="dependent-stream">dependent streams</xref> into a
          <xref target="source-stream">source stream</xref>.</t>

          <t>In practical implementations, the media decoder and the media
          depacketizer may be tightly coupled and share information to improve
          or optimize the overall decoding process in various ways. It is,
          however, not expected that there would be any benefit in defining a
          taxonomy for those detailed (and likely very
          implementation-dependent) steps.</t>

          <t>A media decoder has to deal with any errors in the encoded
          streams that resulted from corruption or failure to repair packet
          losses. Therefore, it commonly is robust to error and losses, and
          includes concealment methods.</t>
        </section>

        <section anchor="received-source-stream"
                 title="Received Source Stream">
          <t>The received source stream is the received version of a <xref
          target="source-stream">source stream</xref>.</t>
        </section>

        <section anchor="media-sink" title="Media Sink">
          <t>The Media Sink receives a <xref target="source-stream">source
          stream</xref> that contains, usually periodically, sampled media
          data together with associated synchronization information. Depending
          on application, this source stream then needs to be transformed into
          a <xref target="raw-stream">raw stream</xref> that is conveyed to
          the <xref target="media-render">Media Render</xref> and synchronized
          with the output from other media sinks. The media sink may also be
          connected with a <xref target="media-source">media source</xref> and
          be used as part of a conceptual media source.</t>

          <t>The media sink can further transform the source stream into a
          representation that is suitable for rendering on the media render as
          defined by the application or system-wide configuration. This
          includes sample scaling, level adjustments, etc.</t>
        </section>

        <section anchor="received-raw-stream" title="Received Raw Stream">
          <t>The Received Raw Stream is the received version of a <xref
          target="raw-stream">raw stream</xref>.</t>
        </section>

        <section anchor="media-render" title="Media Render">
          <t>A media render takes a <xref target="raw-stream">raw
          stream</xref> and converts it into <xref
          target="physical-stimulus">physical stimulus</xref> that a human
          user can perceive. Examples of such devices are screens and D/A
          converters connected to amplifiers and loudspeakers.</t>

          <t>An endpoint can potentially have multiple media renders for each
          media type.</t>
        </section>
      </section>

      <section anchor="communication-entities" title="Communication Entities">
        <t>This section contains concepts for entities involved in the
        communication.</t>

        <figure align="center" anchor="fig-p2p"
                title="Example Point-to-Point Communication Session with Two RTP Sessions">
          <artwork align="center"><![CDATA[
+------------------------------------------------------------+
| Communication Session                                      |
|                                                            |
| +----------------+                      +----------------+ |
| | Participant A  |    +------------+    | Participant B  | |
| |                |    | Multimedia |    |                | |
| | +------------+ |<==>| Session    |<==>| +------------+ | |
| | | Endpoint A | |    |            |    | | Endpoint B | | |
| | |            | |    +------------+    | |            | | |
| | | +----------+-+----------------------+-+----------+ | | |
| | | | RTP      | |                      | |          | | | |
| | | | Session  |-+---Media Transport----+>|          | | | |
| | | | Audio    |<+---Media Transport----+-|          | | | |
| | | |          | |          ^           | |          | | | |
| | | +----------+-+----------|-----------+-+----------+ | | |
| | |            | |          v           | |            | | |
| | |            | | +-----------------+  | |            | | |
| | |            | | | Synchronization |  | |            | | |
| | |            | | |     Context     |  | |            | | |
| | |            | | +-----------------+  | |            | | |
| | |            | |          ^           | |            | | |
| | | +----------+-+----------|-----------+-+----------+ | | |
| | | | RTP      | |          v           | |          | | | |
| | | | Session  |<+---Media Transport----+-|          | | | |
| | | | Video    |-+---Media Transport----+>|          | | | |
| | | |          | |                      | |          | | | |
| | | +----------+-+----------------------+-+----------+ | | |
| | +------------+ |                      | +------------+ | |
| +----------------+                      +----------------+ |
+------------------------------------------------------------+
]]></artwork>
        </figure>

        <t><xref target="fig-p2p"/> shows a high-level example representation
        of a very basic point-to-point Communication Session between
        Participants A and B. It uses two different audio and video RTP
        sessions between A's and B's endpoints, where each RTP session is a
        group communications channel that can potentially carry a number of
        RTP streams. It is using separate media transports for those RTP
        sessions. The multimedia session shared by the participants can, for
        example, be established using SIP (i.e., there is a SIP dialog between
        A and B). The terms used in <xref target="fig-p2p"/> are further
        elaborated in the subsections below.</t>

        <section anchor="endpoint" title="Endpoint">
          <t>An endpoint is a single addressable entity sending or receiving
          RTP packets. It may be decomposed into several functional blocks,
          but as long as it behaves as a single RTP stack entity, it is
          classified as a single "endpoint".</t>

          <t>Characteristics:<list style="symbols">
              <t>Endpoints can be identified in several different ways. While
              RTCP Canonical Names (CNAMEs) <xref target="RFC3550"/> provide a
              globally unique and stable identification mechanism for the
              duration of the communication session (see <xref
              target="comm-session"/>), their validity applies exclusively
              within a <xref target="sync-context">Synchronization
              Context</xref>. Thus, one endpoint can handle multiple CNAMEs,
              each of which can be shared among a set of endpoints belonging
              to the same <xref target="participant">participant</xref>.
              Therefore, mechanisms outside the scope of RTP, such as
              application-defined mechanisms, must be used to provide endpoint
              identification when outside this synchronization context.</t>

              <t>An endpoint can be associated with at most one <xref
              target="participant">participant</xref> at any single point in
              time.</t>

              <t>In some contexts, an endpoint would typically correspond to a
              single "host", for example, a computer using a single network
              interface and being used by a single human user. In other
              contexts, a single "host" can serve multiple participants, in
              which case each participant's endpoint may share properties, for
              example, the IP address part of a transport address.</t>
            </list></t>
        </section>

        <section anchor="rtp-session" title="RTP Session">
          <t>An RTP session is an association among a group of participants
          communicating with RTP. It is a group communications channel that
          can potentially carry a number of RTP streams. Within an RTP
          session, every participant can find metadata and control information
          (over RTCP) about all the RTP streams in the RTP session. The
          bandwidth of the RTCP control channel is shared between all
          participants within an RTP session.</t>

          <t>Characteristics:<list style="symbols">
              <t>An RTP session can carry one or more RTP streams.</t>

              <t>An RTP session shares a single SSRC space as defined in <xref
              target="RFC3550"/>. That is, the endpoints participating in an
              RTP session can see an SSRC identifier transmitted by any of the
              other endpoints. An endpoint can receive an SSRC either as SSRC
              or as a contributing source (CSRC) in RTP and RTCP packets, as
              defined by the endpoints' network interconnection topology.</t>

              <t>An RTP session uses at least two <xref
              target="media-transport">media transports</xref>: one for
              sending and one for receiving. Commonly, the receiving media
              transport is the reverse direction of the media transport used
              for sending. An RTP session may use many media transports and
              these define the session's network interconnection topology.</t>

              <t>A single media transport always carries a single RTP
              session.</t>

              <t>Multiple RTP sessions can be conceptually related, for
              example, originating from or targeted for the same <xref
              target="participant">participant</xref> or <xref
              target="endpoint">endpoint</xref>, or by containing RTP streams
              that are somehow <xref target="relations">related</xref>.</t>
            </list></t>
        </section>

        <section anchor="participant" title="Participant">
          <t>A participant is an entity reachable by a single signaling
          address and is thus related more to the signaling context than to
          the media context.</t>

          <t>Characteristics:<list style="symbols">
              <t>A single signaling-addressable entity, using an
              application-specific signaling address space, for example, a SIP
              URI.</t>

              <t>A participant can participate in several <xref
              target="multimedia-session">multimedia sessions</xref>.</t>

              <t>A participant can be comprised of several associated <xref
              target="endpoint">endpoints</xref>.</t>
            </list></t>
        </section>

        <section anchor="multimedia-session" title="Multimedia Session">
          <t>A multimedia session is an association among a group of <xref
          target="participant">participants</xref> engaged in the
          communication via one or more <xref target="rtp-session">RTP
          sessions</xref>. It defines logical relationships among <xref
          target="media-source">media sources</xref> that appear in multiple
          RTP sessions.</t>

          <t>Characteristics:<list style="symbols">
              <t>A multimedia session can be composed of several RTP sessions
              with potentially multiple RTP streams per RTP session.</t>

              <t>Each participant in a multimedia session can have a multitude
              of media captures and media rendering devices.</t>

              <t>A single multimedia session can contain media from one or
              more <xref target="sync-context">synchronization
              contexts</xref>. An example of that is a multimedia session
              containing one set of audio and video for communication purposes
              belonging to one synchronization context, and another set of
              audio and video for presentation purposes (like playing a video
              file) with a separate synchronization context that has no strong
              timing relationship and need not be strictly synchronized with
              the audio and video used for communication.</t>
            </list></t>
        </section>

        <section anchor="comm-session" title="Communication Session">
          <t>A communication session is an association among two or more <xref
          target="participant">participants</xref> communicating with each
          other via one or more <xref target="multimedia-session">multimedia
          sessions</xref>.</t>

          <t>Characteristics:<list style="symbols">
              <t>Each participant in a communication session is identified via
              an application-specific signaling address.</t>

              <t>A communication session is composed of participants that
              share at least one multimedia session, involving one or more
              parallel RTP sessions with potentially multiple RTP streams per
              RTP session.</t>
            </list></t>

          <t>For example, in a full mesh communication, the communication
          session consists of a set of separate multimedia sessions between
          each pair of participants. Another example is a centralized
          conference, where the communication session consists of a set of
          multimedia sessions between each participant and the conference
          handler.</t>
        </section>
      </section>
    </section>

    <section anchor="relations" title="Concepts of Inter-Relations">
      <t>This section uses the concepts from previous sections and looks at
      different types of relationships among them. These relationships occur
      at different abstraction levels and for different purposes, but the
      reason for the needed relationship at a certain step in the media
      handling chain may exist at another step. For example, the use of <xref
      target="simulcast">simulcast</xref> implies a need to determine
      relations at the RTP stream level, but the underlying reason is that
      multiple media encoders use the same media source, i.e., to be able to
      identify a common media source.</t>

      <section anchor="sync-context" title="Synchronization Context">
        <t>A synchronization context defines a requirement for a strong timing
        relationship between the media sources, typically requiring alignment
        of clock sources. Such a relationship can be identified in multiple
        ways as listed below. A single media source can only belong to a
        single synchronization context, since it is assumed that a single
        media source can only have a single media clock and requiring
        alignment to several synchronization contexts (and thus reference
        clocks) will effectively merge those into a single synchronization
        context.</t>

        <section anchor="cname" title="RTCP CNAME">
          <t><xref target="RFC3550"/> describes inter-media synchronization
          between RTP sessions based on RTCP CNAME, RTP, and timestamps of a
          reference clock formatted using the Network Time Protocol (NTP)
          <xref target="RFC5905"/>. As indicated in <xref target="RFC7273"/>,
          despite using NTP format timestamps, it is not required that the
          clock be synchronized to an NTP source.</t>
        </section>

        <section title="Clock Source Signaling">
          <t><xref target="RFC7273"/> provides a mechanism to signal the clock
          source in the <xref target="RFC4566">Session Description Protocol
          (SDP)</xref> both for the reference clock as well as the media
          clock, thus allowing a synchronization context to be defined beyond
          the one defined by the usage of CNAME source descriptions.</t>
        </section>

        <section title="Implicitly via RtcMediaStream">
          <t>WebRTC defines RtcMediaStream with one or more
          RtcMediaStreamTracks. All tracks in a RtcMediaStream are intended to
          be synchronized when rendered, implying that they must be generated
          such that synchronization is possible.</t>
        </section>

        <section title="Explicitly via SDP Mechanisms">
          <t><xref target="RFC5888">The SDP Grouping Framework</xref> defines
          an <xref target="media-description">"m=" line</xref> grouping
          mechanism called Lip Synchronization (with LS identification-tag)
          for establishing the synchronization requirement across "m=" lines
          when they map to individual sources.</t>

          <t><xref target="RFC5576">Source-Specific Media Attributes in
          SDP</xref> extends the above mechanism when multiple media sources
          are described by a single "m=" line.</t>
        </section>
      </section>

      <section title="Endpoint">
        <t>Some applications require knowledge of what media sources originate
        from a particular <xref target="endpoint">endpoint</xref>. This can
        include such decisions as packet routing between parts of the
        topology, knowing the endpoint origin of the RTP streams.</t>

        <t>In RTP, this identification has been overloaded with the <xref
        target="sync-context">synchronization context</xref> through the usage
        of the RTCP source description <xref target="cname">CNAME</xref>. This
        works for some usages, but in others it breaks down. For example, if
        an endpoint has two sets of media sources that have different
        synchronization contexts, like the audio and video of the human
        participant as well as a set of media sources of audio and video for a
        shared movie, CNAME would not be an appropriate identification for
        that endpoint. Therefore, an endpoint may have multiple CNAMEs. The
        CNAMEs or the media sources themselves can be related to the
        endpoint.</t>
      </section>

      <section title="Participant">
        <t>In communication scenarios, information about which media sources
        originate from which <xref target="participant">participant</xref> is
        commonly needed. One reason is, for example, to enable the application
        to correctly display participant identity information associated with
        the media sources. This association is handled through signaling to
        point at a specific multimedia session where the media sources may be
        explicitly or implicitly tied to a particular endpoint.</t>

        <t>Participant information becomes more problematic when there are
        media sources that are generated through mixing or other conceptual
        processing of raw streams or source streams that originate from
        different participants. These types of media sources can thus have a
        dynamically varying set of origins and participants. RTP contains the
        concept of CSRC that carries information about the previous step
        origin of the included media content on the RTP level.</t>
      </section>

      <section title="RtcMediaStream">
        <t>An RtcMediaStream in WebRTC is an explicit grouping of a set of
        media sources (RtcMediaStreamTracks) that share a common identifier
        and a single <xref target="sync-context">synchronization
        context</xref>.</t>
      </section>

      <section title="Multi-Channel Audio">
        <t>There exist a number of RTP payload formats that can carry
        multi-channel audio, despite the codec being a single-channel (mono)
        encoder. Multi-channel audio can be viewed as multiple media sources
        sharing a common synchronization context. These are independently
        encoded by a media encoder and the different encoded streams are
        packetized together in a time-synchronized way into a single source
        RTP stream, using the used codec's RTP payload format. Examples of
        codecs that support multi-channel audio are <xref
        target="RFC3551">PCMA and PCMU</xref>, <xref target="RFC4867">Adaptive
        Multi Rate (AMR)</xref>, and <xref target="RFC5404">G.719</xref>.</t>
      </section>

      <section anchor="simulcast" title="Simulcast">
        <t>A media source represented as multiple independent encoded streams
        constitutes a <xref target="SDP-SIMULCAST">simulcast</xref> or
        Modification Detection Code (MDC) of that media source. <xref
        target="fig-simulcast"/> shows an example of a media source that is
        encoded into three separate simulcast streams, that are in turn sent
        on the same media transport flow. When using simulcast, the RTP
        streams may be sharing an RTP session and media transport, or be
        separated on different RTP sessions and media transports, or be any
        combination of these two. One major reason to use separate media
        transports is to make use of different quality of service (QoS) for
        the different source RTP streams. Some considerations on separating
        related RTP streams are discussed in <xref
        target="rtp-stream-separation"/>.</t>

        <figure anchor="fig-simulcast"
                title="Example of Media Source Simulcast">
          <artwork align="center"><![CDATA[                        +----------------+
                        |  Media Source  |
                        +----------------+
                 Source Stream  |
         +----------------------+----------------------+
         |                      |                      |
         V                      V                      V
+------------------+   +------------------+   +------------------+
|  Media Encoder   |   |  Media Encoder   |   |  Media Encoder   |
+------------------+   +------------------+   +------------------+
         | Encoded              | Encoded              | Encoded
         | Stream               | Stream               | Stream
         V                      V                      V
+------------------+   +------------------+   +------------------+
| Media Packetizer |   | Media Packetizer |   | Media Packetizer |
+------------------+   +------------------+   +------------------+
         | Source               | Source               | Source
         | RTP                  | RTP                  | RTP
         | Stream               | Stream               | Stream
         +-----------------+    |    +-----------------+
                           |    |    |
                           V    V    V
                      +-------------------+
                      |  Media Transport  |
                      +-------------------+
]]></artwork>
        </figure>

        <t>The simulcast relation between the RTP streams is the common media
        source. In addition, to be able to identify the common media source, a
        receiver of the RTP stream may need to know which configuration or
        encoding goals lay behind the produced encoded stream and its
        properties. This enables selection of the stream that is most useful
        in the application at that moment.</t>
      </section>

      <section anchor="layered-multi-stream" title="Layered Multi-Stream">
        <t>Layered Multi-Stream (LMS) is a mechanism by which different
        portions of a layered or scalable encoding of a source stream are sent
        using separate RTP streams (sometimes in separate RTP sessions). LMSs
        are useful for receiver control of layered media.</t>

        <t>A media source represented as an encoded stream and multiple
        dependent streams constitutes a media source that has layered
        dependencies. <xref target="fig-ddp"/> represents an example of a
        media source that is encoded into three dependent layers, where two
        layers are sent on the same media transport using different RTP
        streams, i.e., SSRCs, and the third layer is sent on a separate media
        transport.</t>

        <figure align="center" anchor="fig-ddp"
                title="Example of Media Source Layered Dependency">
          <artwork align="center"><![CDATA[                     +----------------+
                     |  Media Source  |
                     +----------------+
                             |
                             |
                             V
+---------------------------------------------------------+
|                      Media Encoder                      |
+---------------------------------------------------------+
        |                    |                     |
 Encoded Stream       Dependent Stream     Dependent Stream
        |                    |                     |
        V                    V                     V
+----------------+   +----------------+   +----------------+
|Media Packetizer|   |Media Packetizer|   |Media Packetizer|
+----------------+   +----------------+   +----------------+
        |                    |                     |
   RTP Stream           RTP Stream            RTP Stream
        |                    |                     |
        +------+      +------+                     |
               |      |                            |
               V      V                            V
         +-----------------+              +-----------------+
         | Media Transport |              | Media Transport |
         +-----------------+              +-----------------+
]]></artwork>
        </figure>

        <t>It is sometimes useful to make a distinction between using a single
        media transport or multiple separate media transports when (in both
        cases) using multiple RTP streams to carry encoded streams and
        dependent streams for a media source. Therefore, the following new
        terminology is defined here:</t>

        <t>
          <list style="hanging">
            <t hangText="SRST:">Single RTP stream on a Single media
            Transport</t>

            <t hangText="MRST:">Multiple RTP streams on a Single media
            Transport</t>

            <t hangText="MRMT:">Multiple RTP streams on Multiple media
            Transports</t>
          </list>
        </t>

        <t>MRST and MRMT relations need to identify the common media encoder
        origin for the encoded and dependent streams. When using different RTP
        sessions (MRMT), a single RTP stream per media encoder, and a single
        media source in each RTP session, common SSRCs and CNAMEs can be used
        to identify the common media source. When multiple RTP streams are
        sent from one media encoder in the same RTP session (MRST), then CNAME
        is the only currently specified RTP identifier that can be used. In
        cases where multiple media encoders use multiple media sources sharing
        synchronization context, and thus have a common CNAME, additional
        heuristics or identification need to be applied to create the MRST or
        MRMT relationships between the RTP streams.</t>
      </section>

      <section anchor="stream-dup" title="RTP Stream Duplication">
        <t><xref target="RFC7198">RTP Stream Duplication</xref>, using the
        same or different media transports, and optionally also <xref
        target="RFC7197">delaying the duplicate</xref>, offers a simple way to
        protect media flows from packet loss in some cases (see <xref
        target="fig-duplication"/>). This is a specific type of redundancy.
        All but one <xref target="rtp-stream">source RTP stream</xref> are
        effectively <xref target="redundancy-rtp-stream">redundancy RTP
        streams</xref>, but since both source and redundant RTP streams are
        the same, it does not matter which one is which. This can also be seen
        as a specific type of <xref target="simulcast">simulcast</xref> that
        transmits the same <xref target="encoded-stream">encoded stream</xref>
        multiple times.</t>

        <figure anchor="fig-duplication"
                title="Example of RTP Stream Duplication">
          <artwork align="center"><![CDATA[             +----------------+
             |  Media Source  |
             +----------------+
      Source Stream  |
                     V
             +----------------+
             | Media Encoder  |
             +----------------+
     Encoded Stream  |
         +-----------+-----------+
         |                       |
         V                       V
+------------------+    +------------------+
| Media Packetizer |    | Media Packetizer |
+------------------+    +------------------+
  Source | RTP Stream     Source | RTP Stream
         |                       V
         |                +-------------+
         |                | Delay (opt) |
         |                +-------------+
         |                       |
         +-----------+-----------+
                     |
                     V
           +-------------------+
           |  Media Transport  |
           +-------------------+
]]></artwork>
        </figure>
      </section>

      <section anchor="red" title="Redundancy Format">
        <t><xref target="RFC2198">"RTP Payload for Redundant Audio
        Data"</xref> defines a transport for redundant audio data together
        with primary data in the same RTP payload. The redundant data can be a
        time-delayed version of the primary or another time-delayed encoded
        stream using a different media encoder to encode the same media source
        as the primary, as depicted in <xref target="fig-red-rfc2198"/>.</t>

        <figure align="center" anchor="fig-red-rfc2198"
                title="Concept for Usage of Audio Redundancy with Different Media Encoders">
          <artwork align="center"><![CDATA[+--------------------+
|    Media Source    |
+--------------------+
          |
     Source Stream
          |
          +------------------------+
          |                        |
          V                        V
+--------------------+   +--------------------+
|   Media Encoder    |   |   Media Encoder    |
+--------------------+   +--------------------+
          |                        |
          |                 +------------+
    Encoded Stream          | Time Delay |
          |                 +------------+
          |                        |
          |     +------------------+
          V     V
+--------------------+
|  Media Packetizer  |
+--------------------+
          |
          V
     RTP Stream ]]></artwork>
        </figure>

        <t>The redundancy format is thus providing the necessary meta
        information to correctly relate different parts of the same encoded
        stream. The case <xref target="fig-red-rfc2198">depicted above</xref>
        relates the received source stream fragments coming out of different
        media decoders, to be able to combine them together into a less
        erroneous source stream.</t>
      </section>

      <section anchor="rtx" title="RTP Retransmission">
        <t><xref target="fig-rtx"/> shows an example where a media source's
        source RTP stream is protected by a <xref
        target="RFC4588">retransmission (RTX) flow</xref>. In this example,
        the source RTP stream and the redundancy RTP stream share the same
        media transport.</t>

        <figure align="center" anchor="fig-rtx"
                title="Example of Media Source Retransmission Flows">
          <artwork align="center"><![CDATA[+--------------------+
|    Media Source    |
+--------------------+
          |
          V
+--------------------+
|   Media Encoder    |
+--------------------+
          |                              Retransmission
    Encoded Stream     +--------+     +---- Request
          V            |        V     V
+--------------------+ | +--------------------+
|  Media Packetizer  | | | RTP Retransmission |
+--------------------+ | +--------------------+
          |            |           |
          +------------+  Redundancy RTP Stream
   Source RTP Stream               |
          |                        |
          +---------+    +---------+
                    |    |
                    V    V
             +-----------------+
             | Media Transport |
             +-----------------+
]]></artwork>
        </figure>

        <t>The <xref target="fig-rtx">RTP retransmission example</xref>
        illustrates that this mechanism works purely on the source RTP stream.
        The RTP retransmission transforms buffers from the sent source RTP
        stream and, upon request, emits a retransmitted packet with an extra
        payload header as a redundancy RTP stream. The <xref
        target="RFC4588">RTP retransmission mechanism</xref> is specified such
        that there is a one-to-one relation between the source RTP stream and
        the redundancy RTP stream. Therefore, a redundancy RTP stream needs to
        be associated with its source RTP stream. This is done based on CNAME
        selectors and heuristics to match requested packets for a given source
        RTP stream with the original sequence number in the payload of any new
        redundancy RTP stream using the RTX payload format. In cases where the
        redundancy RTP stream is sent in a different RTP session than the
        source RTP stream, the RTP session relation is signaled by using the
        <xref target="RFC5888">SDP media grouping's</xref> Flow Identification
        (FID identification-tag) semantics.</t>
      </section>

      <section anchor="fec" title="Forward Error Correction">
        <t><xref target="fig-fec"/> shows an example where two media sources'
        source RTP streams are protected by FEC. Source RTP stream A has an
        RTP-based redundancy transformation in FEC encoder 1. This produces a
        redundancy RTP stream 1, that is only related to source RTP stream A.
        The FEC encoder 2, however, takes two source RTP streams (A and B) and
        produces a redundancy RTP stream 2 that protects them jointly, i.e.,
        redundancy RTP stream 2 relates to two source RTP streams (a FEC
        group). FEC decoding, when needed due to packet loss or packet
        corruption at the receiver, requires knowledge about which source RTP
        streams that the FEC encoding was based on.</t>

        <t>In <xref target="fig-fec"/>, all RTP streams are sent on the same
        media transport. This is, however, not the only possible choice.
        Numerous combinations exist for spreading these RTP streams over
        different media transports to achieve the communication application's
        goal.</t>

        <figure align="center" anchor="fig-fec"
                title="Example of FEC Redundancy RTP Streams">
          <artwork align="center"><![CDATA[+--------------------+                +--------------------+
|   Media Source A   |                |   Media Source B   |
+--------------------+                +--------------------+
          |                                     |
          V                                     V
+--------------------+                +--------------------+
|   Media Encoder A  |                |   Media Encoder B  |
+--------------------+                +--------------------+
          |                                     |
    Encoded Stream                        Encoded Stream
          V                                     V
+--------------------+                +--------------------+
| Media Packetizer A |                | Media Packetizer B |
+--------------------+                +--------------------+
          |                                     |
 Source RTP Stream A                   Source RTP Stream B
          |                                     |
    +-----+---------+-------------+         +---+---+
    |               V             V         V       |
    |       +---------------+  +---------------+    |
    |       | FEC Encoder 1 |  | FEC Encoder 2 |    |
    |       +---------------+  +---------------+    |
    |  Redundancy   |     Redundancy   |            |
    |  RTP Stream 1 |     RTP Stream 2 |            |
    V               V                  V            V
+----------------------------------------------------------+
|                    Media Transport                       |
+----------------------------------------------------------+
]]></artwork>
        </figure>

        <t>As FEC encoding exists in various forms, the methods for relating
        FEC redundancy RTP streams with its source information in source RTP
        streams are many. The <xref target="RFC5109">XOR-based RTP FEC payload
        format</xref> is defined in such a way that a redundancy RTP stream
        has a one-to-one relation with a source RTP stream. In fact, the RFC
        requires the redundancy RTP stream to use the same SSRC as the source
        RTP stream. This requires the use of either a separate RTP session or
        the <xref target="RFC2198">redundancy RTP payload format</xref>. The
        underlying relation requirement for this FEC format and a particular
        redundancy RTP stream is to know the related source RTP stream,
        including its SSRC.</t>
      </section>

      <section anchor="rtp-stream-separation" title="RTP Stream Separation">
        <t>RTP streams can be separated exclusively based on their SSRCs, at
        the RTP session level, or at the multimedia session level.</t>

        <t>When the RTP streams that have a relationship are all sent in the
        same RTP session and are uniquely identified based on their SSRC only,
        it is termed an "SSRC-only-based separation". Such streams can be
        related via RTCP CNAME to identify that the streams belong to the same
        endpoint. <xref target="RFC5576">SSRC-based approaches </xref>, when
        used, can explicitly relate various such RTP streams.</t>

        <t>On the other hand, when RTP streams that are related are sent in
        the context of different RTP sessions to achieve separation, it is
        known as "RTP session-based separation". This is commonly used when
        the different RTP streams are intended for different media
        transports.</t>

        <t>Several mechanisms that use RTP session-based separation rely on it
        as a grouping mechanism expressing the relationship. The solutions
        have been based on using the same SSRC value in the different RTP
        sessions to implicitly indicate their relation. That way, no explicit
        RTP level mechanism has been needed; only signaling level relations
        have been established using semantics from <xref target="RFC5888">the
        media-line grouping framework</xref>. Examples of this are <xref
        target="RFC4588">RTP retransmission</xref>, <xref target="RFC6190">SVC
        Multi-Session Transmission</xref>, and <xref
        target="RFC5109">XOR-based FEC</xref>. RTCP CNAME explicitly relates
        RTP streams across different RTP sessions, as explained in the
        previous section. Such a relationship can be used to perform
        inter-media synchronization.</t>

        <t>RTP streams that are related and need to be associated can be part
        of different multimedia sessions, rather than just different RTP
        sessions within the same multimedia session context. This puts further
        demand on the scope of the mechanism(s) and its handling of
        identifiers used for expressing the relationships.</t>
      </section>

      <section title="Multiple RTP Sessions over one Media Transport">
        <t><xref target="TRANSPORT-MULTIPLEX"/> describes a mechanism that
        allows several RTP sessions to be carried over a single underlying
        media transport. The main reasons for doing this are related to the
        impact of using one or more media transports (using a common network
        path or potentially having different ones). The fewer media transports
        used, the less need for NAT/firewall traversal resources and smaller
        number of flow-based QoS.</t>

        <t>However, multiple RTP sessions over one media transport imply that
        a single media transport 5-tuple is not sufficient to express in which
        RTP session context a particular RTP stream exists. Complexities in
        the relationship between media transports and RTP sessions already
        exist as one RTP session contains multiple media transports, e.g.,
        even a Peer-to-Peer RTP Session with RTP/RTCP Multiplexing requires
        two media transports, one in each direction. The relationship between
        media transports and RTP sessions as well as additional levels of
        identifiers needs to be considered in both signaling design and when
        defining terminology.</t>
      </section>
    </section>

    <section anchor="mapping" title="Mapping from Existing Terms">
      <t>This section describes a selected set of terms from some relevant
      RFCs and Internet-Drafts (at the time of writing), using the concepts
      from previous sections.</t>

      <section title="Telepresence Terms">
        <t>The terms in this subsection are used in the context of <xref
        target="CLUE-FRAME">CLUE</xref>. Note that some terms listed in this
        subsection use the same names as terms defined elsewhere in this
        document. Unless explicitly stated (as "RTP Taxonomy") and in this
        subsection, they are to be read as references to the CLUE-specific
        term within this subsection.</t>

        <section title="Audio Capture">
          <t>Defined in CLUE as a <xref target="clue-media-capture">Media
          Capture</xref> for audio. Describes an audio <xref
          target="media-source">media source</xref>.</t>
        </section>

        <section anchor="clue-capture-device" title="Capture Device">
          <t>Defined in CLUE as a device that converts physical input into an
          electrical signal. Identifies a physical entity performing an RTP
          Taxonomy <xref target="media-capture">media capture</xref>
          transformation.</t>
        </section>

        <section anchor="clue-capture-encoding" title="Capture Encoding">
          <t>Defined in CLUE as a specific <xref
          target="clue-encoding">Encoding</xref> of a <xref
          target="clue-media-capture">Media Capture</xref>. Describes an <xref
          target="encoded-stream">encoded stream</xref> related to
          CLUE-specific semantic information.</t>
        </section>

        <section title="Capture Scene">
          <t>Defined in CLUE as a structure representing a spatial region
          captured by one or more <xref target="clue-capture-device">Capture
          Devices</xref>, each capturing media representing a portion of the
          region. Describes a set of spatially related <xref
          target="media-source">media sources</xref>.</t>
        </section>

        <section title="Endpoint">
          <t>Defined in CLUE as a CLUE-capable device that is the logical
          point of final termination through receiving, decoding, and
          rendering and/or initiation through capturing, encoding, and sending
          of media <xref target="clue-stream">Streams</xref>. CLUE further
          defines it to consist of one or more physical devices with source
          and sink media streams, and exactly one <xref
          target="RFC4353">participant</xref>. Describes exactly one <xref
          target="participant">participant</xref> and one or more RTP Taxonomy
          <xref target="endpoint">endpoints</xref>.</t>
        </section>

        <section anchor="clue-encoding" title="Individual Encoding">
          <t>Defined in CLUE as a set of parameters representing a way to
          encode a <xref target="clue-media-capture">Media Capture</xref> to
          become a <xref target="clue-capture-encoding">Capture
          Encoding</xref>. Describes the configuration information needed to
          perform a <xref target="media-encoder">media encoder</xref>
          transformation.</t>
        </section>

        <section anchor="clue-media-capture" title="Media Capture">
          <t>Defined in CLUE as a source of media, such as from one or more
          <xref target="clue-capture-device">Capture Devices</xref> or
          constructed from other media <xref
          target="clue-stream">Streams</xref>. Describes either an RTP
          Taxonomy <xref target="media-capture">media capture</xref> or a
          <xref target="media-source">media source</xref>, depending on in
          which context the term is used.</t>
        </section>

        <section anchor="clue-media-consumer" title="Media Consumer">
          <t>Defined in CLUE as a CLUE-capable device that intends to receive
          <xref target="clue-capture-encoding">Capture Encodings</xref>.
          Describes the media receiving part of an RTP Taxonomy <xref
          target="endpoint">endpoint</xref>.</t>
        </section>

        <section anchor="clue-media-provider" title="Media Provider">
          <t>Defined in CLUE as a CLUE-capable device that intends to send
          <xref target="clue-capture-encoding">Capture Encodings</xref>.
          Describes the media sending part of an RTP Taxonomy <xref
          target="endpoint">endpoint</xref>.</t>
        </section>

        <section anchor="clue-stream" title="Stream">
          <t>Defined in CLUE as a <xref target="clue-capture-encoding">Capture
          Encoding</xref> sent from a <xref target="clue-media-provider">Media
          Provider</xref> to a <xref target="clue-media-consumer">Media
          Consumer</xref> via RTP. Describes an <xref target="rtp-stream">RTP
          stream</xref>.</t>
        </section>

        <section title="Video Capture">
          <t>Defined in CLUE as a <xref target="clue-media-capture">Media
          Capture</xref> for video. Describes a video <xref
          target="media-source">media source</xref>.</t>
        </section>
      </section>

      <section anchor="media-description" title="Media Description">
        <t>A single <xref target="RFC4566">Session Description Protocol
        (SDP)</xref> Media Description (or media block; an "m=" line and all
        subsequent lines until the next "m=" line or the end of the SDP)
        describes part of the necessary configuration and identification
        information needed for a media encoder transformation, as well as the
        necessary configuration and identification information for the media
        decoder to be able to correctly interpret a received RTP stream.</t>

        <t>A media description typically relates to a single media source.
        This is, for example, an explicit restriction in WebRTC. However,
        nothing prevents that the same media description (and same RTP
        session) is reused for <xref target="RTP-MULTI-STREAM">multiple media
        sources</xref>. It can thus describe properties of one or more RTP
        streams, and can also describe properties valid for an entire RTP
        session (via <xref target="RFC5576"/> mechanisms, for example).</t>
      </section>

      <section title="Media Stream">
        <t><xref target="RFC3550">RTP</xref> uses media stream, audio stream,
        video stream, and a stream of (RTP) packets interchangeably, which are
        all RTP streams.</t>
      </section>

      <section title="Multimedia Conference">
        <t>A Multimedia Conference is a <xref
        target="comm-session">communication session</xref> between two or more
        <xref target="participant">participants</xref>, along with the
        software they are using to communicate.</t>
      </section>

      <section title="Multimedia Session">
        <t><xref target="RFC4566">SDP</xref> defines a multimedia session as a
        set of multimedia senders and receivers and the data streams flowing
        from senders to receivers, which would correspond to a set of
        endpoints and the RTP streams that flow between them. In this
        document, <xref target="multimedia-session">multimedia session</xref>
        also assumes those endpoints belong to a set of participants that are
        engaged in communication via a set of related RTP streams.</t>

        <t><xref target="RFC3550">RTP</xref> defines a multimedia session as a
        set of concurrent RTP sessions among a common group of participants.
        For example, a video conference may contain an audio RTP session and a
        video RTP session. This would correspond to a group of participants
        (each using one or more endpoints) sharing a set of concurrent RTP
        sessions. In this document, multimedia session also defines those RTP
        sessions to have some relation and be part of a communication among
        the participants.</t>
      </section>

      <section title="Multipoint Control Unit (MCU)">
        <t>This term is commonly used to describe the central node in any type
        of star <xref target="RTP-TOPOLOGIES">topology</xref> conference. It
        describes a device that includes one <xref
        target="participant">participant</xref> (usually corresponding to a
        so-called conference focus) and one or more related <xref
        target="endpoint">endpoints</xref> (sometimes one or more per
        conference participant).</t>
      </section>

      <section anchor="mst" title="Multi-Session Transmission (MST)">
        <t>One of two transmission modes defined in <xref
        target="RFC6190">H.264-based SVC</xref>, the other mode being <xref
        target="sst">a Single-Session Transmission (SST)</xref>. In
        Multi-Session Transmission (MST), the SVC media encoder sends encoded
        streams and dependent streams distributed across two or more RTP
        streams in one or more RTP sessions. The term "MST" is ambiguous in
        RFC 6190, especially since the name indicates the use of multiple
        "sessions", while MST-type packetization is in fact required whenever
        two or more RTP streams are used for the encoded and dependent
        streams, regardless if those are sent in one or more RTP sessions.
        Corresponds either to <xref target="layered-multi-stream">MRST or
        MRMT</xref> stream relations defined in this document. The <xref
        target="RFC6190">SVC RTP payload RFC</xref> is not particularly
        explicit about how the common <xref target="media-encoder">media
        encoder</xref> relation between <xref target="encoded-stream">encoded
        streams</xref> and <xref target="dependent-stream">dependent
        streams</xref> is to be implemented.</t>
      </section>

      <section title="Recording Device">
        <t>WebRTC specifications use this term to refer to locally available
        entities performing a <xref target="media-capture">media
        capture</xref> transformation.</t>
      </section>

      <section title="RtcMediaStream">
        <t>A WebRTC RtcMediaStream is a set of <xref
        target="media-source">media sources</xref> sharing the same <xref
        target="sync-context">synchronization context</xref>.</t>
      </section>

      <section title="RtcMediaStreamTrack">
        <t>A WebRTC RtcMediaStreamTrack is a <xref target="media-source">media
        source</xref>.</t>
      </section>

      <section anchor="rtp-receiver" title="RTP Receiver">
        <t><xref target="RFC3550">RTP</xref> uses this term, which can be seen
        as the RTP protocol part of a <xref target="media-depacketizer">media
        depacketizer</xref>.</t>
      </section>

      <section anchor="rtp-sender" title="RTP Sender">
        <t><xref target="RFC3550">RTP</xref> uses this term, which can be seen
        as the RTP protocol part of a <xref target="media-packetizer">media
        packetizer</xref>.</t>
      </section>

      <section title="RTP Session">
        <t>Within the context of SDP, a singe "m=" line can map to a single
        <xref target="rtp-session">RTP session</xref>, or multiple "m=" lines
        can map to a single RTP session. The latter is enabled via
        multiplexing schemes such as BUNDLE <xref target="SDP-BUNDLE"/>, for
        example, which allows mapping of multiple "m=" lines to a single RTP
        session.</t>
      </section>

      <section anchor="sst" title="Single-Session Transmission (SST)">
        <t>One of two transmission modes defined in <xref
        target="RFC6190">H.264-based SVC</xref>, the other mode being <xref
        target="mst">MST</xref>. In SST, the SVC media encoder sends <xref
        target="encoded-stream">encoded streams</xref> and <xref
        target="dependent-stream">dependent streams</xref> combined into a
        single <xref target="rtp-stream">RTP stream</xref> in a single <xref
        target="rtp-session">RTP session</xref>, using the SVC RTP payload
        format. The term "SST" is ambiguous in RFC 6190, in that it sometimes
        refers to the use of a single RTP stream, like in sections relating to
        packetization, and sometimes appears to refer to use of a single RTP
        session, like in the context of discussing SDP. Closely corresponds to
        <xref target="layered-multi-stream">SRST</xref> defined in this
        document.</t>
      </section>

      <section title="SSRC">
        <t><xref target="RFC3550">RTP</xref> defines this as "the source of a
        stream of RTP packets", which indicates that an SSRC is not only a
        unique identifier for the <xref target="encoded-stream">encoded
        stream</xref> carried in those packets but is also effectively used as
        a term to denote a <xref target="media-packetizer">media
        packetizer</xref>. In <xref target="RFC3550"/>, it is stated that "a
        synchronization source may change its data format, e.g., audio
        encoding, over time". The related encoded stream data format in an
        <xref target="rtp-stream">RTP stream</xref> is identified by the RTP
        payload type. Changing the data format for an encoded stream
        effectively also changes what <xref target="media-encoder">media
        encoder</xref> is used for the encoded stream. No ambiguity is
        introduced to SSRC as an encoded stream identifier by allowing RTP
        payload type changes, as long as only a single RTP payload type is
        valid for any given RTP Timestamp. This is aligned with and further
        described by Section 5.2 of <xref target="RFC3550"/>.</t>
      </section>
    </section>

    <section anchor="security" title="Security Considerations">
      <t>The purpose of this document is to make clarifications and reduce the
      confusion prevalent in RTP taxonomy because of inconsistent usage by
      multiple technologies and protocols making use of the RTP protocol. It
      does not introduce any new security considerations beyond those already
      well documented in the RTP protocol <xref target="RFC3550"/> and each of
      the many respective specifications of the various protocols making use
      of it.</t>

      <t>Having a well-defined common terminology and understanding of the
      complexities of the RTP architecture will help lead us to better
      standards, avoiding security problems.</t>
    </section>
  </middle>

  <back>
    <references title="Informative References">
      <?rfc include='reference.RFC.2198'?>

      <?rfc include='reference.RFC.3550'?>

      <?rfc include='reference.RFC.3551'?>

      <?rfc include='reference.RFC.3711'?>

      <?rfc include='reference.RFC.4353'?>

      <?rfc include='reference.RFC.4566'?>

      <?rfc include='reference.RFC.4588'?>

      <?rfc include='reference.RFC.4867'?>

      <?rfc include='reference.RFC.5109'?>

      <?rfc include='reference.RFC.5404'?>

      <?rfc include='reference.RFC.5481'?>

      <?rfc include='reference.RFC.5576'?>

      <?rfc include='reference.RFC.5888'?>

      <?rfc include="reference.RFC.5905"?>

      <?rfc include='reference.RFC.6190'?>

      <?rfc include='reference.RFC.7160'?>

      <?rfc include='reference.RFC.7197'?>

      <?rfc include='reference.RFC.7198'?>

      <?rfc include='reference.RFC.7201'?>

      <?rfc include='reference.RFC.7273'?>

      <!--draft-ietf-clue-framework, Active - AD Evaluation -->

      <reference anchor="CLUE-FRAME">
        <front>
          <title>Framework for Telepresence Multi-Streams</title>

          <author fullname="Mark Duckworth" initials="M" surname="Duckworth">
            <organization/>
          </author>

          <author fullname="Andrew Pepperell" initials="A" surname="Pepperell">
            <organization/>
          </author>

          <author fullname="Stephan Wenger" initials="S" surname="Wenger">
            <organization/>
          </author>

          <date month="April" year="2015"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-clue-framework-22"/>
      </reference>

      <!--draft-ietf-rtcweb-overview, Active - I-D exists -->

      <reference anchor="WEBRTC-OVERVIEW">
        <front>
          <title>Overview: Real Time Protocols for Browser-based
          Applications</title>

          <author fullname="Harald Alvestrand" initials="H"
                  surname="Alvestrand">
            <organization/>
          </author>

          <date month="June" year="2015"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-rtcweb-overview-14"/>
      </reference>

      <!--draft-ietf-mmusic-sdp-bundle-negotiation, Active - I-D exists -->

      <reference anchor="SDP-BUNDLE">
        <front>
          <title>Negotiating Media Multiplexing Using the Session Description
          Protocol (SDP)</title>

          <author fullname="Christer Holmberg" initials="C" surname="Holmberg">
            <organization/>
          </author>

          <author fullname="Harald Alvestrand" initials="H"
                  surname="Alvestrand">
            <organization/>
          </author>

          <author fullname="Cullen Jennings" initials="C" surname="Jennings">
            <organization/>
          </author>

          <date month="July" year="2015"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-mmusic-sdp-bundle-negotiation-23"/>
      </reference>

      <!--draft-ietf-avtcore-rtp-multi-stream, Active - I-D exists -->

      <reference anchor="RTP-MULTI-STREAM">
        <front>
          <title>Sending Multiple Media Streams in a Single RTP
          Session</title>

          <author fullname="Jonathan Lennox" initials="J" surname="Lennox">
            <organization/>
          </author>

          <author fullname="Magnus Westerlund" initials="M"
                  surname="Westerlund">
            <organization/>
          </author>

          <author fullname="Wenson Wu" initials="W" surname="Wu">
            <organization/>
          </author>

          <author fullname="Colin Perkins" initials="C" surname="Perkins">
            <organization/>
          </author>

          <date month="July" year="2015"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-avtcore-rtp-multi-stream-08"/>
      </reference>

      <!--draft-ietf-mmusic-sdp-simulcast, Active - I-D exists -->

      <reference anchor="SDP-SIMULCAST">
        <front>
          <title>Using Simulcast in SDP and RTP Sessions</title>

          <author fullname="Bo Burman" initials="B" surname="Burman">
            <organization/>
          </author>

          <author fullname="Magnus Westerlund" initials="M"
                  surname="Westerlund">
            <organization/>
          </author>

          <author fullname="Suhas Nandakumar" initials="S"
                  surname="Nandakumar">
            <organization/>
          </author>

          <author fullname="Mo Zanaty" initials="M" surname="Zanaty">
            <organization/>
          </author>

          <date month="July" year="2015"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-mmusic-sdp-simulcast-01"/>
      </reference>

      <!--draft-westerlund-avtcore-transport-multiplexing, Expired -->

      <reference anchor="TRANSPORT-MULTIPLEX">
        <front>
          <title>Multiplexing Multiple RTP Sessions onto a Single Lower-Layer
          Transport</title>

          <author fullname="Magnus Westerlund" initials="M"
                  surname="Westerlund">
            <organization/>
          </author>

          <author fullname="Colin Perkins" initials="C" surname="Perkins">
            <organization/>
          </author>

          <date month="October" year="2013"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-westerlund-avtcore-transport-multiplexing-07"/>
      </reference>

      <!--draft-ietf-avtcore-rtp-topologies-update, Active - in EDIT state -->

      <reference anchor="RTP-TOPOLOGIES">
        <front>
          <title>RTP Topologies</title>

          <author fullname="Magnus Westerlund" initials="M"
                  surname="Westerlund">
            <organization/>
          </author>

          <author fullname="Stephan Wenger" initials="S" surname="Wenger">
            <organization/>
          </author>

          <date month="July" year="2015"/>
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-avtcore-rtp-topologies-update-10"/>
      </reference>
    </references>

    <section numbered="no" title="Acknowledgements">
      <t>This document has many concepts borrowed from several documents such
      as WebRTC <xref target="WEBRTC-OVERVIEW"/>, CLUE <xref
      target="CLUE-FRAME"/>, and Multiplexing Architecture <xref
      target="TRANSPORT-MULTIPLEX"/>. The authors would like to thank all the
      authors of each of those documents.</t>

      <t>The authors would also like to acknowledge the insights, guidance,
      and contributions of Magnus Westerlund, Roni Even, Paul Kyzivat, Colin
      Perkins, Keith Drage, Harald Alvestrand, Alex Eleftheriadis, Mo Zanaty,
      Stephan Wenger, and Bernard Aboba.</t>
    </section>

    <section numbered="no" title="Contributors">
      <t>Magnus Westerlund has contributed the concept model for the media
      chain using transformations and streams model, including rewriting
      pre-existing concepts into this model and adding missing concepts. The
      first proposal for updating the relationships and the topologies based
      on this concept was also performed by Magnus.</t>
    </section>
  </back>
</rfc>
