<?xml version="1.0" encoding="US-ASCII"?>
<?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>

<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc toc="yes"?>
<?rfc tocdepth="4"?>
<?rfc sortrefs="yes"?>
<?rfc symrefs="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc number="8198" category="std" submissionType="IETF" consensus="yes" ipr="trust200902" updates="4035">
  <front>
    <title abbrev="NSEC/NSEC3 Usage">Aggressive Use of DNSSEC-Validated
    Cache</title>

    <author fullname="Kazunori Fujiwara" initials="K." surname="Fujiwara">
      <organization abbrev="JPRS">Japan Registry Services Co.,
      Ltd.</organization>

      <address>
        <postal>
          <street>Chiyoda First Bldg. East 13F, 3-8-1 Nishi-Kanda</street>

          <city>Chiyoda-ku, Tokyo</city>

          <code>101-0065</code>

          <country>Japan</country>
        </postal>

        <phone>+81 3 5215 8451</phone>

        <email>fujiwara@jprs.co.jp</email>
      </address>
    </author>

    <author fullname="Akira Kato" initials="A." surname="Kato">
      <organization abbrev="Keio/WIDE">Keio University/WIDE
      Project</organization>

      <address>
        <postal>
          <street>Graduate School of Media Design, 4-1-1 Hiyoshi</street>

          <city>Kohoku</city>

          <region>Yokohama</region>

          <code>223-8526</code>

          <country>Japan</country>
        </postal>

        <phone>+81 45 564 2490</phone>

        <email>kato@wide.ad.jp</email>
      </address>
    </author>

    <author fullname="Warren Kumari" initials="W." surname="Kumari">
      <organization>Google</organization>

      <address>
        <postal>
          <street>1600 Amphitheatre Parkway</street>

          <city>Mountain View, CA</city>

          <code>94043</code>

          <country>United States of America</country>
        </postal>

        <email>warren@kumari.net</email>
      </address>
    </author>

    <date month="July" year="2017"/>

    <area>operations</area>

    <abstract>
      <t>The DNS relies upon caching to scale; however, the cache lookup
      generally requires an exact match. This document specifies the use of
      NSEC/NSEC3 resource records to allow DNSSEC-validating resolvers to
      generate negative answers within a range and positive answers from
      wildcards. 

This increases performance, decreases latency, decreases
      resource utilization on both authoritative and recursive servers, and
      increases privacy. Also, it may help increase resilience to certain
      DoS attacks in some circumstances.</t>

      <t>This document updates RFC 4035 by allowing validating resolvers to
      generate negative answers based upon NSEC/NSEC3 records and positive
      answers in the presence of wildcards.</t>

    </abstract>
  </front>

  <middle>
    <section anchor="introduction" title="Introduction">
      <t>A DNS negative cache exists, and is used to cache the fact that an
      RRset does not exist. This method of negative caching requires exact
      matching; this leads to unnecessary additional lookups, increases
      latency, leads to extra resource utilization on both authoritative and
      recursive servers, and decreases privacy by leaking queries.</t>

      <t>This document updates RFC 4035 to allow resolvers to use NSEC/NSEC3
      resource records to synthesize negative answers from the information
      they have in the cache. This allows validating resolvers to respond with
      a negative answer immediately if the name in question falls into a range
      expressed by an NSEC/NSEC3 resource record already in the cache. It also
      allows the synthesis of positive answers in the presence of wildcard
      records.</t>

      <t>Aggressive negative caching was first proposed in Section 6 of DNSSEC
      Lookaside Validation (DLV) <xref target="RFC5074"/> in order to find
      covering NSEC records efficiently.</t>

      <t><xref target="RFC8020"/> and <xref
      target="RES-IMPROVE"/> propose steps to using NXDOMAIN
      information for more effective caching. This document takes this
      technique further.</t>
    </section>

    <section anchor="terminology" title="Terminology">
  <t> The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL
   NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED",
   "MAY", and "OPTIONAL" in this document are to be interpreted as
   described in BCP 14 <xref target="RFC2119"/> <xref target="RFC8174"/> when, and only when, they
   appear in all capitals, as shown here.</t>

      <t>Many of the specialized terms used in this document are defined in
      DNS Terminology <xref target="RFC7719"/>.</t>

      <t>The key words "source of synthesis" in this document are to be
      interpreted as described in <xref target="RFC4592"/>.</t>
    </section>

    <section anchor="problem-statement" title="Problem Statement">
      <t>The DNS negative cache caches negative (non-existent) information,
      and requires an exact match in most instances <xref
      target="RFC2308"/>.</t>

      <t>Assume that the (DNSSEC-signed) "example.com" zone contains:</t>

      <t><figure>
          <artwork><![CDATA[
albatross.example.com. IN A 192.0.2.1
elephant.example.com.  IN A 192.0.2.2
zebra.example.com.     IN A 192.0.2.3
]]></artwork>
        </figure></t>

      <t>If a validating resolver receives a query for cat.example.com, it
      contacts its resolver (which may be itself) to query the example.com
      servers and will get back an NSEC record stating that there are no
      records (alphabetically) between albatross and elephant, or an NSEC3
      record stating there is nothing between two hashed names. The resolver
      then knows that cat.example.com does not exist; however, it does not use
      the fact that the proof covers a range (albatross to elephant) to
      suppress queries for other labels that fall within this range. This
      means that if the validating resolver gets a query for ball.example.com
      (or dog.example.com) it will once again go off and query the example.com
      servers for these names.</t>

      <t>Apart from wasting bandwidth, this also wastes resources on the
      recursive server (it needs to keep state for outstanding queries),
      wastes resources on the authoritative server (it has to answer
      additional questions), increases latency (the end user has to wait
      longer than necessary to get back an NXDOMAIN answer), can be used by
      attackers to cause a DoS, and also has
      privacy implications (e.g., typos leak out further than necessary).</t>

      <t>Another example: assume that the (DNSSEC-signed) "example.org" zone
      contains:</t>

      <t><figure>
          <artwork><![CDATA[
avocado.example.org.   IN A 192.0.2.1
*.example.org.         IN A 192.0.2.2
zucchini.example.org.  IN A 192.0.2.3
]]></artwork>
        </figure></t>

      <t>If a query is received for leek.example.org, the system contacts its
      resolver (which may be itself) to query the example.org servers and will
      get back an NSEC record stating that there are no records
      (alphabetically) between avocado and zucchini (or an NSEC3 record
      stating there is nothing between two hashed names), as well as an answer
      for leek.example.org, with the label count of the signature set to two
      (see <xref target="RFC7129"/>, Section 5.3 for more details).</t>

      <t>If the validating resolver gets a query for banana.example.org, it
      will once again go off and query the example.org servers for
      banana.example.org (even though it already has proof that there is a
      wildcard record) -- just like above, this has privacy implications,
      wastes resources, can be used to contribute to a DoS, etc.</t>
    </section>

    <section title="Background">
      <t>DNSSEC <xref target="RFC4035"/> and <xref target="RFC5155"/> both
      provide "authenticated denial of existence"; this is a cryptographic
      proof that the queried-for name does not exist or the type does not exist.
      Proof that a name does not exist is accomplished by providing a (DNSSEC-secured) record containing the names that appear alphabetically before
      and after the queried-for name. In the first example above, if the
      (DNSSEC-validating) recursive server were to query for dog.example.com,
      it would receive a (signed) NSEC record stating that there are no labels
      between "albatross" and "elephant" (or, for NSEC3, a similar pair of
      hashed names). This is a signed, cryptographic proof that these names
      are the ones before and after the queried-for label. As dog.example.com
      falls within this range, the recursive server knows that dog.example.com
      really does not exist. Proof that a type does not exist is accomplished
      by providing a (DNSSEC-secured) record containing the queried-for name,
      and a type bitmap that does not include the requested type.</t>

      <t>This document specifies that this NSEC/NSEC3 record should be used to
      generate negative answers for any queries that the validating server
      receives that fall within the range covered by the record (for the TTL
      for the record). This document also specifies that a positive answer
      should be generated for any queries that the validating server receives
      that are proven to be covered by a wildcard record.</t>

      <t><xref target="RFC4035">Section 4.5 of</xref> says:

      <list style="empty">
   <t>
   In theory, a resolver could use wildcards or NSEC RRs to generate
   positive and negative responses (respectively) until the TTL or
   signatures on the records in question expire.  However, it seems
   prudent for resolvers to avoid blocking new authoritative data or
   synthesizing new data on their own.  Resolvers that follow this
   recommendation will have a more consistent view of the namespace.
      </t>
      </list>
      And, earlier, <xref target="RFC4035">Section 4.5 of</xref> says:
<list>
      <t>
   The reason for these recommendations is that, between the initial
   query and the expiration of the data from the cache, the
   authoritative data might have been changed (for example, via dynamic
   update).</t>
</list>

      In other words, if a resolver
      generates negative answers from an NSEC record, it will not send any
      queries for names within that NSEC range (for the TTL). If a new name is
      added to the zone during this interval, the resolver will not know this.
      Similarly, if the resolver is generating responses from a wildcard
      record, it will continue to do so (for the TTL).</t>

      <t>We believe that this recommendation can be relaxed because, in the absence
      of this technique, a lookup for the exact name could have come in during
      this interval, and so a negative answer could already be cached (see
      <xref target="RFC2308"/> for more background). This means that zone
      operators should have no expectation that an added name would work
      immediately. With DNSSEC and aggressive use of DNSSEC-validated cache, the TTL of the NSEC/NSEC3
      record and the SOA.MINIMUM field are the authoritative statement of how
      quickly a name can start working within a zone.</t>
    </section>

    <section anchor="aggressive-negative-caching"
             title="Aggressive Use of DNSSEC-Validated Cache">
      <t>This document relaxes the restriction given in Section 4.5 of <xref
      target="RFC4035"/>. See <xref target="update"/> for more detail.</t>

      <t>If the negative cache of the validating resolver has sufficient
      information to validate the query, the resolver SHOULD use NSEC, NSEC3, and wildcard records to synthesize answers as described in this
      document. Otherwise, it MUST fall back to send the query to the
      authoritative DNS servers.</t>

      <section anchor="nsec" title="NSEC">
        <t>The validating resolver needs to check the existence of an NSEC RR
        matching/covering the source of synthesis and an NSEC RR covering the
        query name.</t>

        <t>If denial of existence can be determined according to the rules set
        out in <xref target="RFC4035">Section 5.4 of</xref>, using NSEC
        records in the cache, then the resolver can immediately return an
        NXDOMAIN or NODATA (as appropriate) response.</t>
      </section>

      <section anchor="nsec3" title="NSEC3">
        <t>NSEC3 aggressive negative caching is more difficult than NSEC
        aggressive caching. If the zone is signed with NSEC3, the validating
        resolver needs to check the existence of non-terminals and wildcards
        that derive from query names.</t>

        <t>If denial of existence can be determined according to the rules set
        out in <xref target="RFC5155"/>, Sections 8.4, 8.5, 8.6, and 8.7, using
        NSEC3 records in the cache, then the resolver can immediately return
        an NXDOMAIN or NODATA response (as appropriate).</t>

        <t>If a covering NSEC3 RR has an Opt-Out flag, the covering NSEC3 RR does
        not prove the non-existence of the domain name and the aggressive
        negative caching is not possible for the domain name.</t>
      </section>

      <section title="Wildcards">
        <t>The last paragraph of <xref target="RFC4035"/>, Section 4.5 also
        discusses the use of wildcards and NSEC RRs to generate positive
        responses and recommends that it not be relied upon. Just like the
        case for the aggressive use of NSEC/NSEC3 for negative answers, we
        revise this recommendation.</t>

        <t>As long as the validating resolver can determine that a name would
        not exist without the wildcard match, determined according to the
        rules set out in <xref target="RFC4035">Section 5.3.4 of</xref>
        (NSEC), or in <xref target="RFC5155">Section 8.8 of</xref>, it SHOULD
        synthesize an answer (or NODATA response) for that name using the
        cache-deduced wildcard. If the corresponding wildcard record is not
        in the cache, it MUST fall back to send the query to the authoritative
        DNS servers.</t>
      </section>

      <section anchor="consideration-on-ttl" title="Consideration on TTL">
        <t>The TTL value of negative information is especially important,
        because newly added domain names cannot be used while the negative
        information is effective.</t>

        <t><xref target="RFC2308">Section 5 of</xref> suggests a maximum
        default negative cache TTL value of 3 hours (10800). It is RECOMMENDED
        that validating resolvers limit the maximum effective TTL value of
        negative responses (NSEC/NSEC3 RRs) to this same value.</t>

        <t>Section 5 of <xref target="RFC2308"/> also states that a negative
        cache entry TTL is taken from the minimum of the SOA.MINIMUM field and
        SOA's TTL. This can be less than the TTL of an NSEC or NSEC3 record,
        since their TTL is equal to the SOA.MINIMUM field (see <xref
        target="RFC4035"/>, Section 2.3 and <xref target="RFC5155"/>, Section
        3).</t>

        <t>A resolver that supports aggressive use of NSEC and NSEC3 SHOULD
        reduce the TTL of NSEC and NSEC3 records to match the SOA.MINIMUM
        field in the authority section of a negative response, if SOA.MINIMUM
        is smaller.</t>
      </section>
    </section>

    <section title="Benefits">
      <t>The techniques described in this document provide a number of
      benefits, including (in no specific order):<list style="hanging">
          <t hangText="Reduced latency:">By answering directly from cache,
          validating resolvers can immediately inform clients that the name
          they are looking for does not exist, improving the user
          experience.</t>

          <t hangText="Decreased recursive server load:">By answering queries
          from the cache by synthesizing answers, validating servers avoid
          having to send a query and wait for a response. In addition to
          decreasing the bandwidth used, it also means that the server does
          not need to allocate and maintain state, thereby decreasing memory
          and CPU load.</t>

          <t hangText="Decreased authoritative server load:">Because recursive
          servers can answer queries without asking the authoritative server,
          the authoritative servers receive fewer queries. This decreases the
          authoritative server bandwidth, queries per second, and CPU
          utilization.</t>
        </list></t>

      <t>The scale of the benefit depends upon multiple factors, including the
      query distribution. For example, at the time of this writing, around 65%
      of queries to root name servers result in NXDOMAIN responses (see
      statistics from <xref target="ROOT-SERVERS"/>); this technique will
      eliminate a sizable quantity of these.</t>

      <t>The technique described in this document may also mitigate so-called
      "random QNAME attacks", in which attackers send many queries for random
      subdomains to resolvers. As the resolver will not have the answers
      cached, it has to ask external servers for each random query, leading to
      a DoS on the authoritative servers (and often resolvers). The technique may help mitigate these attacks by allowing the resolver to answer
      directly from the cache for any random queries that fall within already
      requested ranges. It will not always work as an effective defense, not
      least because not many zones are DNSSEC signed at all -- but it will
      still provide an additional layer of defense.</t>

      <t>As these benefits are only accrued by those using DNSSEC, it is hoped
      that these techniques will lead to more DNSSEC deployment.</t>
    </section>

    <section anchor="update" title="Update to RFC 4035">
      <t>Section 4.5 of <xref target="RFC4035"/> shows that "In theory, a
      resolver could use wildcards or NSEC RRs to generate positive and
      negative responses (respectively) until the TTL or signatures on the
      records in question expire. However, it seems prudent for resolvers to
      avoid blocking new authoritative data or synthesizing new data on their
      own. Resolvers that follow this recommendation will have a more
      consistent view of the namespace".</t>

      <t>The paragraph is updated as follows:</t>

      <figure>
        <artwork><![CDATA[
+-----------------------------------------------------------------+
|  Once the records are validated, DNSSEC-enabled validating      |
|  resolvers SHOULD use wildcards and NSEC/NSEC3 resource records |
|  to generate positive and negative responses until the          |
|  effective TTLs or signatures for those records expire.         |
+-----------------------------------------------------------------+
]]></artwork>
      </figure>
    </section>

    <section anchor="ianacons" title="IANA Considerations">
      <t>This document does not require any IANA actions.</t>
    </section>

    <section anchor="securitycons" title="Security Considerations">
      <t>Use of NSEC/NSEC3 resource records without DNSSEC validation may
      create serious security issues, and so this technique requires DNSSEC
      validation.</t>

      <t>Newly registered resource records may not be used immediately.
      However, choosing a suitable TTL value and a negative cache TTL value (SOA.MINIMUM field) will mitigate the delay concern, and it is not a security
      problem.</t>

      <t>It is also suggested to limit the maximum TTL value of NSEC/NSEC3
      resource records in the negative cache to, for example, 10800 seconds
      (3 hours), to mitigate this issue.</t>

      <t>Although the TTL of NSEC/NSEC3 records is typically fairly short
      (minutes or hours), their RRSIG expiration time can be much further in
      the future (weeks). An attacker who is able to successfully spoof
      responses might poison a cache with old NSEC/NSEC3 records. If the
      resolver is not making aggressive use of NSEC/NSEC3, the attacker has to
      repeat the attack for every query. If the resolver is making aggressive
      use of NSEC/NSEC3, one successful attack would be able to suppress many
      queries for new names, up to the negative TTL.</t>
    </section>

  </middle>

  <back>
    <references title="Normative References">
<?rfc include="reference.RFC.2119"?>
<?rfc include="reference.RFC.2308"?>
<?rfc include="reference.RFC.4035"?>
<?rfc include="reference.RFC.4592"?>
<?rfc include="reference.RFC.5155"?>
<?rfc include="reference.RFC.7719"?>
<?rfc include='reference.RFC.7129'?>
<?rfc include='reference.RFC.8174'?>
    </references>

    <references title="Informative References">

<!-- vixie-dnsext-resimprove-00 IESG state: Expired -->

<reference anchor='RES-IMPROVE'>
<front>
<title>Improvements to DNS Resolvers for Resiliency, Robustness, and Responsiveness</title>

<author initials='P' surname='Vixie' fullname='Paul Vixie'>
    <organization />
</author>

<author initials='R' surname='Joffe' fullname='Rodney Joffe'>
    <organization />
</author>

<author initials='F' surname='Neves' fullname='Frederico Neves'>
    <organization />
</author>

<date month='June' day='23' year='2010' />

</front>

<seriesInfo name='Work in Progress,' value='draft-vixie-dnsext-resimprove-00' />

</reference>

      <?rfc include='reference.RFC.8020'?>

      <?rfc include='reference.RFC.5074'?>

      <reference anchor="ROOT-SERVERS"
                 target="http://www.root-servers.org/">
        <front>
          <title abbrev="Autonomous System (AS) Number">Root Server Technical
          Operations Assn</title>

          <author>
            <organization/>
          </author>

          <date/>
        </front>
      </reference>
    </references>

    <section anchor="detailed-implementation-idea"
             title="Detailed Implementation Notes">
      <t><list style="symbols">
          <t>Previously, cached negative responses were indexed by QNAME,
          QCLASS, QTYPE, and the setting of the CD bit (see RFC 4035, Section
          4.7), and only queries matching the index key would be answered from
          the cache. With aggressive negative caching, the validator, in
          addition to checking to see if the answer is in its cache before
          sending a query, checks to see whether any cached and validated NSEC
          record denies the existence of the sought record(s). Using
          aggressive negative caching, a validator will not make queries for
          any name covered by a cached and validated NSEC record. Furthermore,
          a validator answering queries from clients will synthesize a
          negative answer (or NODATA response) whenever it has an applicable
          validated NSEC in its cache unless the CD bit was set on the
          incoming query. (Imported from Section 6 of <xref
          target="RFC5074"/>.)</t>

          <t>Implementing aggressive negative caching suggests that a
          validator will need to build an ordered data structure of NSEC and
          NSEC3 records for each signer domain name of NSEC/NSEC3 records in
          order to efficiently find covering NSEC/NSEC3 records. Call the
          table as "NSEC_TABLE". (Imported from Section 6.1 of <xref
          target="RFC5074"/> and expanded.)</t>

          <t>The aggressive negative caching may be inserted at the cache
          lookup part of the recursive resolvers.</t>

          <t>If errors happen in an aggressive negative caching algorithm,
          resolvers MUST fall back to resolve the query as usual. "Resolve the
          query as usual" means that the resolver must process the query as
          though it does not implement aggressive negative caching.</t>
        </list></t>
    </section>

    <section title="Procedure for Determining ENT vs. NXDOMAIN with NSEC">
      <t>This procedure outlines how to determine if a given name does not
      exist, or is an ENT (empty non-terminal; see <xref target="RFC5155"/>, Section 1.3) with NSEC.</t>

      <t>If the NSEC record has not been verified as secure, discard it.</t>

      <t>If the given name sorts before or matches the NSEC owner name, discard
      it as it does not prove the NXDOMAIN or ENT.</t>

      <t>If the given name is a subdomain of the NSEC owner name and the NS
      bit is present and the SOA bit is absent, then discard the NSEC as it is
      from a parent zone.</t>

      <t>If the next domain name sorts after the NSEC owner name and the given
      name sorts after or matches next domain name, then discard the NSEC
      record as it does not prove the NXDOMAIN or ENT.</t>

      <t>If the next domain name sorts before or matches the NSEC owner name
      and the given name is not a subdomain of the next domain name, then
      discard the NSEC as it does not prove the NXDOMAIN or ENT.</t>

      <t>You now have an NSEC record that proves the NXDOMAIN or ENT.</t>

      <t>If the next domain name is a subdomain of the given name, you have an
      ENT. Otherwise, you have an NXDOMAIN.</t>
    </section>
    <section anchor="acknowledgments" title="Acknowledgments" numbered="no">
      <t>The authors gratefully acknowledge DNSSEC Lookaside Validation (DLV) <xref target="RFC5074"/>
      author Samuel Weiler and the Unbound developers.</t>

      <t>Thanks to Mark Andrews for providing the helpful notes for
      implementors provided in Appendix B.</t>

      <t>The authors would like to specifically thank Stephane Bortzmeyer (for
      standing next to and helping edit), Ralph Dolmans, Tony Finch, Tatuya
      JINMEI for extensive review and comments, and also Mark Andrews, Casey
      Deccio, Alexander Dupuy, Olafur Gudmundsson, Bob Harold, Shumon Huque,
      John Levine, Pieter Lexis, Matthijs Mekking (who even sent pull
      requests!), and Ondrej Sury.</t>

    </section>


  </back>
</rfc>
