<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [
<!ENTITY rfc3261 SYSTEM "reference.RFC.3261.xml">
<!ENTITY rfc2119 SYSTEM "reference.RFC.2119.xml">
<!ENTITY rfc2544 SYSTEM "reference.RFC.2544.xml">
<!ENTITY rfc3550 SYSTEM "reference.RFC.3550.xml">
<!ENTITY rfc1242 SYSTEM "reference.RFC.1242.xml">
<!ENTITY rfc2285 SYSTEM "reference.RFC.2285.xml">
<!ENTITY rfc3711 SYSTEM "reference.RFC.3711.xml">
<!ENTITY rfc6357 SYSTEM "reference.RFC.6357.xml">
<!ENTITY rfc4320 SYSTEM "reference.RFC.4320.xml">
<!ENTITY rfc5393 SYSTEM "reference.RFC.5393.xml">
<!ENTITY rfc6026 SYSTEM "reference.RFC.6026.xml">
<!ENTITY rfc7118 SYSTEM "reference.RFC.7118.xml">
]>

<?rfc rfcedstyle="yes" ?>
<?rfc toc="yes" ?>
<?rfc compact="yes" ?>
<?rfc subcompact="yes" ?>
<?rfc sortrefs="no" ?>
<?rfc symrefs="yes" ?>

<rfc number="7501" submissionType="IETF" ipr="trust200902" category="info" consensus="yes">

<front>
     <title abbrev="SIP Benchmarking Terminology">
         Terminology for Benchmarking Session Initiation Protocol (SIP) 
         Devices: Basic Session Setup and Registration
     </title>

<author initials="C." surname="Davids" fullname="Carol Davids">
     <organization>Illinois Institute of Technology</organization>
     <address>
       <postal>
          <street>201 East Loop Road</street>
          <city>Wheaton</city>
          <region>IL</region>
          <code>60187</code>
          <country>United States</country>
       </postal>
	   <phone>+1 630 682 6024</phone>
       <email>davids@iit.edu</email>
     </address>
</author>

<author initials="V." surname="Gurbani" fullname="Vijay K. Gurbani">
     <organization>Bell Laboratories, Alcatel-Lucent</organization>
     <address>
       <postal>
          <street>1960 Lucent Lane</street>
          <street>Rm 9C-533</street>
          <city>Naperville</city>
          <region>IL</region>
          <code>60566</code>
          <country>United States</country>
       </postal>
       <phone>+1 630 224 0216</phone>
       <email>vkg@bell-labs.com</email>
     </address>
</author>

<author initials="S." surname="Poretsky" fullname="Scott Poretsky">
     <organization>Allot Communications</organization>
     <address>
       <postal>
          <street>300 TradeCenter, Suite 4680</street>
          <city>Woburn</city>
          <region>MA</region>
          <code>08101</code>
          <country>United States</country>
       </postal>
       <phone>+1 508 309 2179</phone>
       <email>sporetsky@allot.com</email>
     </address>
</author>

     <date month="April" year="2015" />
	<area>Operations and Management Area</area>
     <workgroup>Benchmarking Methodology Working Group</workgroup>

<abstract>
 <t>This document provides a terminology for benchmarking the Session
 Initiation Protocol (SIP) performance of devices.  Methodology
 related to benchmarking SIP devices is described in the companion
 methodology document (RFC 7502).  Using these two documents, benchmarks can 
 be obtained and compared for different types of devices such as 
 SIP Proxy Servers, Registrars, and Session Border Controllers.  The 
 term "performance" in this context means  the capacity of the 
 Device Under Test (DUT) to process SIP messages.  Media streams are 
 used only to study how  they impact the signaling behavior.  The 
 intent of the two documents is to provide a normalized set of tests 
 that will enable an objective comparison of the capacity of SIP devices.  
 Test setup parameters and a methodology are necessary because 
 SIP allows a wide range of configurations and operational conditions 
 that can influence performance benchmark measurements.  A standard
 terminology and methodology will ensure that benchmarks have
 consistent definitions and were obtained following the same procedures.</t>
</abstract>

</front>
<middle>


<section title="Introduction" anchor="sec-intro">

 <t>Service Providers and IT organizations deliver Voice Over IP (VoIP) and
 multimedia network services based on the IETF Session Initiation Protocol 
 (SIP) <xref target="RFC3261"/>.  SIP is a signaling protocol originally 
 intended to be used to dynamically establish, disconnect, and modify 
 streams of media between end users.  As it has evolved, it has been 
 adopted for use in a growing number of services and applications.  Many 
 of these result in the creation of a media session, but some do not.  
 Examples of this latter group include text messaging and subscription 
 services.  The set of benchmarking terms provided in this document is 
 intended for use with any SIP-enabled device performing SIP functions 
 in the interior of the network, whether or not these result in the 
 creation of media sessions.  The performance of end-user devices is 
 outside the scope of this document.</t>

 <t>A number of networking devices have been developed to support SIP-based 
 VoIP services.  These include SIP servers, Session Border Controllers 
 (SBCs), and Back-to-back User Agents (B2BUAs).  These devices contain a 
 mix of voice and IP functions whose performance may 
 be reported using metrics defined by the equipment manufacturer or vendor.  
 The Service Provider or IT organization seeking to compare the performance 
 of such devices will not be able to do so using these vendor-specific 
 metrics, whose conditions of test and algorithms for collection are often 
 unspecified.</t>

 <t>SIP functional elements and the devices that include them 
 can be configured many different ways and can be organized into various 
 topologies. These configuration and topological choices impact the value 
 of any chosen signaling benchmark. Unless these conditions of test are 
 defined, a true comparison of performance metrics across multiple vendor
 implementations will not be possible.</t>

 <t>Some SIP-enabled devices terminate 
 or relay media as well as signaling.  The processing of media by the 
 device impacts the signaling performance. As a result, the 
 conditions of test must include information as to  whether or not the 
 Device Under Test processes media. If the device processes media during
 the test, a description of the media must be provided.
 This document and its companion methodology document 
 <xref target="RFC7502"/> provide a set of black-box
 benchmarks for describing and comparing the performance of devices
 that incorporate the SIP User Agent Client and Server functions
 and that operate in the network's core.</t>

 <t>The definition of SIP performance benchmarks necessarily includes
 definitions of Test Setup Parameters and a test methodology.  These
 enable the Tester to perform benchmarking tests on different
 devices and to achieve comparable results.  This
 document provides a common set of definitions for Test
 Components, Test Setup Parameters, and Benchmarks.  All the benchmarks
 defined are black-box measurements of the SIP signaling 
 plane.  The Test Setup Parameters and Benchmarks defined in this
 document are intended for use with the companion methodology
 document. </t>


<section title="Scope" anchor="scope">

<t>The scope of this document is summarized as follows:
  <list style="symbols">
   <t>This terminology document describes SIP signaling performance 
   benchmarks for black-box measurements of
   SIP networking devices.  

Stress conditions and debugging scenarios are not addressed
in this document.
   </t>

   <t>The DUT must be network equipment that is RFC 3261 capable.  This
   may be a Registrar, Redirect Server, or Stateful Proxy.  This
   document does not require the intermediary to assume the 
   role of a stateless proxy. 

A DUT may also act as a B2BUA or take the role of an SBC.
   </t>

   <t>The Tester acts as multiple Emulated Agents (EAs) that initiate
   (or respond to) SIP messages as session endpoints and source
   (or receive) associated media for established connections.</t>

   <t>Regarding SIP signaling in presence of media:
    <list style="symbols">
     <t>The media performance is not benchmarked.</t>

     <t>Some tests require media, but the use of media is limited to
     observing the performance of SIP signaling.  Tests that require
     media will annotate the media characteristics as a condition of
     test.</t>

     <t>The type of DUT dictates whether the associated media
     streams traverse the DUT.  Both scenarios are within the
     scope of this document.</t>

     <t>SIP is frequently used to create media streams; the signaling 
     plane and media plane are treated as orthogonal to each other
     in this document.  While many devices support the creation of
     media streams, benchmarks that measure the performance of these
     streams are outside the scope of this document and its companion
     methodology document <xref target="RFC7502"/>.
     Tests may be performed with or without the creation of media
     streams.  The presence or absence of media streams MUST 
     be noted as a condition of the test, as the performance of SIP
     devices may vary accordingly.  Even if the media is used during
     benchmarking, only the SIP performance will be benchmarked, not
     the media performance or quality.</t>
    </list></t>

   <t>Both INVITE and non-INVITE scenarios (registrations)
   are addressed in this document.  However, benchmarking SIP
   presence or subscribe-notify extensions is not a part of this 
   document.</t>

   <t>Different transport -- such as UDP, TCP, SCTP, or TLS -- may be 
   used. The specific transport mechanism MUST be noted as a condition of 
   the test, as the performance of SIP devices may vary accordingly.</t>

   <t>REGISTER and INVITE requests may be challenged or remain
   unchallenged for authentication purposes. Whether or not the REGISTER and 
   INVITE requests are challenged is a condition of test that will be 
   recorded along with other such parameters that may impact the SIP 
   performance of the device or system under test. </t>

   <t>Re-INVITE requests are not considered within the scope of this document
   since the benchmarks for INVITEs are based on the dialog created 
   by the INVITE and not on the transactions that take place within that 
   dialog. </t>

   <t>Only session establishment is considered for the performance
   benchmarks.  Session disconnect is not considered within the scope
   of this document. This is because our goal is to determine the maximum 
   capacity of the device or system under test, that is, the number of 
   simultaneous SIP sessions that the device or system can support.  It is 
   true that there are BYE requests being created during the test process.  
   These transactions do contribute to the load on the device or system 
   under test and thus are accounted for in the metric we derive.  We do not 
   seek a separate metric for the number of BYE transactions a device or 
    system can support. </t>


   <t>Scenarios that are specific to the IP Multimedia Subsystem (IMS) are not considered, but test cases can
   be applied with 3GPP-specific SIP signaling and the Proxy-Call Session
   Control Function (P-CSCF) as a
   DUT.</t>

   <t>The benchmarks described in this document are intended for a
   laboratory environment and are not intended to be used on a 
   production network.  Some of the benchmarks send enough traffic
   that a denial-of-service attack is possible if used in production
   networks.</t>

  </list></t>

</section> <!-- scope -->

</section> <!-- Introduction -->

<section title="Terminology">
<t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
    "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
    document are to be interpreted as described in BCP 14, RFC2119
    <xref target="RFC2119"/>.  RFC 2119 defines the use of these key
    words to help make the intent of Standards Track documents as clear
    as possible.  While this document uses these keywords, this document
    is not a Standards Track document.  

</t>

<t>For the sake of clarity and continuity, this document adopts the
template for definitions set out in Section 2 of RFC 1242
<xref target="RFC1242"/>.</t>

<t>
   The term "Device Under Test (DUT)" is defined in Section 3.1.1 of RFC 2285
   <xref target="RFC2285"/>.

</t>

<t> Many commonly used SIP terms in this document are defined in
RFC 3261 <xref target="RFC3261"/>.  For convenience, the most important
of these are reproduced below.  Use of these terms in this document
is consistent with their corresponding definition in the base SIP
specification <xref target="RFC3261"/> as amended by <xref target="RFC4320"/>,
<xref target="RFC5393"/>, and <xref target="RFC6026"/>.</t>
<t>
  <list style="symbols">
   <t>Call Stateful: A proxy is call stateful if it retains state for
   a dialog from the initiating INVITE to the terminating BYE request.
   A call stateful proxy is always transaction stateful, but the
   converse is not necessarily true.</t>

   <t>Stateful Proxy: A logical entity, as defined by <xref target="RFC3261"/>,
   that maintains the client and server transaction state machines    
   during the processing of a request. (Also known as a transaction
   stateful proxy.)  The behavior of a stateful proxy is further defined
   in Section 16 of RFC 3261 <xref target="RFC3261"/> .  A transaction 
   stateful proxy is not the same as a call stateful proxy.</t>

   <t>Back-to-Back User Agent: A back-to-back user agent (B2BUA) is a 
   logical entity that receives a request and processes it as a user 
   agent server (UAS).  In order to determine how the request should be 
   answered, it acts as a user agent client (UAC) and generates requests.  
   Unlike a proxy server, it maintains dialog state and must participate in all
   requests sent on the dialogs it has established.  Since it is a
   concatenation of a UAC and a UAS, no explicit definitions are
   needed for its behavior.</t>
  </list>
</t>


</section>


<section title="Term Definitions" anchor="term-def">

<section title="Protocol Components" anchor="protocol-components">

<section title="Session" anchor="session">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>

    <t>The combination of signaling and media messages and associated
    processing that enable a single SIP-based audio or video call, or
    SIP registration.</t>

   <t></t>

   <t hangText="Discussion:"></t>

     <t>The term "session" commonly implies a media session.  In 
     this document the term is extended to cover the signaling
     and any media specified and invoked by the corresponding
     signaling.</t>

   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
     <t>Media Plane</t>
     <t>Signaling Plane</t>
     <t>Associated Media</t>
  </list>

</t> <!-- vkg -->
</section>

<section title="Signaling Plane" anchor="signaling-plane">
<t>
<list style="hanging">
   <t hangText="Definition:"></t>
    <t>The plane in which SIP messages <xref target="RFC3261"/> are
       exchanged between SIP agents <xref target="RFC3261"/>.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>SIP messages are used to establish sessions
       in several ways: directly between two User Agents
       <xref target="RFC3261"/>, through a Proxy Server
       <xref target="RFC3261"/>, or through a series of Proxy Servers.
       The Session Description Protocol (SDP) is included in the Signaling 
       Plane.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t> Media Plane</t>
    <t>Emulated Agent</t>
  </list>
</t>
</section> <!-- signaling plane -->

<section title="Media Plane" anchor="media-plane">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>The data plane in which one or more media streams and their
    associated media control protocols (e.g., RTCP <xref target="RFC3550"/>) 
    are exchanged between User Agents after a media connection has been 
    created by the exchange of signaling messages in the Signaling Plane.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>Media may also be known as the  "bearer channel".  The Media 
    Plane MUST include the media control protocol, if one is used, and 
    the media stream(s). Examples of media are audio and video.  The media
    streams are described in the SDP of the Signaling Plane.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
    <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t>Signaling Plane</t>
  </list>
</t>
</section> <!-- Media Plane -->

<section title="Associated Media" anchor="associated-media-stream">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>Media that corresponds to an 'm' line in the SDP
       payload of the Signaling Plane.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>The format of the media is determined by the SDP attributes for the 
    corresponding 'm' line.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
    </list>
</t>
</section> <!-- Associated Media stream -->

<section title="Overload" anchor="sec-overload">
<t>
<list style="hanging">
  <t hangText="Definition:"></t>
  <t>Overload is defined as the state where a SIP server does not
  have sufficient resources to process all incoming SIP messages
  <xref target="RFC6357"/>. </t>
  <t></t>
  <t hangText="Discussion:"></t>
   <t>The distinction between an overload condition and other failure 
   scenarios is outside the scope of black-box testing and of this document.  
   Under overload conditions, all or a percentage of Session Attempts
   will fail due to lack of resources.  In black-box testing, the cause of 
   the failure is not explored.  The fact that a failure occurred for 
   whatever reason will trigger the tester to reduce the offered load, as 
   described in the companion methodology document
   <xref target="RFC7502"/>.  SIP server resources may
   include CPU processing capacity, network bandwidth, input/output queues, 
   or disk resources.  Any combination of resources may be fully utilized 
   when a SIP server (the DUT) is in the overload condition.  For 
   proxy-only (or intermediary) devices, it is expected that the proxy will be 
   driven into overload based on the delivery rate of signaling 
   requests.</t>
  <t></t>
  <t hangText="Measurement Units:"></t>
   <t>N/A.</t>
</list></t>
</section> <!-- sec-overload -->

<section title="Session Attempt" anchor="session-attempt">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>A SIP INVITE or REGISTER request sent by the EA that has not received a
    final response.</t>
    <t></t>
   <t hangText="Discussion:"></t>
    <t>The attempted session may be either an invitation to an audio/video
    communication or a registration attempt. When counting the number of 
    session attempts, we include all requests that are rejected for lack 
    of authentication information. The EA needs to 
    record the total number of session attempts including those attempts 
    that are routinely rejected by a proxy that requires the UA to 
    authenticate itself.  The EA is provisioned to deliver a specific 
    number of session attempts per second. But the EA must also count the 
    actual number of session attempts per given time interval. </t>
    <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t>Session</t>
    <t>Session Attempt Rate</t>
  </list>
</t>
</section> <!-- session attempting state -->

<section title="Established Session">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>


    <t>A SIP session for which the EA acting as the UA has
    received a 200 OK message.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>An Established Session may be either an invitation to an 
    audio/video communication or a registration attempt.  Early dialogs 
    for INVITE requests are out of scope for this work.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
   <t>None.</t>
  </list>
</t>
</section> <!-- session established state -->

<section title="Session Attempt Failure" anchor="IS-fail">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>A session attempt that does not result in an Established
    Session.</t>
   <t></t>
   <t hangText="Discussion:"></t>
   <t>The session attempt failure may be indicated by the following
   observations at the EA:
    <list style="numbers">
     <t>Receipt of a SIP 3xx-, 4xx-, 5xx-, or 6xx-class response to a Session
     Attempt.</t>
     <t>The lack of any received SIP response to a Session Attempt within the
     Establishment Threshold Time (cf.&nbsp;<xref target="ET"/>).</t>
    </list></t>

   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t>Session Attempt</t>
  </list>
</t>
</section> <!-- IS-Fail -->

</section> <!-- protocol components -->

<section title="Test Components" anchor="test-components">

<section title="Emulated Agent" anchor="emulated-agent">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>A device in the test topology that initiates/responds to SIP
     messages as one or more session endpoints and, wherever
     applicable, sources/receives Associated Media for Established
     Sessions.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>The EA functions in the Signaling and Media
    Planes.  The Tester may act as multiple EAs.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
   <t>Media Plane</t>
   <t>Signaling Plane</t>
   <t>Established Session</t>
   <t>Associated Media</t>
  </list>
</t>
</section> <!-- emulated agent -->

  <section title="Signaling Server" anchor="signaling-server">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>Device in the test topology that facilitates the creation of 
    sessions between EAs.  This device is the DUT.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>The DUT is a network intermediary that is RFC 3261 capable such as
    a Registrar, Redirect Server, Stateful Proxy, B2BUA, or SBC.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>N/A.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
     <t>Signaling Plane</t>
	 </list>
</t>
</section> <!-- signaling server-->

<section title="SIP Transport Protocol" anchor="SIP-transport-protocol">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>The protocol used for transport of the Signaling Plane
        messages. </t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>Performance benchmarks may vary for the same SIP networking
       device depending upon whether TCP, UDP, TLS, SCTP, websockets
       <xref target="RFC7118"/>, or any future transport-layer protocol 
       is used.  For this reason, it is necessary to measure the SIP 
       Performance Benchmarks using
       these various transport protocols.  Performance Benchmarks
       MUST report the SIP Transport Protocol used to obtain the
       benchmark results.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>While these are not units of measure, they are attributes that are 
    one of many factors that will contribute to the value of the
    measurements to be taken.  TCP, UDP, SCTP, TLS over TCP, TLS over 
    UDP, TLS over SCTP, and websockets are among the possible values
    to be recorded as part of the test.</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
     <t>None.</t>
  </list>
</t>
</section> <!-- SIP transport protocol -->

</section> <!-- Test components -->

<section title="Test Setup Parameters" anchor="test-setup-parameters">

<section title="Session Attempt Rate" anchor="session-attempt-rate">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>Configuration of the EA for the number of sessions per second (sps)
    that the EA attempts to establish using the services of the DUT.</t>

   <t></t>
   <t hangText="Discussion:"></t>
    <t>The Session Attempt Rate is the number of sessions per second 
    that the EA sends toward the DUT.  Some of the sessions attempted may 
    not result in a session being established.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>Session Attempts per second</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
   <t>Session</t>
   <t>Session Attempt</t>
  </list>
</t>
</section> <!-- Session attempt rate -->

<section title="Establishment Threshold Time" anchor="ET">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>Configuration of the EA that represents the amount of time that
    an EA client will wait for a response from an EA server before declaring a
    Session Attempt Failure.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>This time duration is test dependent.</t>
    <t></t>
    <t>It is RECOMMENDED that the Establishment Threshold Time value
    be set to Timer B or Timer F as specified
    in RFC 3261, Table 4 <xref target="RFC3261"/>.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>seconds</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t>None.</t>
  </list>
</t>
</section> <!-- Establishment Threshold -->

<section title="Session Duration" anchor="SD">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>Configuration of the EA that represents the amount
    of time that the SIP dialog is intended to exist between the 
    two EAs associated with the test.</t>
   <t></t>
   <t hangText="Discussion:"></t>
   <t>The time at which the BYE is sent will control the Session Duration.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>seconds</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t>None.</t>
  </list>
</t>
</section> <!-- SD -->

<section title="Media Packet Size" anchor="media-packet-size">
<t>
  <list style="hanging">
   <t hangText="Definition:"></t>
    <t>Configuration on the EA for a fixed number of frames or samples to be
    sent in each RTP packet of the media stream when the test involves
    Associated Media.</t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>This document describes a method to measure SIP performance.  
    If the DUT is processing media as well as SIP messages the media 
    processing will potentially slow down the SIP processing and lower 
    the SIP performance metric.  The tests with associated media are 
    designed for audio codecs, and the assumption was made that larger 
    media packets would require more processor time.  This document does 
    not define parameters applicable to video codecs.</t>
    <t></t>
    <t>For a single benchmark test, media sessions use a defined number of
    samples or frames per RTP packet.  If two SBCs, for example, used the
    same codec but one puts more frames into the RTP packet, this might
    cause variation in the performance benchmark results.</t>
   <t></t>

   <t hangText="Measurement Units:"></t>
    <t>
      An integer number of frames or samples, depending on whether
      a hybrid- or sample-based codec is used, respectively.
    </t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
    <t>None.</t>
  </list>
</t>
</section> <!-- media packet size -->

<section title="Codec Type" anchor="codec">
 <t>
  <list style="hanging">
   <t hangText="Definition:"></t>
   <t>The name of the codec used to generate the media session.</t>
   <t></t>
   <t hangText="Discussion"></t>
   <t>For a single benchmark test, all sessions use the same size packet
   for media streams.  The size of packets can cause a variation in the
   performance benchmark measurements.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
   <t>This is a textual name (alphanumeric) assigned to uniquely identify
   the codec.</t>
   <t></t>
   <t hangText="Issues:"></t>
   <t>None.</t>
   <t hangText="See Also:"></t>
   <t>None.</t>
  </list>
 </t>
</section> <!-- codec -->

</section>

<section title="Benchmarks" anchor="benchmarks">

<section title="Session Establishment Rate"
          anchor="session-rate">
<t>
<list style="hanging">
  <t hangText="Definition:"></t>
   <t>The maximum value of the Session Attempt Rate that the DUT can 
   handle for an extended, predefined period with zero failures. </t>
   <t></t>
   <t hangText="Discussion:"></t>
    <t>This benchmark is obtained with zero failure.  The Session Attempt 
    Rate provisioned on the EA is raised and lowered as described in the 
    algorithm in the accompanying methodology document
    <xref target="RFC7502"/>, until a traffic 
    load over the period of time necessary to attempt N sessions  completes 
    without failure, where N is a parameter specified in the 
    algorithm and recorded in the Test Setup Report.</t>

    <t></t>
   <t hangText="Measurement Units:"></t>
    <t>sessions per second (sps)</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>

   <t hangText="See Also:"></t>
   <t> Session Attempt Rate </t>
  </list>
</t>
</section> <!-- session establishment rate -->

<section title="Registration Rate" anchor="maximum-registration-rate">
<t>
<list style="hanging">
   <t hangText="Definition:"></t>
    <t>The maximum value of the Registration Attempt Rate that the DUT can 
    handle for an extended, predefined period with zero failures.</t>
   <t></t>
   <t hangText="Discussion:"></t>

   <t>This benchmark is obtained with zero failures.
   The registration rate provisioned on the Emulated Agent
   is raised and lowered as described in the algorithm in the
   companion methodology document <xref target="RFC7502"/>,
   until a traffic load consisting of registration attempts at the given 
   attempt rate over the  period of time necessary to attempt N 
   registrations completes without failure, where N is a parameter 
   specified in the algorithm and recorded in the Test Setup Report.

  <vspace blankLines="1"/>
   This benchmark is described separately from the Session 
   Establishment Rate (<xref target="session-rate"/>), although it could 
   be considered a special case of that benchmark, since a REGISTER 
   request is a request for a session that is not initiated by an INVITE request.  It is 
   defined separately because it is a very important benchmark for 
   most SIP installations.  An example demonstrating its use is an
   avalanche restart, where hundreds of thousands of endpoints register
   simultaneously following a power outage.  In such a case, an 
   authoritative measurement of the capacity of the device to register 
   endpoints is useful to the network designer.  Additionally, in
   certain controlled networks, there appears to be a difference between
   the registration rate of new endpoints and the registering rate of
   existing endpoints (register refreshes).  This benchmark can capture
   these differences as well.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>registrations per second (rps)</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
     <t>None.</t>
  </list>
</t>
</section> <!-- registration rate -->

<section title="Registration Attempt Rate" anchor="rar">

<t>
<list style="hanging">
   <t hangText="Definition:"></t>
    <t>Configuration of the EA for the number of registrations per second 
    that the EA attempts to send to the DUT.</t>
   <t></t>
   <t hangText="Discussion:"></t>

   <t>The Registration Attempt Rate is the number of registration 
   requests per second that the EA sends toward the DUT.</t>
   <t></t>
   <t hangText="Measurement Units:"></t>
    <t>registrations per second (rps)</t>
   <t></t>
   <t hangText="Issues:"></t>
    <t>None.</t>
   <t></t>
   <t hangText="See Also:"></t>
     <t>None.</t>
  </list>
</t>

</section> <!-- rar -->


</section> <!-- gets you up to 3.5 -->
</section> <!-- gets you up to 4 -->


<section title="Security Considerations" anchor="security">
    <t>Documents of this type do not directly affect the security of
    the Internet or corporate networks as long as benchmarking is not
    performed on devices or systems connected to production
    networks.  Security threats and how to counter these in SIP
    and the media layer are discussed in RFC 3261 <xref target="RFC3261"/>,
    RFC 3550 <xref target="RFC3550"/>, and RFC 3711 <xref target="RFC3711"/>.
    This document attempts to formalize a set of common terminology 
    for benchmarking SIP networks. Packets with unintended and/or 
    unauthorized DSCP or IP precedence values may present security 
    issues.  Determining the security consequences of such packets is 
    out of scope for this document.</t>
  </section> <!-- gets you up to 6 -->


</middle>

<back>

<references title="Normative References">
   &rfc2119;
   &rfc3261;
   &rfc5393;
   &rfc4320;
   &rfc6026;
<!-- draft-ietf-bmwg-sip-bench-meth: RFC 7502 -->

   <reference anchor="RFC7502" target="http://www.rfc-editor.org/info/rfc7502">
    <front>
     <title>Terminology for Benchmarking Session Initiation Protocol (SIP)
     Devices: Basic Session Setup and Registration</title>
     <author initials="C." surname="Davids"><organization/></author>
     <author initials="V." surname="Gurbani"><organization/></author>
     <author initials="S." surname="Poretsky"><organization/></author>
     <date month="April" year="2015"/>
    </front>
    <seriesInfo name="RFC"
                value="7502"/>
   </reference>

</references>

<references title="Informative References">
   &rfc2285;
   &rfc1242;
   &rfc3550;
   &rfc3711;
   &rfc6357;
   &rfc7118;

</references>

<section title="Acknowledgments" anchor="acks" numbered="no">

<t>The authors would like to thank Keith Drage, Cullen Jennings, Daryl
Malas, Al Morton, and Henning Schulzrinne for invaluable contributions to
this document.  Dale Worley provided an extensive review that lead to
improvements in the documents.  We are grateful to Barry Constantine, 
William Cerveny, and Robert Sparks for providing valuable comments during 
the documents' last calls and expert reviews.  Al Morton and Sarah Banks 
have been exemplary working group chairs; we thank them for tracking 
this work to completion.</t>
</section>

</back>
</rfc>
