<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?>

<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="3"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes" ?>
<?rfc compact="yes" ?>
<?rfc subcompact="no" ?>

<rfc number="7567" seriesNo="197" category="bcp" 
     ipr="pre5378Trust200902" obsoletes="2309" submissionType="IETF" consensus="yes">
  <front>
    <title abbrev="Active Queue Management Recommendations">IETF
    Recommendations Regarding Active Queue Management</title>

    <author fullname="Fred Baker" initials="F." role="editor" surname="Baker">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street></street>

          <city>Santa Barbara</city>

          <code>93117</code>

          <region>California</region>

          <country>United States</country>
        </postal>

        <email>fred@cisco.com</email>
      </address>
    </author>

    <author fullname="Godred Fairhurst" initials="G." role="editor"
            surname="Fairhurst">
      <organization>University of Aberdeen</organization>

      <address>
        <postal>
          <street>School of Engineering</street>

          <street>Fraser Noble Building</street>

          <city>Aberdeen</city>

          <region>Scotland</region>

          <code>AB24 3UE</code>

          <country>United Kingdom</country>
        </postal>

        <email>gorry@erg.abdn.ac.uk</email>

        <uri>http://www.erg.abdn.ac.uk</uri>
      </address>
    </author>

    <date month="July" year="2015" />

    <abstract>
      <t>This memo presents recommendations to the Internet community
      concerning measures to improve and preserve Internet performance. It
      presents a strong recommendation for testing, standardization, and
      widespread deployment of active queue management (AQM) in network
      devices to improve the performance of today's Internet. It also urges a
      concerted effort of research, measurement, and ultimate deployment of
      AQM mechanisms to protect the Internet from flows that are not
      sufficiently responsive to congestion notification.</t>

      <t>Based on 15 years of experience and new research, this document replaces the recommendations of RFC 2309.</t>
    </abstract>

  </front>

  <middle>

    <section title="Introduction">
      <t>The Internet protocol architecture is based on a connectionless end-to-end packet service using the Internet Protocol, whether <xref
      target="RFC0791">IPv4</xref> or <xref target="RFC2460">IPv6</xref>. The
      advantages of its connectionless design -- flexibility and robustness --
      have been amply demonstrated. However, these advantages are not without
      cost: careful design is required to provide good service under heavy
      load. In fact, lack of attention to the dynamics of packet forwarding
      can result in severe service degradation or "Internet meltdown". This
      phenomenon was first observed during the early growth phase of the
      Internet in the mid 1980s <xref target="RFC0896"></xref> <xref
      target="RFC0970"></xref>; it is technically called "congestion
      collapse" and was a key focus of RFC 2309.</t>

      <t>Although wide-scale congestion collapse is not common in the
      Internet, the presence of localized congestion collapse is by no means
      rare. It is therefore important to continue to avoid congestion
      collapse.</t>

      <t>Since 1998, when RFC 2309 was written, the Internet has become used
      for a variety of traffic. In the current Internet, low latency is
      extremely important for many interactive and transaction-based
      applications. The same type of technology that RFC 2309 advocated for
      combating congestion collapse is also effective at limiting delays to
      reduce the interaction delay (latency) experienced by applications <xref
      target="Bri15"></xref>. High or unpredictable latency can impact the
      performance of the control loops used by end-to-end protocols (including
      congestion control algorithms using TCP). There is now also a focus on
      reducing network latency using the same technology.</t>

      <t>The mechanisms described in this document may be implemented in
      network devices on the path between endpoints that include routers,
      switches, and other network middleboxes. The methods may also be
      implemented in the networking stacks within endpoint devices that
      connect to the network.</t>

      <section title="Congestion Collapse">
        <t>The original fix for Internet meltdown was provided by Van
        Jacobsen. Beginning in 1986, Jacobsen developed the congestion
        avoidance mechanisms <xref target="Jacobson88"></xref> that are now
        required for implementations of the Transport Control Protocol (TCP)
        <xref target="RFC0793"></xref> <xref target="RFC1122"></xref>. (<xref
        target="RFC7414"></xref> provides a roadmap to help identify
        TCP-related documents.) These mechanisms operate in Internet hosts to
        cause TCP connections to "back off" during congestion. We say that TCP
        flows are "responsive" to congestion signals (i.e., packets that are
        dropped or marked with explicit congestion notification <xref
        target="RFC3168"></xref>). It is primarily these TCP congestion
        avoidance algorithms that prevent the congestion collapse of today's
        Internet. Similar algorithms are specified for other non-TCP
        transports.</t>

        <t>However, that is not the end of the story. Considerable research
        has been done on Internet dynamics since 1988, and the Internet has
        grown. It has become clear that the <xref target="RFC5681">congestion
        avoidance mechanisms</xref>, while necessary and powerful, are not
        sufficient to provide good service in all circumstances. Basically,
        there is a limit to how much control can be accomplished from the
        edges of the network. Some mechanisms are needed in network devices to
        complement the endpoint congestion avoidance mechanisms. These
        mechanisms may be implemented in network devices.</t>
      </section>

      <section title="Active Queue Management to Manage Latency">
        <t>Internet latency has become a focus of attention to increase the
        responsiveness of Internet applications and protocols. One major
        source of delay is the buildup of queues in network devices. Queueing
        occurs whenever the arrival rate of data at the ingress to a device
        exceeds the current egress rate. Such queueing is normal in a
        packet-switched network and is often necessary to absorb bursts in
        transmission and perform statistical multiplexing of traffic, but
        excessive queueing can lead to unwanted delay, reducing the
        performance of some Internet applications.</t>

        <t>RFC 2309 introduced the concept of "Active Queue Management" (AQM),
        a class of technologies that, by signaling to common
        congestion-controlled transports such as TCP, manages the size of
        queues that build in network buffers. RFC 2309 also describes a
        specific AQM algorithm, Random Early Detection (RED), and recommends
        that this be widely implemented and used by default in routers.</t>

        <t>With an appropriate set of parameters, RED is an effective
        algorithm. However, dynamically predicting this set of parameters was
        found to be difficult. As a result, RED has not been enabled by
        default, and its present use in the Internet is limited. Other AQM
        algorithms have been developed since RFC 2309 was published, some of
        which are self-tuning within a range of applicability. 

 Hence, while this memo continues to recommend the deployment of
 AQM, it no longer recommends that RED or any other specific
 algorithm is used by default.  It instead provides recommendations
 on IETF processes for the selection of appropriate algorithms,
 and especially that a recommended algorithm is able to automate
 any required tuning for common deployment scenarios.
	</t>

        <t>Deploying AQM in the network can significantly reduce the latency
        across an Internet path, and, since the writing of RFC 2309, this has become a
        key motivation for using AQM in the Internet. In the context of AQM,
        it is useful to distinguish between two related classes of algorithms:
        "queue management" versus "scheduling" algorithms. To a rough
        approximation, queue management algorithms manage the length of packet
        queues by marking or dropping packets when necessary or appropriate,
        while scheduling algorithms determine which packet to send next and
        are used primarily to manage the allocation of bandwidth among flows.
        While these two mechanisms are closely related, they address different
        performance issues and operate on different timescales. Both may be
        used in combination.</t>
      </section>

      <section title="Document Overview">
        <t>The discussion in this memo applies to "best-effort" traffic, which
        is to say, traffic generated by applications that accept the
        occasional loss, duplication, or reordering of traffic in flight. It
        also applies to other traffic, such as real-time traffic that can
        adapt its sending rate to reduce loss and/or delay. It is most
        effective when the adaption occurs on timescales of a single Round-Trip Time (RTT) or a small number of RTTs, for <xref
        target="RFC1633">elastic traffic</xref>.</t>

        <t>Two performance issues are highlighted:</t>

        <t>The first issue is the need for an advanced form of queue
        management that we call "Active Queue Management", AQM. <xref
        target="need_for_AQM"></xref> summarizes the benefits that active queue
        management can bring. A number of AQM procedures are described in the
        literature, with different characteristics. This document does not
        recommend any of them in particular, but it does make recommendations
        that ideally would affect the choice of procedure used in a given
        implementation.</t>

        <t>The second issue, discussed in <xref target="conclusion"></xref> of
        this memo, is the potential for future congestion collapse of the
        Internet due to flows that are unresponsive, or not sufficiently
        responsive, to congestion indications. Unfortunately, while scheduling
        can mitigate some of the side effects of sharing a network queue with
        an unresponsive flow, there is currently no consensus solution to
        controlling the congestion caused by such aggressive flows. Methods
        such as congestion exposure (ConEx) <xref target="RFC6789"></xref>
        offer a framework <xref target="CONEX"></xref> that can update network
        devices to alleviate these effects. Significant research and
        engineering will be required before any solution will be available. It
        is imperative that work to mitigate the impact of unresponsive flows
        is energetically pursued to ensure acceptable performance and the
        future stability of the Internet.</t>

        <t><xref target="conclusion"></xref> concludes the memo with a set of
        recommendations to the Internet community on the use of AQM and
        recommendations for defining AQM algorithms.</t>
      </section>

      <section anchor="update-to-rfc2309"
               title="Changes to the Recommendations of RFC 2309">
        <t>This memo replaces the recommendations in <xref
        target="RFC2309"></xref>, which resulted from past discussions of
        end-to-end performance, Internet congestion, and RED in the End-to-End
        Research Group of the Internet Research Task Force (IRTF). It results from
        experience with RED and other algorithms, and the AQM discussion
        within the IETF <xref target="AQM-WG"></xref>.</t>

        <t>Whereas RFC 2309 described AQM in terms of the length of a queue, this
        memo uses AQM to refer to any method that allows
        network devices to control the queue length and/or the mean
        time that a packet spends in a queue.</t>

        <t>This memo also explicitly obsoletes the recommendation that Random
        Early Detection (RED) be used as the default AQM mechanism for
        the Internet. This is replaced by a detailed set of recommendations
        for selecting an appropriate AQM algorithm. 

As in RFC 2309, this memo illustrates the need for continued research. It also
clarifies the research needed with examples appropriate at the time that this
memo is published.
	</t>

      </section>

      <section title="Requirements Language">
        <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
        "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
        document are to be interpreted as described in <xref
        target="RFC2119"></xref>.</t>
      </section>
    </section>

    <section anchor="need_for_AQM" title="The Need for Active Queue Management">
      <t>Active Queue Management (AQM) is a method that allows network devices
      to control the queue length or the mean time that a packet spends in a
      queue. Although AQM can be applied across a range of deployment
      environments, the recommendations in this document are for use
      in the general Internet. It is expected that the principles and guidance
      are also applicable to a wide range of environments, but they may require
      tuning for specific types of links or networks (e.g., to accommodate the
      traffic patterns found in data centers, the challenges of wireless
      infrastructure, or the higher delay encountered on satellite Internet
      links). The remainder of this section identifies the need for AQM and
      the advantages of deploying AQM methods.</t>

      <t>The traditional technique for managing the queue length in a network
      device is to set a maximum length (in terms of packets) for each queue,
      accept packets for the queue until the maximum length is reached, then
      reject (drop) subsequent incoming packets until the queue decreases
      because a packet from the queue has been transmitted. This technique is
      known as "tail drop", since the packet that arrived most recently (i.e.,
      the one on the tail of the queue) is dropped when the queue is full.
      This method has served the Internet well for years, but it has four
      important drawbacks:<list style="numbers">
          <t>Full Queues <vspace blankLines="1" />The "tail drop" discipline
          allows queues to maintain a full (or, almost full) status for long
          periods of time, since tail drop signals congestion (via a packet
          drop) only when the queue has become full. It is important to reduce
          the steady-state queue size, and this is perhaps the most important
          goal for queue management. <vspace blankLines="1" />The naive
          assumption might be that there is a simple trade-off between delay
          and throughput, and that the recommendation that queues be
          maintained in a "non-full" state essentially translates to a
          recommendation that low end-to-end delay is more important than high
          throughput. However, this does not take into account the critical
          role that packet bursts play in Internet performance. For example,
          even though TCP constrains the congestion window of a flow, packets
          often arrive at network devices in bursts <xref
          target="Leland94"></xref>. If the queue is full or almost full, an
          arriving burst will cause multiple packets to be dropped from the
          same flow. Bursts of loss can result in a global synchronization of
          flows throttling back, followed by a sustained period of lowered
          link utilization, reducing overall throughput <xref
          target="Flo94"></xref> <xref target="Zha90"></xref>.<vspace
          blankLines="1" />The goal of buffering in the network is to absorb
          data bursts and to transmit them during the (hopefully) ensuing
          bursts of silence. This is essential to permit transmission of
          bursts of data. Queues that are normally small are preferred in network
          devices, with sufficient queue capacity to absorb the bursts. The
          counterintuitive result is that maintaining queues that are normally
	  small
          can result in higher throughput as well as lower end-to-end delay.
          In summary, queue limits should not reflect the steady-state queues
          we want to be maintained in the network; instead, they should
          reflect the size of bursts that a network device needs to
          absorb.</t>

          <t>Lock-Out <vspace blankLines="1" />In some situations tail drop
          allows a single connection or a few flows to monopolize the queue
          space, thereby starving other connections, preventing them from getting room
          in the queue <xref target="Flo92"></xref>.</t>

          <t>Mitigating the Impact of Packet Bursts <vspace
          blankLines="1" />A large burst of packets can delay other packets,
          disrupting the control loop (e.g., the pacing of flows by the TCP
          ACK clock), and reducing the performance of flows that share a
          common bottleneck.</t>

          <t>Control Loop Synchronization<vspace blankLines="1" />Congestion
          control, like other end-to-end mechanisms, introduces a control loop
          between hosts. Sessions that share a common network bottleneck can
          therefore become synchronized, introducing periodic disruption (e.g.,
          jitter/loss). "Lock-out" is often also the result of synchronization
          or other timing effects</t>
        </list></t>

      <t>Besides tail drop, two alternative queue management disciplines that
      can be applied when a queue becomes full are "random drop on full" or
      "head drop on full". When a new packet arrives at a full queue using the
      "random drop on full" discipline, the network device drops a randomly
      selected packet from the queue (this can be an expensive operation,
      since it naively requires an O(N) walk through the packet queue). When a
      new packet arrives at a full queue using the "head drop on full"
      discipline, the network device drops the packet at the front of the
      queue <xref target="Lakshman96"></xref>. Both of these solve the
      lock-out problem, but neither solves the full-queues problem described
      above.</t>

      <t>In general, we know how to solve the full-queues problem for
      "responsive" flows, i.e., those flows that throttle back in response to
      congestion notification. In the current Internet, dropped packets
      provide a critical mechanism indicating congestion notification to
      hosts. The solution to the full-queues problem is for network devices to
      drop or ECN-mark packets before a queue becomes full, so that hosts can
      respond to congestion before buffers overflow. We call such a proactive
      approach AQM. By dropping or ECN-marking packets before buffers
      overflow, AQM allows network devices to control when and how many
      packets to drop.</t>

      <t>In summary, an active queue management mechanism can provide the
      following advantages for responsive flows. <list style="numbers">
          <t>Reduce number of packets dropped in network devices <vspace
          blankLines="1" />Packet bursts are an unavoidable aspect of packet
          networks <xref target="Willinger95"></xref>. If all the queue space
          in a network device is already committed to "steady-state" traffic
          or if the buffer space is inadequate, then the network device will
          have no ability to buffer bursts. By keeping the average queue size
          small, AQM will provide greater capacity to absorb
          naturally occurring bursts without dropping packets. <vspace
          blankLines="1" />Furthermore, without AQM, more packets will be
          dropped when a queue does overflow. This is undesirable for several
          reasons. First, with a shared queue and the "tail drop" discipline,
          this can result in unnecessary global synchronization of flows,
          resulting in lowered average link utilization and, hence, lowered
          network throughput. Second, unnecessary packet drops represent a
          waste of network capacity on the path before the drop point. <vspace
          blankLines="1" />While AQM can manage queue lengths and reduce
          end-to-end latency even in the absence of end-to-end congestion
          control, it will be able to reduce packet drops only in an
          environment that continues to be dominated by end-to-end congestion
          control.</t>

          <t>Provide a lower-delay interactive service <vspace
          blankLines="1" />By keeping a small average queue size, AQM will
          reduce the delays experienced by flows. This is particularly
          important for interactive applications such as short web transfers,
          POP/IMAP, DNS, terminal traffic (Telnet, SSH, Mosh, RDP, etc.),
          gaming or interactive audio-video sessions, whose subjective (and
          objective) performance is better when the end-to-end delay is
          low.</t>

          <t>Avoid lock-out behavior <vspace blankLines="1" />AQM can prevent
          lock-out behavior by ensuring that there will almost always be a
          buffer available for an incoming packet. For the same reason, AQM
          can prevent a bias against low-capacity, but highly bursty, flows.
          <vspace blankLines="1" />Lock-out is undesirable because it
          constitutes a gross unfairness among groups of flows. However, we
          stop short of calling this benefit "increased fairness", because
          general fairness among flows requires per-flow state, which is not
          provided by queue management. For example, in a network device using
          AQM with only FIFO scheduling, two TCP flows may receive very
          different shares of the network capacity simply because they have
          different RTTs <xref target="Floyd91"></xref>, and a
          flow that does not use congestion control may receive more capacity
          than a flow that does. AQM can therefore be combined with a
          scheduling mechanism that divides network traffic between multiple
          queues (<xref target="mult"/>).</t>

          <t>Reduce the probability of control loop synchronization<vspace
          blankLines="1" />The probability of network control loop
          synchronization can be reduced if network devices introduce
          randomness in the AQM functions that trigger congestion avoidance at
          the sending host.</t>
        </list></t>

      <section title="AQM and Multiple Queues" anchor="mult">
        <t>A network device may use per-flow or per-class queueing with a
        scheduling algorithm to either prioritize certain applications or
        classes of traffic, limit the rate of transmission, or provide
        isolation between different traffic flows within a common class. For
        example, a router may maintain per-flow state to achieve general
        fairness by a per-flow scheduling algorithm such as various forms of
        Fair Queueing (FQ) <xref target="Dem90"></xref> <xref
        target="Sut99"></xref>, including Weighted Fair Queueing (WFQ),
        Stochastic Fairness Queueing (SFQ) <xref target="McK90"></xref>,
        Deficit Round Robin (DRR) <xref target="Shr96"></xref> <xref
        target="Nic12"></xref>, and/or a Class-Based Queue scheduling
        algorithm such as CBQ <xref target="Floyd95"></xref>. Hierarchical
        queues may also be used, e.g., as a part of a Hierarchical Token Bucket
        (HTB) or Hierarchical Fair Service Curve (HFSC) <xref
        target="Sto97"></xref>. These methods are also used to realize a range
        of Quality of Service (QoS) behaviors designed to meet the need of
        traffic classes (e.g., using the integrated or differentiated service
        models).</t>

        <t>AQM is needed even for network devices that use per-flow or
        per-class queueing, because scheduling algorithms by themselves do not
        control the overall queue size or the sizes of individual queues. AQM
        mechanisms might need to control the overall queue sizes to ensure
        that arriving bursts can be accommodated without dropping packets. AQM
        should also be used to control the queue size for each individual flow
        or class, so that they do not experience unnecessarily high delay.
        Using a combination of AQM and scheduling between multiple queues has
        been shown to offer good results in experimental use and some types of
        operational use.</t>

        <t>In short, scheduling algorithms and queue management should be seen
        as complementary, not as replacements for each other.</t>
      </section>

      <section title="AQM and Explicit Congestion Marking (ECN)">
        <t>An AQM method may use Explicit Congestion Notification (ECN) <xref
        target="RFC3168"></xref> instead of dropping to mark packets under
        mild or moderate congestion. ECN-marking can allow a network device to
        signal congestion at a point before a transport experiences congestion
        loss or additional queueing delay <xref target="ECN-Benefit"></xref>.
        <xref target="ECN"> </xref> describes some of the benefits of using
        ECN with AQM.</t>
      </section>

      <section title="AQM and Buffer Size">
        <t>It is important to differentiate the choice of buffer size for a
        queue in a switch/router or other network device, and the threshold(s)
        and other parameters that determine how and when an AQM algorithm
        operates. The optimum buffer size is a function of operational
        requirements and should generally be sized to be sufficient to buffer
        the largest normal traffic burst that is expected. This size depends
        on the amount and burstiness of traffic arriving at the queue and the
        rate at which traffic leaves the queue.</t>

        <t>One objective of AQM is to minimize the effect of lock-out, where
        one flow prevents other flows from effectively gaining capacity. This
        need can be illustrated by a simple example of drop-tail queueing when
        a new TCP flow injects packets into a queue that happens to be almost
        full. A TCP flow's congestion control algorithm <xref
        target="RFC5681"></xref> increases the flow rate to maximize its
        effective window. This builds a queue in the network, inducing latency
        in the flow and other flows that share this queue. Once a drop-tail
        queue fills, there will also be loss. A new flow, sending its initial
        burst, has an enhanced probability of filling the remaining queue and
        dropping packets. 


   As a result, the new flow can be prevented from effectively
   sharing the queue for a period of many RTTs.
  In contrast, AQM can minimize the mean queue depth and therefore
        reduce the probability that competing sessions can materially
        prevent each other from performing well.</t>

        <t>AQM frees a designer from having to limit the buffer space assigned
        to a queue to achieve acceptable performance, allowing allocation of
        sufficient buffering to satisfy the needs of the particular traffic
        pattern. Different types of traffic and deployment scenarios will lead
        to different requirements. The choice of AQM algorithm and associated
        parameters is therefore a function of the way in which congestion is
        experienced and the required reaction to achieve acceptable
        performance. The latter is the primary topic of the following
        sections.</t>
      </section>
    </section>

    <section anchor="Section4" title="Managing Aggressive Flows">
      <t>One of the keys to the success of the Internet has been the
      congestion avoidance mechanisms of TCP. Because TCP "backs off" during
      congestion, a large number of TCP connections can share a single,
      congested link in such a way that link bandwidth is shared reasonably
      equitably among similarly situated flows. The equitable sharing of
      bandwidth among flows depends on all flows running compatible congestion
      avoidance algorithms, i.e., methods conformant with the current TCP
      specification <xref target="RFC5681"></xref>.</t>

      <t>In this document, a flow is known as "TCP-friendly" when it has a
      congestion response that approximates the average response expected of a
      TCP flow. One example method of a TCP-friendly scheme is the
      TCP-Friendly Rate Control algorithm <xref target="RFC5348"></xref>. In
      this document, the term is used more generally to describe this and
      other algorithms that meet these goals.</t>

      <t>There are a variety of types of network flow. Some convenient classes
      that describe flows are: (1) TCP-friendly flows, (2) unresponsive flows,
      i.e., flows that do not slow down when congestion occurs, and (3) flows
      that are responsive but are less responsive to congestion than TCP. The
      last two classes contain more aggressive flows that can pose significant
      threats to Internet performance. <list style="numbers">
          <t>TCP-friendly flows <vspace blankLines="1" />A TCP-friendly flow
          responds to congestion notification within a small number of path
          RTTs, and in steady-state it uses no more capacity
          than a conformant TCP running under comparable conditions (drop
          rate, RTT, packet size, etc.). This is described in the remainder of
          the document.</t>

          <t>Non-responsive flows <vspace blankLines="1" />A non-responsive flow does
          not adjust its rate in response to congestion notification within a
          small number of path RTTs; it can also use more capacity than a
          conformant TCP running under comparable conditions. There is a
          growing set of applications whose congestion avoidance algorithms
          are inadequate or nonexistent (i.e., a flow that does not throttle
          its sending rate when it experiences congestion).<vspace
          blankLines="1" />The User Datagram Protocol (UDP) <xref
          target="RFC0768"></xref> provides a minimal, best-effort transport
          to applications and upper-layer protocols (both simply called
          "applications" in the remainder of this document) and does not
          itself provide mechanisms to prevent congestion collapse or
          establish a degree of fairness <xref target="RFC5405"></xref>.
          Examples that use UDP include some streaming applications for packet
          voice and video, and some multicast bulk data transport. Other
          traffic, when aggregated, may also become unresponsive to congestion
          notification. If no action is taken, such unresponsive flows could
          lead to a new congestion collapse <xref target="RFC2914"></xref>.
          Some applications can even increase their traffic volume in response
          to congestion (e.g., by adding Forward Error Correction when loss is
          experienced), with the possibility that they contribute to
          congestion collapse.<vspace blankLines="1" />In general,
          applications need to incorporate effective congestion avoidance
          mechanisms <xref target="RFC5405"></xref>. Research continues to be
          needed to identify and develop ways to accomplish congestion
          avoidance for presently unresponsive applications. Network devices
          need to be able to protect themselves against unresponsive flows,
          and mechanisms to accomplish this must be developed and deployed.
          Deployment of such mechanisms would provide an incentive for all
          applications to become responsive by either using a
          congestion-controlled transport (e.g., TCP, <xref
          target="RFC4960">SCTP</xref>, and <xref
          target="RFC4340">DCCP</xref>) or incorporating their own
          congestion control in the application <xref
          target="RFC5405"></xref> <xref target="RFC6679"></xref>.</t>

          <t>Transport flows that are less responsive than TCP 

<vspace blankLines="1" />
A second threat is posed by transport protocol implementations that are
responsive to congestion, but, either deliberately or through faulty
implementation, reduce the effective window less than a TCP flow would
have done in response to congestion.
          This covers a
          spectrum of behaviors between (1) and (2). If applications are not
          sufficiently responsive to congestion signals, they may gain an
          unfair share of the available network capacity. <vspace
          blankLines="1" />For example, the popularity of the Internet has
          caused a proliferation in the number of TCP implementations. Some of
          these may fail to implement the TCP congestion avoidance mechanisms
          correctly because of poor implementation. Others may deliberately be
          implemented with congestion avoidance algorithms that are more
          aggressive in their use of capacity than other TCP implementations;
          this would allow a vendor to claim to have a "faster TCP". The
          logical consequence of such implementations would be a spiral of
          increasingly aggressive TCP implementations, leading back to the
          point where there is effectively no congestion avoidance and the
          Internet is chronically congested. <vspace blankLines="1" />Another
          example could be an RTP/UDP video flow that uses an adaptive codec,
          but responds incompletely to indications of congestion or responds
          over an excessively long time period. Such flows are unlikely to be
          responsive to congestion signals in a time frame comparable to a
          small number of end-to-end transmission delays. However, over a
          longer timescale, perhaps seconds in duration, they could moderate
          their speed, or increase their speed if they determine capacity to
          be available. <vspace blankLines="1" />Tunneled traffic aggregates
          carrying multiple (short) TCP flows can be more aggressive than
          standard bulk TCP. Applications (e.g., web browsers primarily
          supporting HTTP 1.1 and peer-to-peer file-sharing) have exploited
          this by opening multiple connections to the same endpoint.<vspace
          blankLines="1" />Lastly, some applications (e.g., web browsers
          primarily supporting HTTP 1.1) open a large numbers of successive
          short TCP flows for a single session. This can lead to each
          individual flow spending the majority of time in the exponential TCP
          slow start phase, rather than in TCP congestion avoidance. The
          resulting traffic aggregate can therefore be much less responsive
          than a single standard TCP flow.</t>
        </list></t>

      <t>The projected increase in the fraction of total Internet traffic for
      more aggressive flows in classes 2 and 3 could pose a threat to the
      performance of the future Internet. There is therefore an urgent need
      for measurements of current conditions and for further research into the
      ways of managing such flows. This raises many difficult issues in
      finding methods with an acceptable overhead cost that can identify and
      isolate unresponsive flows or flows that are less responsive than TCP.
      Finally, there is as yet little measurement or simulation evidence
      available about the rate at which these threats are likely to be
      realized or about the expected benefit of algorithms for managing such
      flows.</t>

      <t>Another topic requiring consideration is the appropriate granularity
      of a "flow" when considering a queue management method. There are a few
      "natural" answers: 1) a transport (e.g., TCP or UDP) flow (source
      address/port, destination address/port, protocol); 2) Differentiated
      Services Code Point, DSCP; 3) a source/destination host pair (IP
      address); 4) a given source host or a given destination host, or various
      combinations of the above; 5) a subscriber or site receiving the
      Internet service (enterprise or residential).</t>

      <t>The source/destination host pair gives an appropriate granularity in
      many circumstances.  However, different vendors/providers use different
      granularities for defining a flow (as a way of "distinguishing"
      themselves from one another), and different granularities may be chosen
      for different places in the network. It may be the case that the
      granularity is less important than the fact that a network device needs
      to be able to deal with more unresponsive flows at *some* granularity.
      The granularity of flows for congestion management is, at least in part,
      a question of policy that needs to be addressed in the wider IETF
      community.</t>
    </section>

    <section anchor="conclusion" title="Conclusions and Recommendations">

      <t>The IRTF, in producing <xref target="RFC2309"></xref>, and the IETF
      in subsequent discussion, have developed a set of specific
      recommendations regarding the implementation and operational use of AQM
      procedures. The recommendations provided by this document are summarized
      as: <list style="numbers">
          <t>Network devices SHOULD implement some AQM mechanism to manage
          queue lengths, reduce end-to-end latency, and avoid lock-out
          phenomena within the Internet.</t>

          <t>Deployed AQM algorithms SHOULD support Explicit Congestion
          Notification (ECN) as well as loss to signal congestion to
          endpoints.</t>

          <t>AQM algorithms SHOULD NOT require tuning of initial or
          configuration parameters in common use cases.</t>

          <t>AQM algorithms SHOULD respond to measured congestion, not
          application profiles.</t>

          <t>AQM algorithms SHOULD NOT interpret specific transport protocol
          behaviors.</t>

          <t>Congestion control algorithms for transport protocols SHOULD maximize
          their use of available capacity (when there is data to send) without
          incurring undue loss or undue round-trip delay.</t>

          <t>Research, engineering, and measurement efforts are needed
          regarding the design of mechanisms to deal with flows that are
          unresponsive to congestion notification or are responsive, but are
          more aggressive than present TCP.</t>
        </list></t>

      <t>These recommendations are expressed using the word "SHOULD". This is
      in recognition that there may be use cases that have not been envisaged
      in this document in which the recommendation does not apply. Therefore,
      care should be taken in concluding that one's use case falls in that
      category; during the life of the Internet, such use cases have been
      rarely, if ever, observed and reported. To the contrary, available <xref
      target="Choi04"> research </xref> says that even high-speed links in
      network cores that are normally very stable in depth and behavior
      experience occasional issues that need moderation. The recommendations
      are detailed in the following sections.</t>

      <section anchor="useAQM"
               title="Operational Deployments SHOULD Use AQM Procedures">
        <t>AQM procedures are designed to minimize the delay and buffer
        exhaustion induced in the network by queues that have filled as a
        result of host behavior. Marking and loss behaviors provide a signal
        that buffers within network devices are becoming unnecessarily full
        and that the sender would do well to moderate its behavior.</t>

        <t>The use of scheduling mechanisms, such as priority queueing,
        classful queueing, and fair queueing, is often effective in networks to
        help a network serve the needs of a range of applications. Network
        operators can use these methods to manage traffic passing a choke
        point. This is discussed in <xref target="RFC2474"></xref> and <xref
        target="RFC2475"></xref>. When scheduling is used, AQM should be
        applied across the classes or flows as well as within each class or
        flow:</t>

        <t><list style="symbols">
            <t>AQM mechanisms need to control the overall queue sizes to
            ensure that arriving bursts can be accommodated without dropping
            packets.</t>

            <t>AQM mechanisms need to allow combination with other mechanisms,
            such as scheduling, to allow implementation of policies for
            providing fairness between different flows.</t>

            <t>AQM should be used to control the queue size for each
            individual flow or class, so that they do not experience
            unnecessarily high delay.</t>
          </list></t>
      </section>

      <section anchor="signaling" title="Signaling to the Transport Endpoints">
        <t>There are a number of ways a network device may signal to the endpoint that the network is becoming congested and trigger a reduction
        in rate. The signaling methods include:</t>

        <t><list style="symbols">
            <t>Delaying transport segments (packets) in flight, such as in a
            queue.</t>

            <t>Dropping transport segments (packets) in transit.</t>

            <t>Marking transport segments (packets), such as using Explicit
            Congestion Control <xref target="RFC3168"></xref> <xref
            target="RFC4301"></xref> <xref target="RFC4774"></xref> <xref
            target="RFC6040"></xref> <xref target="RFC6679"></xref>.</t>
          </list>Increased network latency is used as an implicit signal of
        congestion. For example, in TCP, additional delay can affect ACK clocking and
        has the result of reducing the rate of transmission of new data. In
        the Real-time Transport Protocol (RTP), network latency impacts the
        RTCP-reported RTT, and increased latency can trigger a sender to adjust
        its rate. Methods such as Low Extra Delay Background Transport
        (LEDBAT) <xref target="RFC6817"></xref> assume increased latency as a
        primary signal of congestion. Appropriate use of delay-based methods
        and the implications of AQM presently remain an area for further
        research.</t>

        <t>It is essential that all Internet hosts respond to loss <xref
        target="RFC5681"> </xref> <xref target="RFC5405"></xref> <xref
        target="RFC4960"></xref> <xref target="RFC4340"></xref>. Packet
        dropping by network devices that are under load has two effects: It
        protects the network, which is the primary reason that network devices
        drop packets. 


The detection of loss also provides a signal to a reliable transport (e.g.,
TCP, SCTP) that there is incipient congestion, using a pragmatic but ambiguous
heuristic. Whereas, when the network discards a message in flight, the loss may imply
the presence of faulty equipment or media in a path, or it may imply the
presence of congestion. To be conservative, a transport must assume it may be
the latter.

        Applications using unreliable transports (e.g., using UDP) need to
        similarly react to loss <xref target="RFC5405"></xref>.</t>

        <t>Network devices SHOULD use an AQM algorithm to measure local
        congestion and to determine the packets to mark or drop so that the
        congestion is managed.</t>

        <t>In general, dropping multiple packets from the same sessions in the
        same RTT is ineffective and can reduce throughput. Also, dropping or
        marking packets from multiple sessions simultaneously can have the
        effect of synchronizing them, resulting in increasing peaks and
        troughs in the subsequent traffic load. Hence, AQM algorithms SHOULD
        randomize dropping in time, to reduce the probability that congestion
        indications are only experienced by a small proportion of the active
        flows.</t>

        <t>Loss due to dropping also has an effect on the efficiency of a flow
        and can significantly impact some classes of application. In reliable
        transports, the dropped data must be subsequently retransmitted. While
        other applications/transports may adapt to the absence of lost data,
        this still implies inefficient use of available capacity, and the
        dropped traffic can affect other flows. Hence, congestion signaling
        by loss is not entirely positive; it is a necessary evil.</t>

        <section anchor="ECN" title="AQM and ECN">
          <t>Explicit Congestion Notification (ECN) <xref
          target="RFC4301"></xref> <xref target="RFC4774"></xref> <xref
          target="RFC6040"></xref> <xref target="RFC6679"></xref> is a
          network-layer function that allows a transport to receive network
          congestion information from a network device without incurring the
          unintended consequences of loss. ECN includes both transport
          mechanisms and functions implemented in network devices; the latter
          rely upon using AQM to decide when and whether to ECN-mark.</t>

          <t>Congestion for ECN-capable transports is signaled by a network
          device setting the "Congestion Experienced (CE)" codepoint in the IP
          header. This codepoint is noted by the remote receiving endpoint
          and signaled back to the sender using a transport protocol
          mechanism, allowing the sender to trigger timely congestion control.
          The decision to set the CE codepoint requires an AQM algorithm
          configured with a threshold. Non-ECN capable flows (the default) are
          dropped under congestion.</t>

          <t>Network devices SHOULD use an AQM algorithm that marks
          ECN-capable traffic when making decisions about the response to
          congestion. Network devices need to implement this method by marking
          ECN-capable traffic or by dropping non-ECN-capable traffic.</t>

          <t>Safe deployment of ECN requires that network devices drop
          excessive traffic, even when marked as originating from an
          ECN-capable transport. This is a necessary safety precaution
          because:</t>

          <t><list style="numbers">
              <t>A non-conformant, broken, or malicious receiver could conceal
              an ECN mark and not report this to the sender;</t>

              <t>A non-conformant, broken, or malicious sender could ignore a
              reported ECN mark, as it could ignore a loss without using
              ECN;</t>

              <t>A malfunctioning or non-conforming network device may "hide"
              an ECN mark (or fail to correctly set the ECN codepoint at an
              egress of a network tunnel).</t>
            </list>In normal operation, such cases should be very uncommon;
          however, overload protection is desirable to protect traffic from
          misconfigured or malicious use of ECN (e.g., a denial-of-service
          attack that generates ECN-capable traffic that is unresponsive to
          CE-marking).</t>

<t>
When ECN is added to a scheme, the ECN support MAY define a separate set of
parameters from those used for controlling packet drop. The AQM algorithm
SHOULD still auto-tune these ECN-specific parameters. These
parameters SHOULD also be manually configurable.
	</t>

          <t>Network devices SHOULD use an algorithm to drop excessive traffic
          (e.g., at some level above the threshold for CE-marking), even when
          the packets are marked as originating from an ECN-capable
          transport.</t>
        </section>
      </section>

      <section anchor="autotuning"
               title="AQM Algorithm Deployment SHOULD NOT Require Operational Tuning">
        <t>A number of AQM algorithms have been proposed. Many require some
        form of tuning or setting of parameters for initial network
        conditions. This can make these algorithms difficult to use in
        operational networks.</t>

        <t>AQM algorithms need to consider both "initial conditions" and
        "operational conditions". The former includes values that exist before
        any experience is gathered about the use of the algorithm, such as the
        configured speed of interface, support for full-duplex communication,
        interface MTU, and other properties of the link. Other properties include
        information observed from monitoring the size of the queue,
        the queueing delay experienced, rate of packet discard, etc.</t>

        <t>This document therefore specifies that AQM algorithms that are
        proposed for deployment in the Internet have the following
        properties:</t>

        <t><list style="symbols">
            <t>AQM algorithm deployment SHOULD NOT require tuning. An
            algorithm MUST provide a default behavior that auto-tunes to a
            reasonable performance for typical network operational conditions.
            This is expected to ease deployment and operation. Initial
            conditions, such as the interface rate and MTU size or other
            values derived from these, MAY be required by an AQM
            algorithm.</t>

            <t>AQM algorithm deployment MAY support further manual tuning that could improve
            performance in a specific deployed network. Algorithms that lack
            such variables are acceptable, but, if such variables exist, they
            SHOULD be externalized (made visible to the operator). 

The specification should identify any cases in which auto-tuning is unlikely
to achieve acceptable performance and give guidance on the parametric
adjustments necessary.

  For example, the expected response
            of an algorithm may need to be configured to accommodate the
            largest expected Path RTT, since this value cannot be known at
            initialization. This guidance is expected to enable the algorithm
            to be deployed in networks that have specific characteristics
            (paths with variable or larger delay, networks where capacity is
            impacted by interactions with lower-layer mechanisms, etc).</t>

            <t>AQM algorithm deployment MAY provide logging and alarm signals to assist in identifying
            if an algorithm using manual or auto-tuning is functioning as
            expected. (For example, this could be based on an internal consistency
            check between input, output, and mark/drop rates over time.) This
            is expected to encourage deployment by default and allow operators
            to identify potential interactions with other network
            functions.</t>
          </list>Hence, self-tuning algorithms are to be preferred. Algorithms
        recommended for general Internet deployment by the IETF need to be
        designed so that they do not require operational (especially manual)
        configuration or tuning.</t>
      </section>

      <section title="AQM Algorithms SHOULD Respond to Measured Congestion, Not Application Profiles">
        <t>Not all applications transmit packets of the same size. Although
        applications may be characterized by particular profiles of packet
        size, this should not be used as the basis for AQM (see <xref target="alltraffic"/>).
        Other methods exist, e.g., Differentiated Services queueing,
        Pre-Congestion Notification (PCN) <xref target="RFC5559"></xref>, that
        can be used to differentiate and police classes of application.
        Network devices may combine AQM with these traffic classification
        mechanisms and perform AQM only on specific queues within a network
        device.</t>

        <t>An AQM algorithm should not deliberately try to prejudice the size
        of packet that performs best (i.e., preferentially drop/mark based
        only on packet size). Procedures for selecting packets to drop/mark
        SHOULD observe the actual or projected time that a packet is in a
        queue (bytes at a rate being an analog to time). When an AQM algorithm
        decides whether to drop (or mark) a packet, it is RECOMMENDED that the
        size of the particular packet not be taken into account <xref
        target="RFC7141"></xref>.</t>

        <t>Applications (or transports) generally know the packet size that
        they are using and can hence make their judgments about whether to use
        small or large packets based on the data they wish to send and the
        expected impact on the delay, throughput, or other performance
        parameter. When a transport or application responds to a dropped or
        marked packet, the size of the rate reduction should be proportionate
        to the size of the packet that was sent <xref
        target="RFC7141"></xref>.</t>

        <t>An AQM-enabled system MAY instantiate different instances of an AQM
        algorithm to be applied within the same traffic class. Traffic classes
        may be differentiated based on an Access Control List (ACL), the
        packet DSCP <xref
        target="RFC5559"></xref>, enabling use of the ECN field (i.e., any of
        ECT(0), ECT(1) or CE) <xref target="RFC3168"></xref> <xref
        target="RFC4774"> </xref>, a multi-field (MF) classifier that combines
        the values of a set of protocol fields (e.g., IP address, transport,
        ports), or an equivalent codepoint at a lower layer. This
        recommendation goes beyond what is defined in RFC 3168 by allowing
        that an implementation MAY use more than one instance of an AQM
        algorithm to handle both ECN-capable and non-ECN-capable packets.</t>
      </section>

      <section anchor="alltraffic"
               title="AQM Algorithms SHOULD NOT Be Dependent on Specific Transport Protocol Behaviors">
        <t>In deploying AQM, network devices need to support a range of
        Internet traffic and SHOULD NOT make implicit assumptions about the
        characteristics desired by the set of transports/applications the network
        supports. That is, AQM methods should be opaque to the choice of
        transport and application.</t>

        <t>AQM algorithms are often evaluated by considering <xref
        target="RFC0793">TCP</xref> with a limited number of applications.
        Although TCP is the predominant transport in the Internet today, this
        no longer represents a sufficient selection of traffic for
        verification. There is significant use of <xref
        target="RFC0768">UDP</xref> in voice and video services, and some
        applications find utility in <xref target="RFC4960">SCTP</xref> and
        <xref target="RFC4340">DCCP</xref>. Hence, AQM algorithms should
        demonstrate operation with transports other than TCP and need to
        consider a variety of applications. 


   When selecting AQM algorithms, the use of tunnel encapsulations 
   that may carry traffic aggregates needs to be considered.
	</t>

        <t>AQM algorithms SHOULD NOT target or derive implicit assumptions
        about the characteristics desired by specific transports/applications.
        Transports and applications need to respond to the congestion signals
        provided by AQM (i.e., dropping or ECN-marking) in a timely manner
        (within a few RTTs at the latest).</t>
      </section>

      <section anchor="tcpcc"
               title="Interactions with Congestion Control Algorithms">
        <t>Applications and transports need to react to received implicit or
        explicit signals that indicate the presence of congestion. This
        section identifies issues that can impact the design of transport
        protocols when using paths that use AQM.</t>

        <t>Transport protocols and applications need timely signals of
        congestion. The time taken to detect and respond to congestion is
        increased when network devices queue packets in buffers. It can be
        difficult to detect tail losses at a higher layer, and this may
        sometimes require transport timers or probe packets to detect and
        respond to such loss. Loss patterns may also impact timely detection,
        e.g., the time may be reduced when network devices do not drop long
        runs of packets from the same flow.</t>

        <t>A common objective of an elastic transport congestion control
        protocol is to allow an application to deliver the maximum rate of
        data without inducing excessive delays when packets are queued in 
        buffers within the network. To achieve this, a transport should try to
        operate at rate below the inflection point of the load/delay curve (the
        bend of what is sometimes called a "hockey stick" curve) <xref
        target="Jain94"></xref>. When the congestion window allows the load to
        approach this bend, the end-to-end delay starts to rise -- a
        result of congestion, as packets probabilistically arrive at
        non-overlapping times. On the one hand, a transport that operates
        above this point can experience congestion loss and could also trigger
        operator activities, such as those discussed in <xref
        target="RFC6057"></xref>. On the other hand, a flow may achieve both
        near-maximum throughput and low latency when it operates close to this
        knee point, with minimal contribution to router congestion. Choice of
        an appropriate rate/congestion window can therefore significantly
        impact the loss and delay experienced by a flow and will impact other
        flows that share a common network queue.</t>


        <t>
Some applications may send data at a lower rate or keep less segments
outstanding at any given time.
 Examples include multimedia codecs that
        stream at some natural rate (or set of rates) or an application that
        is naturally interactive (e.g., some web applications, interactive
        server-based gaming, transaction-based protocols). Such applications
        may have different objectives. They may not wish to maximize
        throughput, but may desire a lower loss rate or bounded delay.</t>

        <t>The correct operation of an AQM-enabled network device MUST NOT
        rely upon specific transport responses to congestion signals.</t>
      </section>

      <section anchor="research" title="The Need for Further Research">
        <t><xref target="RFC2309">The second recommendation of </xref> called
        for further research into the interaction between network queues and
        host applications, and the means of signaling between them. This
        research has occurred, and we as a community have learned a lot.
        However, we are not done.</t>

        <t>We have learned that the problems of congestion, latency, and
        buffer-sizing have not gone away and are becoming more important to
        many users. A number of self-tuning AQM algorithms have been found
        that offer significant advantages for deployed networks. There is also
        renewed interest in deploying AQM and the potential of ECN.</t>

        <t>Traffic patterns can depend on the network deployment scenario, and
        Internet research therefore needs to consider the implications of a
        diverse range of application interactions. This includes ensuring that
        combinations of mechanisms, as well as combinations of traffic
        patterns, do not interact and result in either significantly reduced
        flow throughput or significantly increased latency.</t>

        <t>At the time of writing (in 2015), an obvious example of further
        research is the need to consider the many-to-one communication
        patterns found in data centers, known as <xref
        target="Ren12">incast</xref>, (e.g., produced by Map/Reduce
        applications). Such analysis needs to study not only each application
        traffic type but also combinations of types of
        traffic.</t>

        <t>Research also needs to consider the need to extend our taxonomy of
        transport sessions to include not only "mice" and "elephants", but
        "lemmings". Here, "lemmings" are flash crowds of "mice" that the
        network inadvertently tries to signal to as if they were "elephant"
        flows, resulting in head-of-line blocking in a data center deployment
        scenario.</t>


        <t>Examples of other required research include:

        <list style="symbols">

 <t>new AQM and scheduling algorithms</t>
 <t>appropriate use of delay-based methods and the implications of
      AQM</t>
 <t>suitable algorithms for marking ECN-capable packets that do not 
      require operational configuration or tuning for common use</t>
 <t>experience in the deployment of ECN alongside AQM</t>
 <t>tools for enabling AQM (and ECN) deployment and measuring the
      performance</t>
 <t>methods for mitigating the impact of non-conformant and malicious
      flows</t>
 <t>implications on applications of using new network and transport methods </t>
        </list>Hence, this document reiterates the call of RFC
        2309: we need continuing research as applications develop.</t>
      </section>
    </section>


    <section anchor="Security" title="Security Considerations">
      <t>While security is a very important issue, it is largely orthogonal to
      the performance issues discussed in this memo.</t>

      <t>This recommendation requires algorithms to be independent of specific
      transport or application behaviors. Therefore, a network device does not
      require visibility or access to upper-layer protocol information to
      implement an AQM algorithm. This ability to operate in an
      application-agnostic fashion is an example of a
      privacy-enhancing feature.</t>

      <t>Many deployed network devices use queueing methods that allow
      unresponsive traffic to capture network capacity, denying access to
      other traffic flows. This could potentially be used as a
      denial-of-service attack. This threat could be reduced in network
      devices that deploy AQM or some form of scheduling. We note, however,
      that a denial-of-service attack that results in unresponsive traffic
      flows may be indistinguishable from other traffic flows (e.g., tunnels
      carrying aggregates of short flows, high-rate isochronous applications).
      New methods therefore may remain vulnerable, and this document
      recommends that ongoing research consider ways to mitigate such
      attacks.</t>
    </section>

    <section anchor="Privacy" title="Privacy Considerations">
      <t>This document, by itself, presents no new privacy issues.</t>
    </section>

  </middle>

  <back>

    <references title="Normative References">
      <?rfc include="reference.RFC.2119"?>

      <?rfc include="reference.RFC.3168" ?>

      <?rfc include="reference.RFC.6679" ?>

      <?rfc include="reference.RFC.4301" ?>

      <?rfc include="reference.RFC.4774" ?>

      <?rfc include="reference.RFC.5405" ?>

      <?rfc include="reference.RFC.5681" ?>

      <?rfc include="reference.RFC.6040"?>

      <?rfc include="reference.RFC.7141"
 ?>
    </references>

    <references title="Informative References">
      <?rfc include="reference.RFC.0768" ?>

      <?rfc include="reference.RFC.0791" ?>

      <?rfc include="reference.RFC.0793" ?>

      <?rfc include="reference.RFC.0896" ?>

      <?rfc include="reference.RFC.0970" ?>

      <?rfc include="reference.RFC.1122" ?>

      <?rfc include="reference.RFC.1633"?>

      <?rfc include="reference.RFC.2309"?>

      <?rfc include="reference.RFC.2460" ?>

      <?rfc include="reference.RFC.2474" ?>

      <?rfc include="reference.RFC.2475"?>

      <?rfc include="reference.RFC.2914"?>

      <?rfc include="reference.RFC.4340" ?>

      <?rfc include="reference.RFC.4960" ?>

      <?rfc include="reference.RFC.5348"?>

      <?rfc include="reference.RFC.5559"?>

      <?rfc include="reference.RFC.6057" ?>

      <?rfc include="reference.RFC.6817" ?>

      <?rfc include="reference.RFC.6789" ?>

      <?rfc include="reference.RFC.7414"?>

      <reference anchor="Floyd91">
        <front>
          <title>Connections with Multiple Congested Gateways in
          Packet-Switched Networks Part 1: One-way Traffic.</title>

          <author fullname="S. Floyd" initials="S" surname="Floyd">
            <organization></organization>
          </author>

          <date month="October" year="1991" />
        </front>

        <seriesInfo name="Computer Communications Review" value="" />
      </reference>

      <reference anchor="Floyd95">
        <front>
          <title>Link-sharing and Resource Management Models for Packet
          Networks</title>

          <author fullname="S. Floyd" initials="S" surname="Floyd">
            <organization></organization>
          </author>

          <author fullname="Van Jacobson" initials="V" surname="Jacobson">
            <organization></organization>
          </author>

          <date month="August" year="1995" />
        </front>

        <seriesInfo name="IEEE/ACM Transactions on" value="Networking" />
      </reference>

      <reference anchor="Dem90">
        <front>
          <title>Analysis and Simulation of a Fair Queueing Algorithm,
          Internetworking: Research and Experience</title>

          <author fullname="A. Demers" initials="A" surname="Demers">
            <organization></organization>
          </author>

          <author fullname="S. Keshav" initials="S" surname="Keshav">
            <organization></organization>
          </author>

          <author fullname="S. Shenker" initials="S" surname="Shenker">
            <organization></organization>
          </author>

          <date year="1990" />
        </front>

        <seriesInfo name="SIGCOMM Symposium proceedings on Communications architectures and"
                    value="protocols" />
      </reference>

      <reference anchor="Willinger95">
        <front>
          <title>Self-Similarity Through High-Variability: Statistical
          Analysis of Ethernet LAN Traffic at the Source Level</title>

          <author fullname="W. Willinger" initials="W" surname="Willinger">
            <organization></organization>
          </author>

          <author fullname="M. Taqqu" initials="M" surname="Taqqu">
            <organization></organization>
          </author>

          <author fullname="R." initials="R" surname="Sherman">
            <organization></organization>
          </author>

          <author fullname="D.V. Wilson" initials="D" surname="Wilson">
            <organization></organization>
          </author>

          <author fullname="Van Jacobson" initials="V" surname="Jacobson">
            <organization></organization>
          </author>

          <date month="August" year="1995" />
        </front>

        <seriesInfo name="SIGCOMM Symposium proceedings on Communications architectures and"
                    value="protocols" />
      </reference>

      <reference anchor="Jacobson88">
        <front>
          <title>Congestion Avoidance and Control</title>

          <author fullname="Van Jacobson" initials="V" surname="Jacobson">
            <organization>Lawrence Berkeley Network Labs</organization>
          </author>

          <date month="August" year="1988" />
        </front>

        <seriesInfo name="SIGCOMM Symposium proceedings on Communications architectures and"
                    value="protocols" />
      </reference>

      <reference anchor="Lakshman96">
        <front>
          <title>The Drop From Front Strategy in TCP Over ATM and Its
          Interworking with Other Control Features</title>

          <author fullname="T. V. Lakshman" initials="TV" surname="Lakshman">
            <organization></organization>
          </author>

          <author fullname="Arnie Neidhardt" initials="A" surname="Neidhardt">
            <organization></organization>
          </author>

          <author fullname="Teunis Ott" initials="T" surname="Ott">
            <organization></organization>
          </author>

          <date year="1996" />
        </front>

        <seriesInfo name="IEEE" value="Infocomm" />
      </reference>

      <reference anchor="Leland94">
        <front>
          <title>On the Self-Similar Nature of Ethernet Traffic (Extended
          Version)</title>

          <author fullname="W. Leland" initials="W" surname="Leland">
            <organization></organization>
          </author>

          <author fullname="M. Taqqu" initials="M" surname="Taqqu">
            <organization></organization>
          </author>

          <author fullname="W. Willinger" initials="W" surname="Willinger">
            <organization></organization>
          </author>

          <author fullname="D. Wilson" initials="D" surname="Wilson">
            <organization></organization>
          </author>

          <date month="February" year="1994" />
        </front>

        <seriesInfo name="IEEE/ACM Transactions on" value="Networking" />
      </reference>

      <reference anchor="Jain94">
        <front>
          <title>Congestion avoidance scheme for computer networks</title>

          <author fullname="Rajendra K. Jain" initials="R" surname="Jain">
            <organization>Digital Equipment Corporation</organization>
          </author>

          <author fullname="KK Ramakrishnan" initials="KK"
                  surname="Ramakrishnan">
            <organization>Digital Equipment Corporation</organization>
          </author>

          <author fullname="Chiu Dah-Ming" initials="C" surname="Dah-Ming">
            <organization>Digital Equipment Corporation</organization>
          </author>

          <date day="27" month="December" year="1994" />
        </front>

        <seriesInfo name="US Patent Office" value="5377327" />
      </reference>

      <reference anchor="AQM-WG" target="http://datatracker.ietf.org/wg/aqm/charter/">
        <front>
          <title>Active Queue Management and Packet Scheduling (aqm) WG</title>

          <author>
            <organization>IETF</organization>
          </author>

          <date />
        </front>
      </reference>

      <reference anchor="Choi04">
        <front>
          <title>Analysis of Point-To-Point Packet Delay In an Operational
          Network</title>

          <author fullname="Baek-Young Choi " initials="B"
                  surname="Choi">
            <organization>Sprint ATL, Burlingame, CA</organization>
          </author>

          <author fullname=" Sue Moon" initials="S" surname="Moon">
            <organization></organization>
          </author>

          <author fullname="Zhi-Li Zhang" initials="Z " surname="Zhang">
            <organization></organization>
          </author>

          <author fullname="K Papagiannaki" initials="K"
                  surname="Papagiannaki">
            <organization></organization>
          </author>

          <author fullname=" C Diot" initials="C" surname="Diot">
            <organization></organization>

          </author>

          <date month="March" year="2004" />
        </front>
      </reference>


      <reference anchor="Nic12">
        <front>
          <title>Controlling Queue Delay</title>

          <author fullname="K Nichols" initials="K"
		  surname="Nichols"></author>
          <author fullname="Van Jacobson" initials="V" surname="Jacobson"></author>

          <date month="July" year="2012" />
        </front>

        <seriesInfo name="Communications of the" value="ACM"/>
	<seriesInfo name="Vol." value="55"/>
        <seriesInfo name="Issue" value="7" />
        <seriesInfo name="pp." value="42-50" />


      </reference>


      <reference anchor="Shr96">
        <front>
          <title>Efficient Fair Queueing Using Deficit Round Robin</title>

          <author fullname="M Shreedhar" initials="M" surname="Shreedhar"></author>

          <author fullname="G Varghese" initials="G" surname="Varghese"></author>

          <date month="July" year="1996" />
        </front>

        <seriesInfo name="IEEE/ACM Transactions on" value="Networking"/>
	<seriesInfo name="Vol." value="4"/> 
	<seriesInfo name="No." value="3" />
      </reference>


      <reference anchor="McK90"
		 target="http://www2.rdrop.com/~paulmck/scalability/paper/sfq.2002.06.04.pdf">


        <front>
          <title>Stochastic Fairness Queuing</title>

          <author fullname="PE McKenney" initials="PE" surname="McKenney"></author>

          <author fullname="G Varghese" initials="G" surname="Varghese"></author>

          <date year="1990" />
        </front>

      </reference>

      <reference anchor="Sut99">


        <front>
          <title>Buffer Management Schemes for Supporting TCP in Gigabit
          Routers with Per-flow Queueing</title>

          <author fullname="B Suter" initials="B" surname="Suter"></author>

          <date month="June" year="1999" />
        </front>

        <seriesInfo name="IEEE Journal on Selected Areas in"
		    value="Communications"/>
	<seriesInfo name="Vol." value="17"/>
	<seriesInfo name="Issue" value="6"/>
	<seriesInfo name="pp." value="1159-1169"/>

      </reference>

      <reference anchor="Sto97">
        <front>
          <title>A Hierarchical Fair Service Curve algorithm for Link sharing,
          real-time and priority services</title>

          <author fullname="Ion Stoica" initials="I" surname="Stoica">
            <organization></organization>
          </author>

          <author fullname="Hui Zhang" initials="H" surname="Zhang">
            <organization></organization>
          </author>

          <date year="1997" />
        </front>

        <seriesInfo name="ACM" value="SIGCOMM" />
      </reference>

<!-- draft-welzl-ecn-benefits-02 was replaced by
draft-ietf-aqm-ecn-benefits-04: I-D Exists --> 
      <reference anchor="ECN-Benefit">
        <front>
          <title>The Benefits of using Explicit Congestion
          Notification (ECN)</title>

          <author fullname="G Fairhurst" initials="G" surname="Fairhurst">
            <organization></organization>
          </author>

          <author fullname="M Welzl" initials="M" surname="Welzl">
            <organization></organization>
          </author>

          <date month="June" year="2015" />
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-aqm-ecn-benefits-05"/>

      </reference>

      <reference anchor="Flo92" target="http://www.icir.org/floyd/papers/phase.pdf">
        <front>
          <title>On Traffic Phase Effects in Packet-Switched Gateways</title>

          <author fullname="S Floyd" initials="S." surname="Floyd">
            <organization/>
          </author>

          <author fullname="V Jacobson" initials="V." surname="Jacobsen">
            <organization></organization>
          </author>

          <date year="1992" />
        </front>
      </reference>

      <reference anchor="Flo94" target="http://ee.lbl.gov/papers/sync_94.pdf">
        <front>
          <title>The Synchronization of Periodic Routing Messages</title>

          <author fullname="S Floyd" initials="S" surname="Floyd">
            <organization>Floyd</organization>
          </author>

          <author fullname="V Jacobsen" initials="V" surname="Jacobsen">
            <organization></organization>
          </author>

          <date year="1994" />
        </front>
      </reference>

<!-- draft-ietf-conex-abstract-mech-13: 
  Approved-announcement to be sent::Revised I-D Needed -->
      <reference anchor="CONEX">
        <front>
          <title>Congestion Exposure (ConEx) Concepts, Abstract Mechanism and Requirements</title>

          <author fullname="M Mathis" initials="M" surname="Mathis">
            <organization></organization>
          </author>

          <author fullname="B Briscoe" initials="B" surname="Briscoe">
            <organization></organization>
          </author>

          <date  month="October" year="2014" />
        </front>

        <seriesInfo name="Work in Progress,"
                    value="draft-ietf-conex-abstract-mech-13" />
      </reference>

      <reference anchor="Zha90" target="http://groups.csail.mit.edu/ana/Publications/Zhang-DDC-Oscillating-Behavior-of-Network-Traffic-1990.pdf">
        <front>
          <title>Oscillating Behavior of Network Traffic: A Case Study
          Simulation
          </title>

          <author fullname="L Zhang" initials="L" surname="Zhang">
            <organization></organization>
          </author>

          <author fullname="D Clark" initials="D" surname="Clark">
            <organization></organization>
          </author>

          <date year="1990" />
        </front>
      </reference>

      <reference anchor="Ren12">
        <front>
          <title>A survey on TCP Incast in data center networks</title>

          <author fullname="Y Ren" initials="Y" surname="Ren">
            <organization></organization>
          </author>

          <author fullname="Y Zhao" initials="Y" surname="Zhao">
            <organization></organization>
          </author>

          <author fullname="P Liu" initials="P" surname="Liu">
            <organization></organization>
          </author>

          <date year="1990" />
        </front>
<seriesInfo name="International Journal of Communication" value="Systems"/>
<seriesInfo name="Volumes" value="27"/>
<seriesInfo name="Issue" value="8"/>
<seriesInfo name="pages" value="116-117"/>
      </reference>

      <reference anchor="Bri15">
        <front>
          <title>Reducing Internet Latency: A Survey of Techniques and their
          Merit</title>

          <author fullname="B Briscoe" initials="B" surname="Briscoe">
            <organization></organization>
          </author>

          <author fullname="A Brunstrom " initials="A" surname="Brunstrom">
            <organization></organization>
          </author>

          <author fullname="A Petlund" initials="A" surname="Petlund">
            <organization></organization>
          </author>

          <author fullname="D Hayes" initials="D" surname="Hayes">
            <organization></organization>
          </author>

          <author fullname="D Ros" initials="D" surname="Ros">
            <organization></organization>
          </author>

          <author fullname="I-J Tsang" initials="I" surname="Tsang">
            <organization></organization>
          </author>

          <author fullname="S Gjessing" initials="S" surname="Gjessing">
            <organization></organization>
          </author>

          <author fullname="G Fairhurst" initials="G" surname="Fairhurst">
            <organization></organization>
          </author>

          <author fullname="C Griwodz" initials="C" surname="Griwodz">
            <organization></organization>
          </author>

          <author fullname="M Welzl" initials="M" surname="Welzl">
            <organization></organization>
          </author>

          <date year="2015" />
        </front>
<seriesInfo name="IEEE" value="Communications Surveys &amp; Tutorials"/>
      </reference>
    </references>

    <section anchor="Acknowledgements" title="Acknowledgements" numbered="no">
      <t>The original draft of this document describing best current
      practice was based on <xref
      target="RFC2309"></xref>, an Informational RFC. It was written by the End-to-End Research
      Group, which is to say Bob Braden, Dave Clark, Jon Crowcroft, Bruce
      Davie, Steve Deering, Deborah Estrin, Sally Floyd, Van Jacobson, Greg
      Minshall, Craig Partridge, Larry Peterson, KK Ramakrishnan, Scott
      Shenker, John Wroclawski, and Lixia Zhang. Although there are important
      differences, many of the key arguments in the present document remain
      unchanged from those in RFC 2309.</t>

      <t>The need for an updated document was agreed to in the TSV area meeting
      at IETF 86. This document was reviewed on the aqm@ietf.org list.
      Comments were received from Colin Perkins, Richard Scheffenegger, Dave
      Taht, John Leslie, David Collier-Brown, and many others.</t>

      <t>Gorry Fairhurst was in part supported by the European Community under
      its Seventh Framework Programme through the Reducing Internet Transport
      Latency (RITE) project (ICT-317700).</t>
    </section>


  </back>
</rfc>
